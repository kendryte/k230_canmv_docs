# AIå¼€å‘æ–‡æ¡£

## KPUç¡¬ä»¶åŸºæœ¬åŸç†ä»‹ç»

åœ¨è¾¹ç¼˜è®¡ç®—åœºæ™¯ä¸­ï¼ˆå¦‚ç‰©è”ç½‘è®¾å¤‡ã€æ™ºèƒ½æ‘„åƒå¤´ã€å·¥ä¸šæ£€æµ‹ç»ˆç«¯ã€å¯ç©¿æˆ´è®¾å¤‡ç­‰ï¼‰ï¼Œè®¾å¤‡é€šå¸¸éƒ¨ç½²åœ¨è¿œç¦»äº‘ç«¯æ•°æ®ä¸­å¿ƒçš„ç°åœºï¼Œé¢ä¸´ç€**å®æ—¶æ€§è¦æ±‚é«˜ã€ç½‘ç»œå¸¦å®½å—é™ã€æ•°æ®éšç§æ•æ„Ÿä»¥åŠåŠŸè€—çº¦æŸä¸¥æ ¼**çš„æŒ‘æˆ˜ã€‚åœ¨è¿™äº›åœºæ™¯ä¸‹è¿è¡Œå¤æ‚çš„AIæ¨¡å‹ï¼ˆå¦‚å›¾åƒè¯†åˆ«ã€ç›®æ ‡æ£€æµ‹ã€è¯­éŸ³å”¤é†’ï¼‰ï¼Œå¦‚æœä»…ä¾èµ–ä¼ ç»Ÿçš„é€šç”¨CPUè¿›è¡Œè®¡ç®—ï¼Œå¾€å¾€ä¼šé‡åˆ°**è®¡ç®—é‡è¿‡å¤§ã€å¤„ç†é€Ÿåº¦æ…¢ã€åŠŸè€—è¿‡é«˜**çš„é—®é¢˜ï¼Œéš¾ä»¥æ»¡è¶³å®æ—¶å“åº”å’Œèƒ½æ•ˆæ¯”çš„è¦æ±‚ã€‚

**KPUï¼ˆKnowledge Processing Unitï¼‰** æ˜¯å˜‰æ¥ ç§‘æŠ€ä¸“ä¸ºåº”å¯¹è¾¹ç¼˜AIè®¡ç®—æŒ‘æˆ˜è€Œè®¾è®¡çš„ç¡¬ä»¶åŠ é€Ÿå¼•æ“ã€‚å®ƒæœ¬è´¨ä¸Šæ˜¯ä¸€ä¸ªé«˜åº¦ä¼˜åŒ–çš„**æ·±åº¦å­¦ä¹ åå¤„ç†å™¨/åŠ é€Ÿå™¨**ï¼Œå…¶æ ¸å¿ƒåŠŸèƒ½æ˜¯**é«˜æ•ˆæ‰§è¡Œç¥ç»ç½‘ç»œæ¨¡å‹ä¸­çš„å¯†é›†è®¡ç®—ä»»åŠ¡**ï¼ˆç‰¹åˆ«æ˜¯å·ç§¯ã€çŸ©é˜µä¹˜æ³•ã€æ¿€æ´»å‡½æ•°ç­‰æ“ä½œï¼‰ã€‚

**KPUçš„æ ¸å¿ƒä¼˜åŠ¿**ï¼šä¸“ç²¾ä¸é«˜æ•ˆ, ä¸é€šç”¨CPUç›¸æ¯”ï¼ŒKPUçš„ä¼˜åŠ¿åœ¨äºå…¶**ä¸“ç”¨åŒ–æ¶æ„**ï¼š

- **å¹¶è¡Œè®¡ç®—èƒ½åŠ›ï¼š** KPUå†…éƒ¨åŒ…å«å¤§é‡ä¸“ä¸ºç¥ç»ç½‘ç»œè®¡ç®—è®¾è®¡çš„å¤„ç†å•å…ƒï¼ˆPEï¼‰ï¼Œèƒ½å¤ŸåŒæ—¶å¤„ç†æµ·é‡æ•°æ®ï¼ˆå¦‚ç‰¹å¾å›¾ã€æƒé‡ï¼‰ï¼Œæ˜¾è‘—åŠ é€Ÿæ¨¡å‹æ¨ç†è¿‡ç¨‹ã€‚
- **ä¼˜åŒ–çš„æ•°æ®æµä¸å†…å­˜è®¿é—®ï¼š** é’ˆå¯¹ç¥ç»ç½‘ç»œè®¡ç®—æ¨¡å¼ï¼ˆå¦‚æ•°æ®å¤ç”¨ï¼‰è¿›è¡Œæ·±åº¦ä¼˜åŒ–ï¼Œå‡å°‘ä¸å¿…è¦çš„æ•°æ®æ¬è¿ï¼Œæœ€å¤§åŒ–åˆ©ç”¨å†…å­˜å¸¦å®½ï¼Œé™ä½å»¶è¿Ÿã€‚
- **é«˜èƒ½æ•ˆæ¯”ï¼š** ä¸“ç”¨ç”µè·¯è®¾è®¡é¿å…äº†CPUæ‰§è¡Œé€šç”¨æŒ‡ä»¤çš„å¼€é”€ï¼Œåœ¨æ‰§è¡Œç›¸åŒçš„AIè®¡ç®—ä»»åŠ¡æ—¶ï¼ŒKPUé€šå¸¸èƒ½æä¾›**æ•°åå€ç”šè‡³ä¸Šç™¾å€äºCPUçš„è®¡ç®—æ•ˆç‡ï¼ˆTOPS/Wï¼‰**ï¼Œåœ¨æœ‰é™çš„è¾¹ç¼˜è®¾å¤‡åŠŸè€—é¢„ç®—å†…å®ç°é«˜æ€§èƒ½AIå¤„ç†ã€‚
- **é™ä½CPUè´Ÿè½½ï¼š** å°†ç¹é‡çš„AIè®¡ç®—ä»»åŠ¡å¸è½½ï¼ˆOffloadï¼‰åˆ°KPUæ‰§è¡Œï¼Œé‡Šæ”¾å®è´µçš„CPUèµ„æºå»å¤„ç†è®¾å¤‡æ§åˆ¶ã€é€šä¿¡ã€ç”¨æˆ·äº¤äº’ç­‰å…¶ä»–å…³é”®ä»»åŠ¡ï¼Œæå‡ç³»ç»Ÿæ•´ä½“å“åº”èƒ½åŠ›å’Œç¨³å®šæ€§ã€‚

KPUæ”¯æŒå„ç§ä¸»æµçš„ç¥ç»ç½‘ç»œæ¨¡å‹ç»“æ„ï¼Œé€‚ç”¨äºå¹¿æ³›çš„è¾¹ç¼˜è§†è§‰AIåº”ç”¨åœºæ™¯ï¼ŒåŒ…æ‹¬ä½†ä¸é™äºï¼š

- **å›¾åƒåˆ†ç±»ï¼š** è¯†åˆ«å›¾åƒä¸­çš„ç‰©ä½“ç±»åˆ«ï¼ˆå¦‚è¯†åˆ«æ°´æœç§ç±»ã€å·¥ä¸šé›¶ä»¶ï¼‰ã€‚
- **ç›®æ ‡æ£€æµ‹ï¼š** å®šä½å¹¶è¯†åˆ«å›¾åƒä¸­çš„å¤šä¸ªç›®æ ‡åŠå…¶ä½ç½®ï¼ˆå¦‚æ£€æµ‹è¡Œäººã€è½¦è¾†ã€ç¼ºé™·ï¼‰ã€‚
- **è¯­ä¹‰åˆ†å‰²ï¼š** å¯¹å›¾åƒä¸­çš„æ¯ä¸ªåƒç´ è¿›è¡Œåˆ†ç±»ï¼ˆå¦‚åŒºåˆ†é“è·¯ã€å¤©ç©ºã€å»ºç­‘ç‰©ï¼›åŒ»ç–—å›¾åƒåˆ†æï¼‰ã€‚
- **äººè„¸æ£€æµ‹ä¸è¯†åˆ«ï¼š** è®¾å¤‡ç«¯çš„äººè„¸éªŒè¯ã€é—¨ç¦è€ƒå‹¤ã€‚
- **å§¿æ€ä¼°è®¡ï¼š** åˆ†æäººä½“å…³èŠ‚ä½ç½®ï¼ˆå¦‚å¥èº«åŠ¨ä½œæŒ‡å¯¼ï¼‰ã€‚

**KPUåœ¨ç³»ç»Ÿä¸­çš„å®šä½ï¼š**

å®ƒé€šå¸¸ä½œä¸ºSoCï¼ˆSystem on Chipï¼‰ä¸­çš„ä¸€ä¸ªç‹¬ç«‹IPæ ¸å­˜åœ¨ï¼Œä¸CPUã€å†…å­˜ã€å¤–è®¾ç­‰ååŒå·¥ä½œã€‚CPUè´Ÿè´£ç³»ç»Ÿç®¡ç†ã€ä»»åŠ¡è°ƒåº¦å’Œåº”ç”¨é€»è¾‘ï¼Œè€Œå°†è®¡ç®—å¯†é›†å‹çš„AIæ¨¡å‹æ¨ç†ä»»åŠ¡é«˜æ•ˆåœ°äº¤ç»™KPUæ‰§è¡Œã€‚ä¸‹å›¾å±•ç¤ºäº†KPUåœ¨å…¸å‹è¾¹ç¼˜AI SoCä¸­çš„ä½ç½®ã€‚

![kpu_in_system](https://www.kendryte.com/api/post/attachment?id=610)

## K230 AI åº”ç”¨ç¤ºä¾‹å±•ç¤º

ä¸ºäº†å¸®åŠ©å¼€å‘è€…å¿«é€Ÿä¸Šæ‰‹å¹¶ç›´è§‚ä½“éªŒ K230 å¼ºå¤§çš„è¾¹ç¼˜ AI èƒ½åŠ›ï¼ŒCanMV K230 é•œåƒå†…ç½®äº†ä¸°å¯Œå¤šæ ·çš„ AI ç¤ºä¾‹ç¨‹åº (AI Demo)ã€‚

è¿™äº›å¼€ç®±å³ç”¨çš„ Demo æ¶µç›–äº†å•æ¨¡å‹åº”ç”¨ï¼ˆå¦‚äººè„¸æ£€æµ‹ï¼‰å’Œå¤šæ¨¡å‹åº”ç”¨ï¼ˆå¦‚æ‰‹æŒå…³é”®ç‚¹ï¼‰ä¸¤å¤§ç±»åˆ«ï¼Œç”¨æˆ·æ— éœ€ä»é›¶æ­å»ºç¯å¢ƒï¼Œå³å¯é€šè¿‡é›¶é…ç½®ã€ä¸€é”®è¿è¡Œçš„æ–¹å¼ï¼Œä½“éªŒä¸»æµ AI åŠŸèƒ½ï¼ŒåŒ…æ‹¬ä½†ä¸é™äºï¼š

- è§†è§‰åº”ç”¨ï¼š ç‰©ä½“è¯†åˆ«ã€äººè„¸æ£€æµ‹ã€æ‰‹åŠ¿è¯†åˆ«ã€äººä½“è¯†åˆ«ã€è½¦ç‰Œè¯†åˆ«ã€OCR æ–‡å­—è¯†åˆ«ã€‚
- éŸ³é¢‘åº”ç”¨ï¼š å…³é”®è¯è¯†åˆ« (KWS)ã€è¯­éŸ³åˆæˆ (TTS) ç­‰ã€‚

é€šè¿‡è¿™äº› Demoï¼Œå¼€å‘è€…å¯ä»¥å¿«é€ŸéªŒè¯æ¨¡å‹æ€§èƒ½ï¼Œç†Ÿæ‚‰ K230 çš„ AI æ¨ç†èƒ½åŠ›ï¼Œä¸ºåç»­çš„å®šåˆ¶åŒ–å¼€å‘æ‰“ä¸‹åšå®åŸºç¡€ã€‚

**è¿è¡Œæ–¹å¼ï¼š**

æ‰€æœ‰ Demo çš„æºä»£ç å‡å¼€æ”¾ã€ç»“æ„æ¸…æ™°ã€æ³¨é‡Šä¸°å¯Œï¼Œç»Ÿä¸€å­˜æ”¾åœ¨ `/CanMV/sdcard/examples/05-AI-Demo` ç›®å½•ä¸‹ã€‚ç”¨æˆ·å¯ä»¥é€šè¿‡ CanMV IDE ä¾¿æ·åœ°æ‰“å¼€ã€è¿è¡Œã€è°ƒè¯•å’Œæ·±å…¥ç ”ç©¶è¿™äº›ä»£ç ï¼Œç†è§£ API è°ƒç”¨ã€æ•°æ®å¤„ç†æµç¨‹å’Œæ¨¡å‹é›†æˆæ–¹å¼ï¼Œæå¤§åœ°åŠ é€Ÿè‡ªèº«åº”ç”¨çš„å¼€å‘è¿›ç¨‹ã€‚

**æ³¨æ„äº‹é¡¹ï¼š**

- éƒ¨åˆ† Demo å› å†…å­˜å ç”¨è¾ƒé«˜ï¼Œåœ¨ K230D èŠ¯ç‰‡ä¸Šå¯èƒ½æ— æ³•æ­£å¸¸è¿è¡Œï¼Œè¯·å‚è€ƒé€‚é…è¯´æ˜åˆ—è¡¨ä»¥é€‰æ‹©åˆé€‚çš„ç¤ºä¾‹è¿›è¡Œæµ‹è¯•ã€‚

- å…³äºK230å’ŒK230Dçš„åŒºåˆ«ï¼Œè¯·å‚è€ƒï¼š**[äº§å“ä¸­å¿ƒ](https://www.kendryte.com/zh/products)**

| Demo åç§°                | åœºæ™¯            | ä»»åŠ¡ç±»å‹   | K230 | K230D |
| ----------------------- | --------------- | ---------- | ---- | ---- |
| body_seg                | äººä½“éƒ¨ä½åˆ†å‰²    | å•æ¨¡å‹ä»»åŠ¡ | âœ… | âŒ |
| dynamic_gesture         | åŠ¨æ€æ‰‹åŠ¿è¯†åˆ«    | å¤šæ¨¡å‹ä»»åŠ¡ | âœ… | âœ… |
| eye_gaze                | æ³¨è§†ä¼°è®¡        | å¤šæ¨¡å‹ä»»åŠ¡ | âœ… | âŒ |
| face_detection          | äººè„¸æ£€æµ‹        | å•æ¨¡å‹ä»»åŠ¡ | âœ… | âœ… |
| face_landmark           | äººè„¸å…³é”®éƒ¨ä½    | å¤šæ¨¡å‹ä»»åŠ¡ | âœ… | âœ… |
| face_mesh               | äººè„¸3Dç½‘æ ¼      | å¤šæ¨¡å‹ä»»åŠ¡ | âœ… | âŒ |
| face_parse              | äººè„¸è§£æ        | å¤šæ¨¡å‹ä»»åŠ¡ | âœ… | âŒ |
| face_pose               | äººè„¸å§¿æ€        | å¤šæ¨¡å‹ä»»åŠ¡ | âœ… | âœ… |
| face_registration       | äººè„¸æ³¨å†Œ        | å¤šæ¨¡å‹ä»»åŠ¡ | âœ… | âŒ |
| face_recognition        | äººè„¸è¯†åˆ«        | å¤šæ¨¡å‹ä»»åŠ¡ | âœ… | âŒ |
| face_registration_lite  | è½»é‡äººè„¸æ³¨å†Œ     | å¤šæ¨¡å‹ä»»åŠ¡ | âœ… | âœ… |
| face_recognition_lite   | è½»é‡äººè„¸è¯†åˆ«     | å¤šæ¨¡å‹ä»»åŠ¡ | âœ… | âœ… |
| falldown_detection      | è·Œå€’æ£€æµ‹        | å•æ¨¡å‹ä»»åŠ¡ | âœ… | âœ… |
| finger_guessing         | çŒœæ‹³æ¸¸æˆ        | å¤šæ¨¡å‹ä»»åŠ¡ | âœ… | âœ… |
| hand_detection          | æ‰‹æŒæ£€æµ‹        | å•æ¨¡å‹ä»»åŠ¡ | âœ… | âœ… |
| hand_keypoint_class     | æ‰‹æŒå…³é”®ç‚¹åˆ†ç±»  | å¤šæ¨¡å‹ä»»åŠ¡ | âœ… | âœ… |
| hand_keypoint_detection | æ‰‹æŒå…³é”®ç‚¹æ£€æµ‹  | å¤šæ¨¡å‹ä»»åŠ¡ | âœ… | âœ… |
| hand_recognition        | æ‰‹åŠ¿è¯†åˆ«        | å¤šæ¨¡å‹ä»»åŠ¡ | âœ… | âœ… |
| keyword_spotting        | å…³é”®è¯å”¤é†’      | å•æ¨¡å‹ä»»åŠ¡ | âœ… | âœ… |
| multi_kws               | å¤šå‘½ä»¤å…³é”®è¯å”¤é†’ | å•æ¨¡å‹ä»»åŠ¡ | âœ… | âœ… |
| licence_det             | è½¦ç‰Œæ£€æµ‹        | å•æ¨¡å‹ä»»åŠ¡ | âœ… | âœ… |
| licence_det_rec         | è½¦ç‰Œè¯†åˆ«        | å¤šæ¨¡å‹ä»»åŠ¡ | âœ… | âœ… |
| nanotracker             | å•ç›®æ ‡è·Ÿè¸ª      | å¤šæ¨¡å‹ä»»åŠ¡ | âœ… | âœ… |
| object_detect_yolov8n   | yolov8nç›®æ ‡æ£€æµ‹ | å•æ¨¡å‹ä»»åŠ¡ | âœ… | âœ… |
| ocr_det                 | OCRæ£€æµ‹         | å•æ¨¡å‹ä»»åŠ¡ | âœ… | âŒ |
| ocr_rec                 | OCRè¯†åˆ«         | å¤šæ¨¡å‹ä»»åŠ¡ | âœ… | âŒ |
| person_detection        | äººä½“æ£€æµ‹        | å•æ¨¡å‹ä»»åŠ¡ | âœ… | âœ… |
| person_kp_detect        | äººä½“å…³é”®ç‚¹æ£€æµ‹  | å¤šæ¨¡å‹ä»»åŠ¡ | âœ… | âœ… |
| puzzle_game             | æ‹¼å›¾æ¸¸æˆ        | å¤šæ¨¡å‹ä»»åŠ¡ | âœ… | âœ… |
| segment_yolov8n         | yolov8åˆ†å‰²      | å•æ¨¡å‹ä»»åŠ¡ | âœ… | âŒ |
| self_learning           | è‡ªå­¦ä¹           | å•æ¨¡å‹ä»»åŠ¡ | âœ… | âœ… |
| space_resize            | å±€éƒ¨æ”¾å¤§å™¨      | å¤šæ¨¡å‹ä»»åŠ¡ | âœ… | âœ… |
| tts_zh                  | ä¸­æ–‡æ–‡æœ¬è½¬è¯­éŸ³  | å¤šæ¨¡å‹ä»»åŠ¡ | âœ… | âŒ |
| yolo11n_obb             | yolo11næ—‹è½¬ç›®æ ‡æ£€æµ‹| å•æ¨¡å‹ä»»åŠ¡ | âœ… |âœ… |
| yolov8n_obb             | yolov8næ—‹è½¬ç›®æ ‡æ£€æµ‹| å•æ¨¡å‹ä»»åŠ¡ | âœ… |âœ… |

## AIæ¨¡å‹æ¨ç†çš„åŸºæœ¬æµç¨‹

æŠŠè®­ç»ƒçš„AIæ¨¡å‹éƒ¨ç½²åœ¨K230ä¸Šçš„åŸºæœ¬æµç¨‹è§ä¸‹é¢çš„æµç¨‹å›¾ï¼š

![pipeline_model_deploy](https://www.kendryte.com/api/post/attachment?id=611)

ğŸ·ï¸ **æ•°æ®é‡‡é›†**:

æ•°æ®é‡‡é›†æ˜¯æŒ‡é€šè¿‡æ‘„åƒå¤´ã€éº¦å…‹é£ç­‰ä¼ æ„Ÿè®¾å¤‡æ”¶é›†åŸå§‹è¾“å…¥æ•°æ®çš„è¿‡ç¨‹ã€‚é‡‡é›†æ•°æ®çš„è´¨é‡ä¸æ•°é‡ç›´æ¥å†³å®šäº†æ¨¡å‹è®­ç»ƒä¸æ¨ç†çš„æ•ˆæœã€‚å› æ­¤ï¼Œé€‰æ‹©åˆé€‚çš„é‡‡é›†è®¾å¤‡å’Œç­–ç•¥è‡³å…³é‡è¦ã€‚

ä¸ºè·å¾—æ›´å¥½çš„éƒ¨ç½²æ•ˆæœï¼Œæ¨èä½¿ç”¨ K230 æœ¬èº«é‡‡é›†å›¾åƒæ•°æ®ï¼Œä»¥ç¡®ä¿æ•°æ®åˆ†å¸ƒæ›´è´´è¿‘å®é™…éƒ¨ç½²ç¯å¢ƒã€‚

ğŸ·ï¸ **æ•°æ®æ ‡æ³¨**:

æ•°æ®æ ‡æ³¨æ˜¯ä¸ºé‡‡é›†åˆ°çš„æ•°æ®æ·»åŠ è¯­ä¹‰æ ‡ç­¾çš„è¿‡ç¨‹ï¼Œç”¨äºç›‘ç£å­¦ä¹ æ¨¡å‹çš„è®­ç»ƒã€‚è¿™ä¸€è¿‡ç¨‹å¯ä»¥é€šè¿‡äººå·¥æ–¹å¼å®Œæˆï¼Œä¹Ÿå¯ä»¥å€ŸåŠ©æ ‡æ³¨å·¥å…·è¿›è¡ŒåŠè‡ªåŠ¨åŒ–å¤„ç†ã€‚

æ¯”å¦‚å›¾åƒåˆ†ç±»ä»»åŠ¡éœ€è¦ä¸ºæ¯å¼ å›¾åƒåˆ†é…æ­£ç¡®çš„ç±»åˆ«æ ‡ç­¾ï¼›ç›®æ ‡æ£€æµ‹ä»»åŠ¡è¦ä¸ºå›¾åƒä¸­æ¯ä¸ªç›®æ ‡æ·»åŠ è¾¹ç•Œæ¡†åŠå…¶ç±»åˆ«æ ‡ç­¾ã€‚å‡†ç¡®çš„æ ‡æ³¨å¯¹äºè®­ç»ƒå‡ºé«˜æ€§èƒ½ã€æ³›åŒ–èƒ½åŠ›å¼ºçš„æ¨¡å‹è‡³å…³é‡è¦ã€‚

ğŸ·ï¸ **æ¨¡å‹è®­ç»ƒ**:

æ¨¡å‹è®­ç»ƒé˜¶æ®µæ˜¯æ•´ä¸ª AI åº”ç”¨å¼€å‘æµç¨‹çš„é‡è¦æ­¥éª¤ä¹‹ä¸€ï¼Œå…¶ä¸»è¦ç›®æ ‡æ˜¯åˆ©ç”¨å·²æ ‡æ³¨çš„æ•°æ®é›†ï¼Œé€šè¿‡æ·±åº¦å­¦ä¹ æ–¹æ³•è®­ç»ƒå‡ºå…·æœ‰æ³›åŒ–èƒ½åŠ›çš„ç¥ç»ç½‘ç»œæ¨¡å‹ã€‚åœ¨è¿™ä¸€è¿‡ç¨‹ä¸­ï¼Œæ¨¡å‹é€šè¿‡ä¸æ–­åœ°è°ƒæ•´å†…éƒ¨å‚æ•°ï¼Œé€æ­¥æ‹Ÿåˆæ•°æ®çš„åˆ†å¸ƒç‰¹å¾ï¼Œä»¥ä¾¿åœ¨é¢å¯¹æœªè§è¿‡çš„è¾“å…¥æ•°æ®æ—¶ï¼Œä»èƒ½åšå‡ºå‡†ç¡®ä¸”ç¨³å®šçš„é¢„æµ‹ç»“æœã€‚

æ¨¡å‹è®­ç»ƒé€šå¸¸éœ€è¦ä¾æ‰˜å¤§é‡é«˜è´¨é‡çš„æ ·æœ¬æ•°æ®ï¼Œæ¶µç›–ä»»åŠ¡ç›¸å…³çš„å¤šæ ·æ€§åœºæ™¯ä¸ç±»åˆ«ã€‚æ•°æ®çš„å……åˆ†æ€§å’Œæ ‡æ³¨çš„å‡†ç¡®æ€§ç›´æ¥å½±å“æ¨¡å‹çš„å­¦ä¹ æ•ˆæœå’Œåº”ç”¨è¡¨ç°ã€‚åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œç¥ç»ç½‘ç»œæ¨¡å‹ä¼šä»è¾“å…¥æ•°æ®ä¸­æå–ç‰¹å¾ï¼Œè®¡ç®—é¢„æµ‹è¾“å‡ºï¼Œå¹¶é€šè¿‡ä¸çœŸå®æ ‡ç­¾å¯¹æ¯”äº§ç”ŸæŸå¤±ï¼ˆLossï¼‰ï¼Œå†å€ŸåŠ©åå‘ä¼ æ’­æœºåˆ¶è°ƒæ•´ç½‘ç»œä¸­çš„æƒé‡å‚æ•°ï¼Œä¸æ–­ä¼˜åŒ–æ¨¡å‹çš„æ€§èƒ½ã€‚

ä¸ºäº†å®ç°é«˜æ•ˆçš„è®­ç»ƒï¼Œå¼€å‘è€…éœ€è¦é€‰æ‹©ä¸€ä¸ªé€‚åˆå½“å‰ä»»åŠ¡çš„æ¨¡å‹ç»“æ„ï¼Œå¦‚å›¾åƒåˆ†ç±»ä¸­çš„ MobileNetã€ResNetï¼Œç›®æ ‡æ£€æµ‹ä¸­çš„ YOLO ç³»åˆ—ç­‰ã€‚æ¨¡å‹çš„é€‰æ‹©ä¸ä»…å–å†³äºç²¾åº¦è¦æ±‚ï¼Œè¿˜éœ€è€ƒè™‘æ¨ç†é€Ÿåº¦ã€æ¨¡å‹ä½“ç§¯å’Œéƒ¨ç½²å¹³å°çš„èµ„æºçº¦æŸç­‰å› ç´ ï¼Œç‰¹åˆ«æ˜¯åœ¨é¢å‘ K230 è¿™æ ·çš„è¾¹ç¼˜ AI èŠ¯ç‰‡æ—¶ï¼Œè½»é‡åŒ–æ¨¡å‹æ›´å…·å®é™…ä»·å€¼ã€‚

æ­¤å¤–ï¼Œè®­ç»ƒè¿‡ç¨‹å¾€å¾€éœ€è¦åœ¨å…·å¤‡ä¸€å®šç®—åŠ›æ”¯æŒçš„è®¡ç®—å¹³å°ï¼ˆå¦‚ GPU æœåŠ¡å™¨æˆ–æœ¬åœ°é«˜æ€§èƒ½å·¥ä½œç«™ï¼‰ä¸Šè¿›è¡Œï¼Œä»¥ä¿è¯æ¨¡å‹åœ¨åˆç†æ—¶é—´å†…å®Œæˆä¼˜åŒ–ã€‚ç°ä»£æ·±åº¦å­¦ä¹ è®­ç»ƒé€šå¸¸ä½¿ç”¨æˆç†Ÿçš„è®­ç»ƒæ¡†æ¶ï¼Œå¦‚ **PyTorch** å’Œ **TensorFlow**ï¼Œå®ƒä»¬æä¾›äº†ä¸°å¯Œçš„ç¥ç»ç½‘ç»œæ„å»ºæ¨¡å—ã€ä¼˜åŒ–å™¨ã€æŸå¤±å‡½æ•°åŠæ•°æ®å¤„ç†å·¥å…·ï¼Œæå¤§åœ°ç®€åŒ–äº†æ¨¡å‹å¼€å‘æµç¨‹ã€‚æ‚¨å¯ä»¥æ ¹æ®è‡ªèº«çš„æŠ€æœ¯èƒŒæ™¯å’Œæ¨¡å‹éœ€æ±‚ï¼Œé€‰æ‹©åˆé€‚çš„æ¡†æ¶å¼€å±•è®­ç»ƒå·¥ä½œã€‚

ğŸ·ï¸ **æ¨¡å‹è½¬æ¢å’ŒéªŒè¯**:

ç”±äºè¾¹ç¼˜è®¾å¤‡è®¡ç®—èµ„æºæœ‰é™ï¼Œä¸èƒ½ç›´æ¥éƒ¨ç½²åœ¨é«˜ç®—åŠ›å¹³å°è®­ç»ƒå¾—åˆ°çš„æ¨¡å‹ã€‚å¿…é¡»é€šè¿‡æ¨¡å‹è½¬æ¢å·¥å…·å¯¹æ¨¡å‹è¿›è¡Œä¼˜åŒ–ä¸é‡åŒ–ï¼Œç”Ÿæˆé€‚ç”¨äºç›®æ ‡ç¡¬ä»¶çš„æ¨ç†æ ¼å¼ã€‚

å¯¹äº K230 èŠ¯ç‰‡ï¼š

- ä½¿ç”¨ KPUï¼ˆKnowledge Processing Unitï¼‰ ä½œä¸ºç¥ç»ç½‘ç»œåŠ é€Ÿå•å…ƒï¼›
- æ”¯æŒçš„æ¨¡å‹æ ¼å¼ä¸º KModelï¼›
- ä½¿ç”¨ nncase ç¼–è¯‘å™¨ å°†è®­ç»ƒå¥½çš„ ONNX æˆ– TFLite æ¨¡å‹ è½¬æ¢ä¸º KModelï¼›
- è½¬æ¢è¿‡ç¨‹ä¸­ä¼šè¿›è¡Œç»“æ„ä¼˜åŒ–ä¸é‡åŒ–ï¼Œä»¥å‡å°‘æ¨¡å‹ä½“ç§¯å’Œè®¡ç®—å¤æ‚åº¦ã€‚

è½¬æ¢å®Œæˆåï¼Œè¿˜éœ€è¿›è¡ŒåŠŸèƒ½éªŒè¯ï¼Œç¡®ä¿æ¨¡å‹åœ¨ç²¾åº¦ã€å»¶è¿Ÿå’Œèµ„æºä½¿ç”¨æ–¹é¢æ»¡è¶³åº”ç”¨éœ€æ±‚ã€‚

ğŸ·ï¸ **æ¨¡å‹éƒ¨ç½²**:

éªŒè¯é€šè¿‡çš„ KModel å¯ä»¥é€šè¿‡ K230 MicroPython SDK æä¾›çš„ API åŠ è½½åˆ°è®¾å¤‡ä¸Šè¿è¡Œã€‚

éƒ¨ç½²æµç¨‹é€šå¸¸åŒ…å«ä»¥ä¸‹å‡ ä¸ªæ­¥éª¤ï¼š

- åŠ è½½kmodelï¼›
- è¯»å–å›¾åƒ/éŸ³é¢‘ç­‰è¾“å…¥æ•°æ®ï¼›
- æ‰§è¡Œæ•°æ®é¢„å¤„ç†ï¼ˆå¦‚ç¼©æ”¾ã€å½’ä¸€åŒ–ã€é€šé“æ’åˆ—ç­‰ï¼‰ï¼›
- è¿è¡Œæ¨¡å‹æ¨ç†ï¼›
- æ‰§è¡Œç»“æœåå¤„ç†ï¼ˆå¦‚åˆ†ç±»è§£ç ã€è¾¹ç•Œæ¡†è¿‡æ»¤ç­‰ï¼‰ï¼›
- ç»˜åˆ¶/è¾“å‡ºæ¨ç†ç»“æœã€‚

ä¸åŒæ¨¡å‹çš„é¢„å¤„ç†å’Œåå¤„ç†æµç¨‹å¯èƒ½ä¸åŒï¼Œéœ€æ ¹æ®å…·ä½“æ¨¡å‹æ‰‹åŠ¨é€‚é…ç›¸åº”ä»£ç é€»è¾‘ã€‚

ğŸ·ï¸ **æ¨¡å‹è°ƒä¼˜**:

éƒ¨ç½²å®Œæˆåï¼Œä»éœ€å¯¹æ¨¡å‹è¿›è¡Œæ€§èƒ½ä¸æ•ˆæœä¸Šçš„è°ƒä¼˜ï¼Œä»¥é€‚é…è¾¹ç¼˜åœºæ™¯çš„å®é™…éœ€æ±‚ã€‚ä¼˜åŒ–æªæ–½åŒ…æ‹¬ä½†ä¸é™äºï¼š

- è®¾ç½®æ›´åˆç†çš„æ¨ç†é˜ˆå€¼æˆ–è¾“å‡ºç­–ç•¥ï¼›
- è°ƒæ•´æ¨¡å‹è½¬æ¢å‚æ•°ï¼ˆå¦‚é‡åŒ–ç­–ç•¥ã€è¾“å…¥åˆ†è¾¨ç‡ï¼‰ï¼›
- æ”¹è¿›æ¨¡å‹ç»“æ„æˆ–è®­ç»ƒè¶…å‚æ•°ï¼›
- ä¸°å¯Œå¹¶ä¼˜åŒ–æ•°æ®é›†ï¼›
- ä¼˜åŒ–æ¨ç†æµç¨‹ï¼ˆå¦‚çº¿ç¨‹è°ƒåº¦ã€å†…å­˜å¤ç”¨ï¼‰ã€‚

æ¨¡å‹è°ƒä¼˜æ˜¯ä¸€ä¸ªæŒç»­è¿­ä»£çš„è¿‡ç¨‹ï¼Œæœ‰åŠ©äºæå‡ç³»ç»Ÿçš„ç¨³å®šæ€§ã€å®æ—¶æ€§ä¸èƒ½æ•ˆæ¯”ã€‚

ä»¥ä¸Šå…­ä¸ªæ­¥éª¤æ„æˆäº†åœ¨ K230 èŠ¯ç‰‡ ä¸Šå®Œæˆ AI æ¨¡å‹éƒ¨ç½²ä¸æ¨ç†çš„å®Œæ•´æµç¨‹ã€‚æ¯ä¸€æ­¥å‡éœ€ç²¾å¿ƒè®¾è®¡ä¸æ‰§è¡Œï¼Œä»¥ç¡®ä¿æœ€ç»ˆåº”ç”¨å…·å¤‡è‰¯å¥½çš„æ€§èƒ½ã€ç¨³å®šæ€§ä¸ç”¨æˆ·ä½“éªŒã€‚

## è®­ç»ƒæ¨¡å‹

```{note}
ğŸ¤– **ã€åœºæ™¯å®šä¹‰ã€‘**ï¼šåœ¨ K230 å¼€å‘æ¿ä¸Šå®ç°â€œæ‰“å°æ•°å­—çš„è¯†åˆ«ä¸å®šä½â€ã€‚

ğŸ“Œ **ä»»åŠ¡èƒŒæ™¯**ï¼š
åœ¨å¾ˆå¤š AI åº”ç”¨ä¸­ï¼Œæˆ‘ä»¬ç»å¸¸ä¼šé‡åˆ°â€œè¯†åˆ«å›¾ç‰‡é‡Œçš„æŸäº›ä¸œè¥¿â€çš„éœ€æ±‚ï¼Œæ¯”å¦‚è¯†åˆ«å›¾ç‰‡ä¸­çš„äººè„¸ã€ç‰©ä½“ï¼Œæˆ–è€…åƒæœ¬ä¾‹ä¸­è¯†åˆ«æ•°å­—ã€‚ä¸ºäº†æ›´å¥½åœ°ç†è§£ç›®æ ‡æ£€æµ‹çš„åŸºæœ¬æµç¨‹ï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€ä¸ªç®€å•çš„å°ä»»åŠ¡â€”â€”â€”â€”**è¯†åˆ«æ‰“å°çº¸ä¸Š â€œ0â€ã€â€œ1â€ã€â€œ2â€ã€â€œ3â€ è¿™å››ç§æ•°å­—ï¼Œå¹¶æ ‡å‡ºå®ƒä»¬åœ¨å›¾åƒä¸­çš„ä½ç½®**ã€‚

è¿™ä¸ªä»»åŠ¡ä¸å¤æ‚ï¼Œä½†èƒ½å®Œæ•´åœ°ç»ƒä¹ ä¸€éä»æ¨¡å‹éƒ¨ç½²åˆ°å›¾åƒå¤„ç†ã€ç»“æœæ˜¾ç¤ºçš„æ•´ä¸ªè¿‡ç¨‹ã€‚å®ƒä½œä¸ºä¸€ä¸ªå…¥é—¨æ•™ç¨‹ï¼Œå¸®åŠ©å¤§å®¶å¿«é€ŸæŒæ¡å¦‚ä½•åœ¨ K230 å¹³å°ä¸Šéƒ¨ç½² AI æ¨¡å‹ï¼Œè¿›è¡Œç›®æ ‡æ£€æµ‹ï¼Œå¹¶å°†æ£€æµ‹ç»“æœæ˜¾ç¤ºåœ¨å±å¹•ä¸Šã€‚

ğŸ¯ **é¡¹ç›®ç›®æ ‡**ï¼š
åŸºäº Kendryte K230 AI SoC å¹³å°ï¼Œå¼€å‘ä¸€ä¸ªè½»é‡çº§ã€é«˜æ€§èƒ½çš„è§†è§‰è¯†åˆ«ç¤ºä¾‹ï¼Œå®ç°ä»¥ä¸‹åŠŸèƒ½ï¼š

* âœ… **è¯†åˆ«ç±»åˆ«**ï¼šä»…è¯†åˆ«â€œ0â€ã€â€œ1â€ã€â€œ2â€ã€â€œ3â€å››ç±»æ•°å­—å­—ç¬¦ï¼›
* âœ… **è¯†åˆ«å¯¹è±¡**ï¼šæ‰“å°åœ¨çº¸å¼ ä¸Šçš„æ ‡å‡†å­—ä½“æ•°å­—ï¼›
* âœ… **å®šä½åŠŸèƒ½**ï¼šä¸ä»…è¯†åˆ«æ•°å­—ç±»åˆ«ï¼Œè¿˜èƒ½**å‡†ç¡®è·å–æ¯ä¸ªæ•°å­—åœ¨å›¾åƒä¸­çš„ä½ç½®åæ ‡**ï¼ˆæ¡†å‡ºæ£€æµ‹æ¡†ï¼‰ï¼Œä¸ºåç»­å¤„ç†æˆ–æ“ä½œæä¾›åŸºç¡€ï¼›
* âœ… **è¿è¡Œå¹³å°**ï¼šåº”ç”¨éƒ¨ç½²åœ¨ K230 å¼€å‘æ¿ï¼Œåˆ©ç”¨å…¶**AI ç¡¬ä»¶åŠ é€Ÿã€æ‘„åƒå¤´è¾“å…¥ã€å±å¹•æ˜¾ç¤ºèƒ½åŠ›**ï¼Œå®ç°ç«¯ä¾§æ¨ç†ã€å®æ—¶æ˜¾ç¤ºã€‚

ğŸ–¼ **é¢„æœŸæ•ˆæœå›¾**ï¼š

![4_number_det](https://www.kendryte.com/api/post/attachment?id=635)
```

### æ•°æ®é‡‡é›†

```{note}
ğŸ‘‰ é‡‡é›†è®­ç»ƒæ•°æ®å…¶å®å¾ˆç®€å•ï¼ä½ åªéœ€è¦å…ˆæŠŠ MicroPython å›ºä»¶çƒ§è¿›å¼€å‘æ¿ï¼Œç„¶åæ‰¾åˆ°é‚£ä¸ªè„šæœ¬â€”â€”/sdcard/examples/16-AI-Cube/DataCollectionCamera.pyï¼ŒæŠŠå®ƒæ”¹åä¸º main.pyï¼Œæ”¾åˆ° /sdcard ç›®å½•ä¸‹ã€‚æ¥ç€é‡æ–°ä¸Šç”µï¼ˆä¹Ÿå°±æ˜¯é‡å¯ä¸€ä¸‹æ¿å­ï¼‰ï¼Œè¿è¡Œèµ·æ¥åï¼ŒæŒ‰ä¸‹æ¿å­ä¸Šçš„keyæŒ‰é”®å°±å¯ä»¥å¼€å§‹é‡‡é›†å•¦ï¼æ¯æŒ‰ä¸€ä¸‹å°±æ‹ä¸€å¼ ç…§ç‰‡ï¼Œå›¾åƒä¼šè‡ªåŠ¨ä¿å­˜åˆ° /sdcard/examples/data/ æ–‡ä»¶å¤¹é‡Œï¼Œå®Œå…¨ä¸ç”¨ä½ ç®¡ï¼Œè¶…çœå¿ƒï¼
```

åœ¨è®­ç»ƒæ¨¡å‹ä¹‹å‰ï¼Œæ•°æ®é‡‡é›†æ˜¯æ•´ä¸ªæµç¨‹ä¸­çš„ç¬¬ä¸€æ­¥ï¼Œä¹Ÿæ˜¯è‡³å…³é‡è¦çš„ä¸€æ­¥ã€‚é«˜è´¨é‡çš„æ•°æ®ä¸ä»…èƒ½æå‡æ¨¡å‹çš„æ€§èƒ½ï¼Œè¿˜èƒ½å¢å¼ºæ¨¡å‹åœ¨å®é™…åº”ç”¨åœºæ™¯ä¸­çš„æ³›åŒ–èƒ½åŠ›ã€‚æ ¹æ®ä¸åŒçš„åº”ç”¨éœ€æ±‚ï¼Œæ•°æ®é‡‡é›†å¯ä»¥åˆ†ä¸º**é€šç”¨åœºæ™¯**å’Œ**ä¸“ç”¨åœºæ™¯**ä¸¤ç§æƒ…å†µï¼Œä¸‹é¢å°†åˆ†åˆ«è¿›è¡Œè¯¦ç»†è¯´æ˜ã€‚

ğŸ“Œ **é€šç”¨åœºæ™¯ä¸‹çš„æ•°æ®é‡‡é›†**

åœ¨é€šç”¨äººå·¥æ™ºèƒ½ä»»åŠ¡ä¸­ï¼Œå¦‚å›¾åƒåˆ†ç±»ã€ç›®æ ‡æ£€æµ‹ã€è¯­ä¹‰åˆ†å‰²ç­‰ï¼Œé€šå¸¸å¯ä»¥å€ŸåŠ©å·²æœ‰çš„å…¬å¼€æ•°æ®é›†æ¥æ„å»ºè®­ç»ƒæ ·æœ¬ã€‚è¿™äº›æ•°æ®é›†ç”±å­¦æœ¯æœºæ„ã€ç ”ç©¶ç»„ç»‡æˆ–å¤§å‹ä¼ä¸šæ•´ç†å‘å¸ƒï¼Œå…·æœ‰è‰¯å¥½çš„æ ‡æ³¨è´¨é‡å’Œå¹¿æ³›çš„åº”ç”¨åŸºç¡€ã€‚

æ¯”å¦‚ï¼Œå¸¸è§å›¾åƒç±»å…¬å¼€æ•°æ®é›†åŒ…æ‹¬ï¼šImageNetã€COCOã€MNISTã€Fashion-MNISTã€CIFARç³»åˆ—ç­‰ï¼Œæˆ–è€…å¯»æ‰¾ç½‘ç»œä¸Šå¯¹åº”åœºæ™¯çš„å¼€æºæ•°æ®é›†ã€‚

è™½ç„¶å…¬å¼€æ•°æ®é›†è´¨é‡è¾ƒé«˜ï¼Œä½†åœ¨å®é™…ä½¿ç”¨å‰ä»éœ€è¿›è¡Œé€‚å½“çš„ç­›é€‰ä¸å¤„ç†ï¼Œä»¥ç¡®ä¿å…¶ç¬¦åˆé¡¹ç›®éœ€æ±‚ï¼š

- **è´¨é‡ä¿è¯å¤„ç†**ï¼šå»é™¤æ¨¡ç³Šã€é”™è¯¯æ ‡æ³¨æˆ–ä½è´¨é‡æ ·æœ¬ã€‚
- **ç±»åˆ«å¹³è¡¡**ï¼šç¡®ä¿å„ç±»åˆ«æ ·æœ¬æ•°é‡å‡è¡¡ï¼Œé¿å…æ¨¡å‹åå‘ã€‚
- **æ ¼å¼ç»Ÿä¸€**ï¼šå°†æ•°æ®è½¬æ¢ä¸ºç»Ÿä¸€æ ¼å¼ï¼ˆå¦‚JPEGã€PNGç­‰ï¼‰ã€‚
- **æ•°æ®æ‰©å¢**ï¼šé€šè¿‡æ—‹è½¬ã€è£å‰ªã€ç¿»è½¬ã€æ·»åŠ å™ªå£°ç­‰æ–¹å¼æ‰©å……æ•°æ®é‡ï¼Œæé«˜æ¨¡å‹é²æ£’æ€§ã€‚
- **æ„å»ºå®šåˆ¶åŒ–æ•°æ®é›†**ï¼šæœ‰æ—¶å•ä¸€æ•°æ®é›†å¯èƒ½æ— æ³•æ»¡è¶³ç‰¹å®šéœ€æ±‚ï¼Œå¯ä»¥é€šè¿‡ç»„åˆå¤šä¸ªæ•°æ®é›†å¹¶è¿›è¡Œé‡æ–°æ ‡æ³¨å’Œæ¸…æ´—ï¼Œæ„å»ºæ›´ç¬¦åˆä¸šåŠ¡åœºæ™¯çš„å®šåˆ¶åŒ–æ•°æ®é›†ã€‚

ğŸ“Œ **ä¸“ç”¨åœºæ™¯ä¸‹çš„æ•°æ®é‡‡é›†**

å¯¹äºä¸€äº›ç‰¹æ®Šè¡Œä¸šæˆ–å…·ä½“åº”ç”¨åœºæ™¯ï¼ˆå¦‚å·¥ä¸šè´¨æ£€ã€å†œä¸šç›‘æµ‹ã€å®‰é˜²ç›‘æ§ã€åŒ»ç–—è¯Šæ–­ç­‰ï¼‰ï¼Œå¾€å¾€éœ€è¦é‡‡é›†ä¸“ç”¨äºè¯¥åœºæ™¯çš„æ•°æ®ã€‚è¿™ç§æƒ…å†µä¸‹ï¼Œå…¬å¼€æ•°æ®é›†å¯èƒ½æ— æ³•å‡†ç¡®åæ˜ çœŸå®ç¯å¢ƒçš„æ•°æ®åˆ†å¸ƒï¼Œå› æ­¤éœ€è¦è¿›è¡Œ**å®šåˆ¶åŒ–æ•°æ®é‡‡é›†**ã€‚

åœ¨æŸäº›ç‰¹å®šçš„AIéƒ¨ç½²åœºæ™¯ä¸­ï¼Œæœ‰æ¡ä»¶çš„æƒ…å†µä¸‹å¯ä»¥ç›´æ¥**ä½¿ç”¨K230è®¾å¤‡**è¿›è¡Œæ•°æ®é‡‡é›†ã€‚è¿™æ ·**é‡‡é›†çš„æ•°æ®æ›´è´´è¿‘å®é™…éƒ¨ç½²ç¯å¢ƒï¼Œæœ‰åŠ©äºæå‡æ¨¡å‹åœ¨è®¾å¤‡ä¸Šçš„è¡¨ç°**ã€‚

âš ï¸ è¿™é‡Œç»™å‡ºä¸€äº›æ•°æ®é‡‡é›†æµç¨‹å»ºè®®ï¼š

- **æ˜ç¡®é‡‡é›†ç›®æ ‡**ï¼šå®šä¹‰é‡‡é›†å¯¹è±¡ï¼ˆå¦‚ç‰©ä½“ç±»å‹ã€åœºæ™¯ï¼‰ã€å…‰ç…§æ¡ä»¶ã€è§’åº¦ã€åˆ†è¾¨ç‡ç­‰ã€‚
- **æ˜ç¡®æ•°æ®ä»»åŠ¡**ï¼šä¸åŒçš„ä»»åŠ¡å¯¹æ•°æ®é›†çš„è¦æ±‚ä¸åŒï¼Œä¸€æ–¹é¢è¦è€ƒè™‘å®é™…éƒ¨ç½²åœºæ™¯ï¼Œå¦ä¸€æ–¹é¢è¦è€ƒè™‘ä»»åŠ¡éœ€æ±‚ï¼Œæ¯”å¦‚åˆ†ç±»ä»»åŠ¡å¯èƒ½éœ€è¦ç‰©ä½“å æ®è¾ƒå¤§çš„åŒºåŸŸï¼Œå¤§ç‰‡çš„èƒŒæ™¯å¯èƒ½ä¼šå½±å“åˆ†ç±»æ•ˆæœï¼›è€Œç›®æ ‡æ£€æµ‹å¯ä»¥æœ‰å¤§å°ä¸åŒçš„å¤šä¸ªç‰©ä½“ã€‚
- **ä½¿ç”¨åˆé€‚å·¥å…·**ï¼šä½¿ç”¨K230å¼€å‘æ¿é…åˆæ‘„åƒå¤´æ¨¡å—ï¼Œå¯ç¼–å†™è„šæœ¬è‡ªåŠ¨é‡‡é›†ã€‚
- **åŒæ­¥æ ‡æ³¨ä¿¡æ¯**ï¼šåœ¨é‡‡é›†è¿‡ç¨‹ä¸­å°½é‡åŒæ­¥è®°å½•æ ‡ç­¾ä¿¡æ¯ï¼Œä¾¿äºåæœŸæ ‡æ³¨ã€‚
- **åˆæ­¥è´¨é‡æ£€æŸ¥**ï¼šå‰”é™¤æ¨¡ç³Šã€æ›å…‰è¿‡åº¦ã€é®æŒ¡ä¸¥é‡ç­‰æ— æ•ˆæ ·æœ¬ã€‚
  
### æ•°æ®æ ‡æ³¨

```{note}
ğŸ‘‰ æ‹¿åˆ°é‡‡é›†å¥½çš„å›¾ç‰‡ä¹‹åï¼Œå°±å¯ä»¥å¼€å§‹ç»™å®ƒä»¬æ‰“æ ‡ç­¾å•¦ï¼æ ¹æ®è¿™ä¸ªä»»åŠ¡çš„è¦æ±‚ï¼Œä½ å¯ä»¥ç”¨ä¸€äº›å¸¸è§çš„æ ‡æ³¨å·¥å…·ï¼Œæ¯”å¦‚ LabelImgã€Labelme æˆ– X-AnyLabelingï¼Œç»™å›¾ç‰‡é‡Œçš„æ•°å­—åŠ ä¸Šå¯¹åº”çš„ç±»åˆ«ã€ç”»å‡ºç›®æ ‡æ¡†ã€‚ä½ å¯ä»¥äº²è‡ªé‡‡é›†å›¾åƒã€è‡ªå·±åŠ¨æ‰‹æ ‡æ³¨ï¼Œæ•´ä¸ªè¿‡ç¨‹ä¹ŸæŒºæœ‰è¶£çš„ã€‚å½“ç„¶å•¦ï¼Œå¦‚æœä½ ä¸æƒ³ä»å¤´åšï¼Œæˆ‘ä»¬ä¹Ÿè´´å¿ƒå‡†å¤‡äº†ä¸€ä»½ç°æˆçš„â€œ0/1/2/3å››ç±»æ‰“å°æ•°å­—è¯†åˆ«â€æ•°æ®é›†ï¼Œç›´æ¥ç‚¹è¿™é‡Œå°±èƒ½ä¸‹è½½ï¼š[0/1/2/3å››ç±»æ‰“å°æ•°å­—è¯†åˆ«æ•°æ®é›†](https://kendryte-download.canaan-creative.com/developer/k230/yolo_dataset/number_det.zip)ã€‚çœæ—¶åˆçœåŠ›ï¼Œç›´æ¥ä¸Šæ‰‹è®­ç»ƒä¹Ÿæ²¡é—®é¢˜ï¼
```

æ•°æ®æ ‡æ³¨æ˜¯è®­ç»ƒæ¨¡å‹çš„å…³é”®æ­¥éª¤ä¹‹ä¸€ï¼Œå®ƒæ¶‰åŠåˆ°å¯¹åŸå§‹æ•°æ®è¿›è¡Œæ ‡æ³¨ï¼Œä»¥ä¾¿æ¨¡å‹èƒ½å¤Ÿå­¦ä¹ åˆ°æ•°æ®çš„ç‰¹å¾å’Œæ¨¡å¼ã€‚åœ¨è¿›è¡Œæ•°æ®æ ‡æ³¨æ—¶ï¼Œéœ€è¦è€ƒè™‘ä»¥ä¸‹å‡ ä¸ªæ–¹é¢ï¼š

- **æ ‡æ³¨æ ¼å¼**ï¼šé€‰æ‹©é€‚åˆæ¨¡å‹çš„æ ‡æ³¨æ ¼å¼ï¼Œå¦‚XMLã€JSONã€TXTç­‰ã€‚
- **æ ‡æ³¨å·¥å…·**ï¼šé€‰æ‹©é€‚åˆçš„æ ‡æ³¨å·¥å…·ï¼Œå¦‚LabelImgã€Labelmeã€X-AnyLabelingã€VIAç­‰ã€‚
- **æ ‡æ³¨è´¨é‡**ï¼šç¡®ä¿æ ‡æ³¨çš„å‡†ç¡®æ€§å’Œä¸€è‡´æ€§ï¼Œé¿å…æ ‡æ³¨é”™è¯¯ã€‚
- **æ ‡æ³¨ç­–ç•¥**ï¼šæ ¹æ®ä»»åŠ¡éœ€æ±‚å’Œæ•°æ®ç‰¹ç‚¹ï¼Œé€‰æ‹©åˆé€‚çš„æ ‡æ³¨ç­–ç•¥ï¼Œå¦‚è¾¹ç•Œæ¡†æ ‡æ³¨ã€å…³é”®ç‚¹æ ‡æ³¨ç­‰ã€‚

å…³äºå¸¸è§çš„è§†è§‰ä»»åŠ¡ï¼Œè¿™é‡Œæ¨èä½¿ç”¨X-AnyLabelingè¿›è¡Œæ ‡æ³¨ã€‚ä¸‹è½½é“¾æ¥: [X-AnyLabeling-release](https://github.com/CVHub520/X-AnyLabeling/releases)ã€‚
  
### æ¨¡å‹è®­ç»ƒ

```{note}
ğŸ‘‰ æ¨¡å‹è®­ç»ƒçš„æ–¹æ³•æœ‰å¾ˆå¤šï¼Œå…¶ä¸­ YOLO ç³»åˆ—æ˜¯ç°åœ¨ç‰¹åˆ«å¸¸ç”¨çš„é€‰æ‹©ï¼Œæ¯”å¦‚ YOLOv5ã€YOLOv8 æˆ– YOLO11ã€‚æˆ‘ä»¬æ¨èä½ ç”¨ YOLO æ¥è¿›è¡Œè®­ç»ƒï¼Œå› ä¸ºå®ƒæ•ˆæœå¥½ã€é€Ÿåº¦å¿«ã€ç¤¾åŒºä¹Ÿå¾ˆæ´»è·ƒã€‚æ›´æ£’çš„æ˜¯ï¼Œæˆ‘ä»¬æä¾›çš„æ•°æ®é›†å·²ç»æ•´ç†å¥½äº†ï¼Œå¯ä»¥ç›´æ¥ç”¨æ¥è®­ç»ƒ YOLO æ¨¡å‹ï¼ä½ åªéœ€è¦è·³è½¬åˆ°è¿™ä¸ªç¤ºä¾‹ï¼š[YOLOæ£€æµ‹ç¤ºä¾‹](#yolov8è·Œå€’æ£€æµ‹)ï¼ŒæŒ‰ç…§é‡Œé¢çš„æµç¨‹æ¥åšï¼ŒæŠŠç¤ºä¾‹ä¸­çš„æ•°æ®é›†éƒ¨åˆ†æ¢æˆæˆ‘ä»¬å‡†å¤‡çš„â€œ0/1/2/3 å››ç±»æ‰“å°æ•°å­—è¯†åˆ«æ•°æ®é›†â€å°±è¡Œå•¦ã€‚æœ¬èŠ‚çš„ç›®æ ‡æ˜¯å…ˆæŠŠæ¨¡å‹è®­ç»ƒå¥½ï¼Œå¹¶å¯¼å‡ºä¸º ONNX æ ¼å¼ï¼Œåé¢è¿˜æœ‰æ›´å¤šæœ‰è¶£çš„å†…å®¹ç­‰ç€ä½ ç»§ç»­è§£é”ï¼
```

æ¨¡å‹è®­ç»ƒæ˜¯æ•´ä¸ªAIæµç¨‹ä¸­æœ€é‡è¦çš„ä¸€æ­¥ï¼Œå®ƒæ¶‰åŠåˆ°æ¨¡å‹çš„æ„å»ºã€è®­ç»ƒå’Œä¼˜åŒ–ã€‚åœ¨è¿›è¡Œæ¨¡å‹è®­ç»ƒæ—¶ï¼Œéœ€è¦è€ƒè™‘ä»¥ä¸‹å‡ ä¸ªæ–¹é¢ï¼š

- **æ¨¡å‹é€‰æ‹©**ï¼šæ ¹æ®ä»»åŠ¡éœ€æ±‚å’Œæ•°æ®ç‰¹ç‚¹ï¼Œé€‰æ‹©é€‚åˆçš„æ¨¡å‹ã€‚
- **æ¨¡å‹æ„å»º**ï¼šæ„å»ºæ¨¡å‹çš„ç½‘ç»œç»“æ„ï¼ŒåŒ…æ‹¬è¾“å…¥å±‚ã€éšè—å±‚å’Œè¾“å‡ºå±‚ã€‚
- **æ¨¡å‹è®­ç»ƒ**ï¼šä½¿ç”¨æ ‡æ³¨å¥½çš„æ•°æ®è¿›è¡Œæ¨¡å‹è®­ç»ƒï¼ŒåŒ…æ‹¬é€‰æ‹©åˆé€‚çš„æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨ã€‚
- **æ¨¡å‹è¯„ä¼°**ï¼šä½¿ç”¨æµ‹è¯•é›†å¯¹æ¨¡å‹è¿›è¡Œè¯„ä¼°ï¼Œè¯„ä¼°æ¨¡å‹çš„æ€§èƒ½å’Œæ³›åŒ–èƒ½åŠ›ã€‚
- **æ¨¡å‹ä¼˜åŒ–**ï¼šæ ¹æ®æ¨¡å‹è¯„ä¼°ç»“æœï¼Œå¯¹æ¨¡å‹è¿›è¡Œä¼˜åŒ–ï¼Œæé«˜æ¨¡å‹çš„æ€§èƒ½å’Œæ³›åŒ–èƒ½åŠ›ã€‚

è®­ç»ƒå¥½çš„æ¨¡å‹éœ€è¦è½¬æ¢æˆonnxæ¨¡å‹æˆ–è€…tfliteæ¨¡å‹ï¼Œå‡†å¤‡åç»­ä½¿ç”¨nncaseè¿›è¡Œæ¨¡å‹è½¬æ¢ï¼Œå¾—åˆ°å¯ä»¥åœ¨K230ä¸Šæ¨ç†çš„kmodelã€‚

## æ¨¡å‹è½¬æ¢

å½“æˆ‘ä»¬è®­ç»ƒç»“æŸåï¼Œä¼šå¾—åˆ°ä¸€ä¸ª ONNX æ¨¡å‹æ–‡ä»¶ã€‚ä½†è¿™ä¸ªæ¨¡å‹è¿˜ä¸èƒ½ç›´æ¥åœ¨ K230 ä¸Šç”¨ KPU æ¥è·‘ï¼Œå› ä¸º KPU åªæ”¯æŒ Kmodel æ ¼å¼ã€‚

æ‰€ä»¥æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬è¦ç”¨ä¸€ä¸ªå« nncase çš„ç¼–è¯‘å™¨ï¼ŒæŠŠ ONNX æ¨¡å‹â€œç¿»è¯‘â€æˆ Kmodelï¼Œè¿™æ · KPU æ‰èƒ½ç†è§£å¹¶è¿è¡Œå®ƒã€‚

ä¸‹é¢æˆ‘ä»¬å°±æ¥ç®€å•è®¤è¯†ä¸€ä¸‹è¿™ä¸ªå…³é”®å·¥å…· â€”â€” nncaseï¼

### ä»€ä¹ˆæ˜¯ nncase

#### nncase ç®€ä»‹

`nncase` æ˜¯ä¸€æ¬¾ä¸“ä¸º AI åŠ é€Ÿå™¨è®¾è®¡çš„**ç¥ç»ç½‘ç»œç¼–è¯‘å™¨**ï¼Œç›®å‰å·²æ”¯æŒçš„åç«¯ï¼ˆtargetï¼‰åŒ…æ‹¬ï¼š**CPUã€K210ã€K510ã€K230** ç­‰å¹³å°ã€‚

**nncase æä¾›çš„æ ¸å¿ƒåŠŸèƒ½**

- æ”¯æŒ **å¤šè¾“å…¥å¤šè¾“å‡º** çš„ç½‘ç»œç»“æ„ï¼Œå…¼å®¹å¸¸è§çš„ **å¤šåˆ†æ”¯æ¨¡å‹æ‹“æ‰‘**ï¼›
- é‡‡ç”¨ **é™æ€å†…å­˜åˆ†é…** ç­–ç•¥ï¼Œæ— éœ€ä¾èµ–è¿è¡Œæ—¶å †å†…å­˜ï¼Œèµ„æºå ç”¨å¯æ§ï¼›
- å®ç° **ç®—å­èåˆä¸å›¾ä¼˜åŒ–**ï¼Œæœ‰æ•ˆå‡å°‘å†—ä½™è®¡ç®—ï¼Œæå‡æ¨ç†æ•ˆç‡ï¼›
- æ”¯æŒ **æµ®ç‚¹ï¼ˆfloatï¼‰æ¨ç†** å’Œ **å®šç‚¹é‡åŒ–æ¨ç†ï¼ˆuint8/int8ï¼‰**ï¼›
- æ”¯æŒ **è®­ç»ƒåé‡åŒ–ï¼ˆPost-Training Quantization, PTQï¼‰**ï¼Œå¯åŸºäºæµ®ç‚¹æ¨¡å‹å’Œæ ¡å‡†æ•°æ®é›†ç”Ÿæˆé«˜æ•ˆçš„é‡åŒ–æ¨¡å‹ï¼›
- ç¼–è¯‘ç”Ÿæˆçš„æ¨¡å‹ä¸º**å¹³å¦ç»“æ„ï¼ˆFlat Modelï¼‰**ï¼Œå…·å¤‡ **é›¶æ‹·è´åŠ è½½ï¼ˆZero-Copy Loadingï¼‰** èƒ½åŠ›ï¼Œé€‚åˆèµ„æºå—é™çš„åµŒå…¥å¼åœºæ™¯ã€‚

**æ”¯æŒçš„æ¨¡å‹æ ¼å¼**

nncase æ”¯æŒä»ä¸»æµæ·±åº¦å­¦ä¹ æ¡†æ¶å¯¼å‡ºçš„ä»¥ä¸‹æ¨¡å‹æ ¼å¼ï¼š

- **TFLiteï¼ˆTensorFlow Liteï¼‰**
- **ONNXï¼ˆOpen Neural Network Exchangeï¼‰**

æ‚¨å¯ä»¥ä½¿ç”¨ PyTorchã€TensorFlow ç­‰è®­ç»ƒæ¡†æ¶å¯¼å‡ºæ¨¡å‹è‡³ä¸Šè¿°æ ¼å¼ï¼Œå†é€šè¿‡ nncase è½¬æ¢ä¸º KModelï¼Œä»¥éƒ¨ç½²è‡³ K230 ç­‰è®¾å¤‡ã€‚

**æ¶æ„æ¦‚è§ˆ**

![nncaseæ¶æ„](https://www.kendryte.com/api/post/attachment?id=509)

nncase çš„è½¯ä»¶æ ˆä¸»è¦åŒ…æ‹¬ä»¥ä¸‹ä¸¤å¤§ç»„æˆéƒ¨åˆ†ï¼š

- **Compilerï¼ˆç¼–è¯‘å™¨ï¼‰**ï¼šå°†é«˜å±‚æ¡†æ¶å¯¼å‡ºçš„ TFLite æˆ– ONNX æ¨¡å‹ï¼Œè½¬æ¢ä¸ºé€‚ç”¨äºç›®æ ‡ç¡¬ä»¶å¹³å°çš„ KModel æ ¼å¼ï¼Œå¹¶æ‰§è¡Œç»“æ„ä¼˜åŒ–ã€ç®—å­è°ƒåº¦ä¸é‡åŒ–å¤„ç†ï¼›
- **Runtimeï¼ˆè¿è¡Œæ—¶ï¼‰**ï¼šåœ¨ç›®æ ‡è®¾å¤‡ï¼ˆå¦‚ K230ï¼‰ä¸ŠåŠ è½½å¹¶è¿è¡Œ KModelï¼Œç»“åˆç¡¬ä»¶åŠ é€Ÿå•å…ƒï¼ˆå¦‚ KPUï¼‰å®ç°é«˜æ€§èƒ½æ¨¡å‹æ¨ç†ã€‚

ğŸ·ï¸ **Compiler**: ç”¨äºåœ¨PCä¸Šç¼–è¯‘ç¥ç»ç½‘ç»œæ¨¡å‹ï¼Œæœ€ç»ˆç”Ÿæˆkmodelæ–‡ä»¶ã€‚ä¸»è¦åŒ…æ‹¬importer, IR, Evaluator, Quantize, Transformä¼˜åŒ–, Tiling, Partition, Schedule, Codegenç­‰æ¨¡å—ã€‚

- Importer: å°†å…¶å®ƒç¥ç»ç½‘ç»œæ¡†æ¶çš„æ¨¡å‹å¯¼å…¥åˆ°nncaseä¸­ï¼›
- IR: ä¸­é—´è¡¨ç¤º, åˆ†ä¸ºimporterå¯¼å…¥çš„Neutral IR(è®¾å¤‡æ— å…³)å’ŒNeutral IRç»loweringè½¬æ¢ç”Ÿæˆçš„Target IR(è®¾å¤‡ç›¸å…³)ï¼›
- Evaluator: Evaluatoræä¾›IRçš„è§£é‡Šæ‰§è¡Œèƒ½åŠ›ï¼Œå¸¸è¢«ç”¨äºConstant Folding/PTQ Calibrationç­‰åœºæ™¯ï¼›
- Transform: ç”¨äºIRè½¬æ¢å’Œå›¾çš„éå†ä¼˜åŒ–ç­‰ï¼›
- Quantize: è®­ç»ƒåé‡åŒ–, å¯¹è¦é‡åŒ–çš„tensoråŠ å…¥é‡åŒ–æ ‡è®°, æ ¹æ®è¾“å…¥çš„æ ¡æ­£é›†, è°ƒç”¨ Evaluatorè¿›è¡Œè§£é‡Šæ‰§è¡Œ, æ”¶é›†tensorçš„æ•°æ®èŒƒå›´, æ’å…¥é‡åŒ–/åé‡åŒ–ç»“ç‚¹, æœ€åä¼˜åŒ–æ¶ˆé™¤ä¸å¿…è¦çš„é‡åŒ–/åé‡åŒ–ç»“ç‚¹ç­‰ï¼›
- Tiling: å—é™äºNPUè¾ƒä½çš„å­˜å‚¨å™¨å®¹é‡ï¼Œéœ€è¦å°†å¤§å—è®¡ç®—è¿›è¡Œæ‹†åˆ†ã€‚å¦å¤–ï¼Œè®¡ç®—å­˜åœ¨å¤§é‡æ•°æ®å¤ç”¨æ—¶é€‰æ‹©Tilingå‚æ•°ä¼šå¯¹æ—¶å»¶å’Œå¸¦å®½äº§ç”Ÿå½±å“ï¼›
- Partition: å°†å›¾æŒ‰ModuleTypeè¿›è¡Œåˆ‡åˆ†, åˆ‡åˆ†åçš„æ¯ä¸ªå­å›¾ä¼šå¯¹åº”RuntimeModule, ä¸åŒç±»å‹çš„RuntimeModuleå¯¹åº”ä¸åŒçš„Device(CPU/K230)ï¼›
- Schedule: æ ¹æ®ä¼˜åŒ–åå›¾ä¸­çš„æ•°æ®ä¾èµ–å…³ç³»ç”Ÿæˆè®¡ç®—é¡ºåºå¹¶åˆ†é…Bufferï¼›
- Codegen: å¯¹æ¯ä¸ªå­å›¾åˆ†åˆ«è°ƒç”¨ModuleTypeå¯¹åº”çš„codegenï¼Œç”ŸæˆRuntimeModuleï¼›

ğŸ·ï¸ **Runtime**: é›†æˆäºç”¨æˆ·åº”ç”¨ç¨‹åºï¼ˆAppï¼‰ä¸­ï¼Œæä¾›æ¨¡å‹åŠ è½½ã€è¾“å…¥è®¾ç½®ã€æ¨ç†æ‰§è¡Œå’Œè¾“å‡ºè¯»å–ç­‰åŠŸèƒ½ã€‚Runtime æ¥å£å±è”½äº†åº•å±‚ç¡¬ä»¶å·®å¼‚ï¼Œä½¿å¼€å‘è€…èƒ½æ›´ä¸“æ³¨äºæ¨¡å‹æ¨ç†é€»è¾‘çš„é›†æˆä¸åº”ç”¨å¼€å‘ã€‚

æ¨¡å‹è½¬æ¢ç« èŠ‚ä¸»è¦ä»‹ç»nncase compilerå’Œsimulatorçš„ä½¿ç”¨æ–¹æ³•ã€‚

#### å®‰è£… nncase ç¯å¢ƒ

- **Linux ç¯å¢ƒæ­å»º nncase**

é¦–å…ˆï¼Œè¯·å®‰è£… `.NET SDK 7.0` å¹¶é…ç½® `DOTNET_ROOT` ç¯å¢ƒå˜é‡ã€‚**è¯·æ³¨æ„ï¼Œä¸å»ºè®®åœ¨ Anaconda è™šæ‹Ÿç¯å¢ƒä¸­å®‰è£… `dotnet`ï¼Œå¦åˆ™å¯èƒ½å¯¼è‡´å…¼å®¹æ€§é—®é¢˜ã€‚**

```bash
sudo apt-get update
sudo apt-get install dotnet-sdk-7.0
export DOTNET_ROOT=/usr/share/dotnet
```

æ¥ä¸‹æ¥ï¼Œé€šè¿‡ pip å®‰è£… `nncase` å’Œ `nncase-kpu`ï¼š

```bash
pip install nncase nncase-kpu
```

- **Windows ç¯å¢ƒæ­å»º nncase**

é¦–å…ˆå®‰è£… [.NET SDK 7.0](https://learn.microsoft.com/zh-cn/dotnet/core/install/windows)ï¼Œè¯·æ ¹æ® Microsoft å®˜æ–¹æ–‡æ¡£å®Œæˆå®‰è£…æµç¨‹ã€‚
å®‰è£… `nncase` åº“ã€‚å¯é€šè¿‡ pip åœ¨çº¿å®‰è£…ä¸»ç¨‹åº `nncase`ï¼Œå¹¶ä» [GitHub Releases é¡µé¢](https://github.com/kendryte/nncase/releases) ä¸‹è½½å¯¹åº”ç‰ˆæœ¬çš„ `nncase_kpu`ï¼Œå†ä½¿ç”¨ pip ç¦»çº¿å®‰è£…ã€‚

```bash
pip install nncase
# è¯·å°† `2.x.x` æ›¿æ¢ä¸ºå®é™…ä¸‹è½½ç‰ˆæœ¬å·ã€‚
pip install nncase_kpu-2.x.x-py2.py3-none-win_amd64.whl
```

- **ä½¿ç”¨ Docker æ­å»ºç¯å¢ƒ**

å¦‚æœæ‚¨æœªé…ç½® Ubuntu æœ¬åœ°ç¯å¢ƒï¼Œå¯ç›´æ¥ä½¿ç”¨å®˜æ–¹æä¾›çš„ `nncase` Docker é•œåƒã€‚è¯¥é•œåƒåŸºäº Ubuntu 20.04ï¼Œé¢„è£…äº† Python 3.8 å’Œ dotnet-sdk-7.0ï¼Œæ–¹ä¾¿å¿«é€Ÿå¯åŠ¨ã€‚

```bash
cd /path/to/nncase_sdk
docker pull ghcr.io/kendryte/k230_sdk
docker run -it --rm -v `pwd`:/mnt -w /mnt ghcr.io/kendryte/k230_sdk /bin/bash
```

- **æŸ¥çœ‹ nncase ç‰ˆæœ¬ä¿¡æ¯**

è¿›å…¥ Python äº¤äº’ç¯å¢ƒåå¯é€šè¿‡å¦‚ä¸‹å‘½ä»¤ç¡®è®¤å½“å‰å®‰è£…çš„ `nncase` ç‰ˆæœ¬ï¼š

```python
>>> import _nncase
>>> print(_nncase.__version__)
2.9.0
```

> ç¤ºä¾‹è¾“å‡ºä¸º `2.9.0`ï¼Œè¯·ä»¥å®é™…å®‰è£…ç‰ˆæœ¬ä¸ºå‡†ã€‚

### ä½¿ç”¨ nncase ç¼–è¯‘å™¨è½¬æ¢kmodel

![compile_kmodel](https://www.kendryte.com/api/post/attachment?id=636)

ç¼–è¯‘kmodelçš„æµç¨‹ä¸»è¦åŒ…å«ä»¥ä¸‹å…³é”®æ­¥éª¤ï¼Œæ¯ä¸ªæ­¥éª¤éƒ½æœ‰å…¶ç‰¹å®šçš„ç›®çš„å’ŒæŠ€æœ¯è€ƒé‡ï¼š

**è®¾ç½®ç¼–è¯‘é€‰é¡¹**ï¼šè¿™ä¸€æ­¥çš„æ ¸å¿ƒç›®çš„æ˜¯ä¸ºæ¨¡å‹éƒ¨ç½²é€‚é…ç›®æ ‡ç¡¬ä»¶å¹³å°ã€‚ç”±äºè¾¹ç¼˜è®¡ç®—è®¾å¤‡éœ€è¦æ˜ç¡®æŒ‡å®šè¿è¡Œå¹³å°ä»¥ç¡®ä¿ç”Ÿæˆçš„kmodelæ˜¯å¦éœ€è¦åˆ©ç”¨ç¡¬ä»¶ï¼ˆkpuï¼‰åŠ é€Ÿã€‚åŒæ—¶ï¼Œé…ç½®é¢„å¤„ç†å‚æ•°ï¼ˆå¦‚è¾“å…¥æ ‡å‡†åŒ–å‚æ•°ï¼‰åˆ°kmodelå†…éƒ¨å¯å‡å°‘æ¨ç†æ—¶çš„è®¡ç®—å¼€é”€ï¼Œæå‡æ•´ä½“æ•ˆç‡ã€‚

**åˆå§‹åŒ–ç¼–è¯‘å™¨**ï¼šnncaseç¼–è¯‘å™¨çš„åˆå§‹åŒ–æ˜¯ä¸ºåç»­è½¬æ¢å·¥ä½œæ„å»ºæ ‡å‡†åŒ–ç¯å¢ƒã€‚ç¼–è¯‘å™¨æ ¹æ®å‰è¿°é…ç½®çš„ç¼–è¯‘é€‰é¡¹å®Œæˆåˆå§‹åŒ–è¿‡ç¨‹ã€‚

**å¯¼å…¥åŸå§‹æ¨¡å‹**ï¼šå½“å‰ä¸»æµè®­ç»ƒæ¡†æ¶ï¼ˆå¦‚TensorFlow/PyTorchï¼‰ç”Ÿæˆçš„ONNX/TFLiteæ¨¡å‹åŒ…å«é€šç”¨è¿ç®—ç¬¦ï¼Œä½†KPUä½œä¸ºä¸“ç”¨åŠ é€Ÿå™¨éœ€è¦ç‰¹å®šç®—å­æ ¼å¼ã€‚æ­¤æ­¥éª¤é€šè¿‡æ¨¡å‹è§£æå’Œç®—å­è½¬æ¢ï¼Œå°†åŸå§‹æ¨¡å‹è½¬åŒ–ä¸ºç¼–è¯‘å™¨å¯ä¼˜åŒ–çš„ä¸­é—´è¡¨ç¤ºï¼Œä¸ºåç»­ç¡¬ä»¶ç›¸å…³ä¼˜åŒ–å¥ å®šåŸºç¡€ã€‚

**é‡åŒ–å¤„ç†**ï¼šè¿™æ˜¯æå‡è¾¹ç¼˜ä¾§æ¨ç†æ€§èƒ½çš„å…³é”®ç¯èŠ‚ã€‚æˆ‘ä»¬è®­ç»ƒå¾—åˆ°çš„FP32æ¨¡å‹è™½ç²¾åº¦é«˜ä½†å­˜åœ¨è®¡ç®—å»¶è¿Ÿå¤§ã€å†…å­˜å ç”¨é«˜ç­‰é—®é¢˜ã€‚é€šè¿‡é‡åŒ–åˆ°INT8/INT16ï¼šæ˜¾è‘—å‡å°‘æ¨¡å‹ä½“ç§¯ï¼Œæå‡è®¡ç®—é€Ÿåº¦ï¼ˆåˆ©ç”¨ç¡¬ä»¶å®šç‚¹åŠ é€ŸæŒ‡ä»¤ï¼‰ï¼Œé™ä½åŠŸè€—ï¼ˆå‡å°‘å†…å­˜å¸¦å®½éœ€æ±‚ï¼‰ã€‚éœ€æ³¨æ„çš„æ˜¯ï¼Œé‡åŒ–ä¼šå¼•å…¥ç²¾åº¦æŸå¤±ï¼Œå› æ­¤éœ€è¦é€šè¿‡æ ¡å‡†æ•°æ®é›†å¸®åŠ©æ¨¡å‹ç¡®å®šåœ¨é‡åŒ–è¿‡ç¨‹ä¸­æ¯ä¸€å±‚æƒé‡å’Œæ¿€æ´»å€¼åº”è¯¥è¢«æ˜ å°„åˆ°çš„èŒƒå›´ï¼Œä»¥ä¾¿ä¿ç•™æ›´å¤šçš„ä¿¡æ¯ï¼Œå‡å°‘é‡åŒ–è¯¯å·®ã€‚é‡åŒ–è¿‡ç¨‹éœ€è¦é…ç½®é‡åŒ–å‚æ•°å’Œæ ¡å‡†æ•°æ®ï¼Œé‡åŒ–å‚æ•°è§[ç¼–è¯‘å‚æ•°è¯´æ˜](#ç¼–è¯‘å‚æ•°è¯´æ˜)ã€‚

**ç¼–è¯‘ç”Ÿæˆkmodel**ï¼šåœ¨å‰è¿°ä¼˜åŒ–åŸºç¡€ä¸Šï¼Œæœ€ç»ˆç”Ÿæˆçš„kmodelæ˜¯ç»è¿‡æ·±åº¦ä¼˜åŒ–çš„å¯ç›´æ¥éƒ¨ç½²åˆ°K230è®¾å¤‡æ‰§è¡Œé«˜æ•ˆæ¨ç†ã€‚

#### è½¬æ¢ç¤ºä¾‹

æˆ‘ä»¬å°±ä»¥**å››ç±»æ‰“å°æ•°å­—è¯†åˆ«**åœºæ™¯ä¸ºä¾‹ï¼Œå°†ä¸Šé¢å¾—åˆ°çš„ONNXæ¨¡å‹è½¬æ¢æˆKmodelã€‚è¿™é‡Œç»™å‡ºç¼–è¯‘ç¤ºä¾‹è„šæœ¬ï¼š

```python
# å¯¼å…¥æ‰€éœ€åº“
import os
import argparse
import numpy as np
from PIL import Image  # ç”¨äºå›¾åƒè¯»å–å’Œå¤„ç†
import onnxsim         # ONNX æ¨¡å‹ç®€åŒ–å·¥å…·
import onnx            # ONNX æ¨¡å‹å¤„ç†å·¥å…·
import nncase          # nncase ç¼–è¯‘å™¨ SDK
import shutil
import math

def parse_model_input_output(model_file, input_shape):
    # åŠ è½½ONNXæ¨¡å‹
    onnx_model = onnx.load(model_file)
    
    # è·å–æ¨¡å‹ä¸­æ‰€æœ‰è¾“å…¥èŠ‚ç‚¹åç§°
    input_all = [node.name for node in onnx_model.graph.input]
    
    # è·å–æ¨¡å‹ä¸­å·²ç»è¢«åˆå§‹åŒ–çš„å‚æ•°ï¼ˆå¦‚æƒé‡ç­‰ï¼‰ï¼Œè¿™äº›ä¸å±äºè¾“å…¥æ•°æ®
    input_initializer = [node.name for node in onnx_model.graph.initializer]
    
    # çœŸå®è¾“å…¥ = æ‰€æœ‰è¾“å…¥ - åˆå§‹åŒ–å™¨
    input_names = list(set(input_all) - set(input_initializer))
    
    # ä»å›¾ä¸­æå–çœŸå®è¾“å…¥å¼ é‡
    input_tensors = [node for node in onnx_model.graph.input if node.name in input_names]

    # æå–è¾“å…¥å¼ é‡çš„åç§°ã€æ•°æ®ç±»å‹ã€å½¢çŠ¶ç­‰ä¿¡æ¯
    inputs = []
    for _, e in enumerate(input_tensors):
        onnx_type = e.type.tensor_type
        input_dict = {}
        input_dict['name'] = e.name
        # è½¬æ¢ä¸ºNumPyæ•°æ®ç±»å‹
        input_dict['dtype'] = onnx.mapping.TENSOR_TYPE_TO_NP_TYPE[onnx_type.elem_type]
        # å¦‚æœæŸç»´ä¸º0ï¼Œè¯´æ˜ONNXæ¨¡å‹æœªå›ºå®šshapeï¼Œä½¿ç”¨ä¼ å…¥çš„input_shapeä»£æ›¿
        input_dict['shape'] = [(i.dim_value if i.dim_value != 0 else d) for i, d in zip(onnx_type.shape.dim, input_shape)]
        inputs.append(input_dict)

    return onnx_model, inputs

def onnx_simplify(model_file, dump_dir, input_shape):
    # è·å–æ¨¡å‹å’Œè¾“å…¥å½¢çŠ¶ä¿¡æ¯
    onnx_model, inputs = parse_model_input_output(model_file, input_shape)

    # è‡ªåŠ¨æ¨æ–­ç¼ºå¤±çš„shapeä¿¡æ¯
    onnx_model = onnx.shape_inference.infer_shapes(onnx_model)

    # æ„é€ ç”¨äºonnxsimçš„è¾“å…¥shapeæ˜ å°„
    input_shapes = {input['name']: input['shape'] for input in inputs}

    # ç®€åŒ–æ¨¡å‹
    onnx_model, check = onnxsim.simplify(onnx_model, input_shapes=input_shapes)
    assert check, "æ¨¡å‹ç®€åŒ–æ ¡éªŒå¤±è´¥"

    # ä¿å­˜ç®€åŒ–åçš„æ¨¡å‹
    model_file = os.path.join(dump_dir, 'simplified.onnx')
    onnx.save_model(onnx_model, model_file)
    return model_file

def read_model_file(model_file):
    with open(model_file, 'rb') as f:
        model_content = f.read()
    return model_content

def generate_data(shape, batch, calib_dir):
    # è·å–æ•°æ®é›†ä¸­çš„æ‰€æœ‰å›¾ç‰‡è·¯å¾„
    img_paths = [os.path.join(calib_dir, p) for p in os.listdir(calib_dir)]
    data = []

    for i in range(batch):
        assert i < len(img_paths), "æ ¡å‡†å›¾ç‰‡æ•°é‡ä¸è¶³"

        # åŠ è½½å›¾ç‰‡ï¼Œè½¬æ¢ä¸ºRGBæ ¼å¼
        img_data = Image.open(img_paths[i]).convert('RGB')

        # æŒ‰æ¨¡å‹è¾“å…¥å°ºå¯¸è¿›è¡Œç¼©æ”¾
        img_data = img_data.resize((shape[3], shape[2]), Image.BILINEAR)

        # è½¬æ¢ä¸ºNumPyæ•°ç»„
        img_data = np.asarray(img_data, dtype=np.uint8)

        # è½¬æ¢ä¸º NCHW æ ¼å¼
        img_data = np.transpose(img_data, (2, 0, 1))

        # å¢åŠ batchç»´åº¦
        data.append([img_data[np.newaxis, ...]])

    return np.array(data)

def main():
    # å‘½ä»¤è¡Œå‚æ•°å®šä¹‰
    parser = argparse.ArgumentParser(prog="nncase")
    parser.add_argument("--target", default="k230", type=str, help='ç¼–è¯‘ç›®æ ‡ï¼Œä¾‹å¦‚k230æˆ–cpu')
    parser.add_argument("--model", type=str, help='è¾“å…¥ONNXæ¨¡å‹è·¯å¾„')
    parser.add_argument("--dataset_path", type=str, help='PTQæ ¡å‡†æ•°æ®é›†è·¯å¾„')
    parser.add_argument("--input_width", type=int, default=320, help='æ¨¡å‹è¾“å…¥å®½åº¦')
    parser.add_argument("--input_height", type=int, default=320, help='æ¨¡å‹è¾“å…¥é«˜åº¦')
    parser.add_argument("--ptq_option", type=int, default=0, help='PTQé€‰é¡¹ï¼š0-5')

    args = parser.parse_args()

    # è¾“å…¥å°ºå¯¸å‘ä¸Šå¯¹é½åˆ°32çš„æ•´æ•°å€ï¼Œç¬¦åˆç¡¬ä»¶è¦æ±‚
    input_width = int(math.ceil(args.input_width / 32.0)) * 32
    input_height = int(math.ceil(args.input_height / 32.0)) * 32
    input_shape = [1, 3, input_height, input_width]  # NCHWæ ¼å¼

    # åˆ›å»ºä¸´æ—¶ç›®å½•ä¿å­˜ä¸­é—´æ¨¡å‹
    dump_dir = 'tmp'
    if not os.path.exists(dump_dir):
        os.makedirs(dump_dir)

    # ç®€åŒ–æ¨¡å‹
    model_file = onnx_simplify(args.model, dump_dir, input_shape)

    # ç¼–è¯‘é€‰é¡¹è®¾ç½®
    compile_options = nncase.CompileOptions()
    compile_options.target = args.target                  # æŒ‡å®šç›®æ ‡å¹³å°
    compile_options.preprocess = True                     # å¯ç”¨é¢„å¤„ç†
    compile_options.swapRB = False                        # ä¸äº¤æ¢RBé€šé“
    compile_options.input_shape = input_shape             # è®¾ç½®è¾“å…¥å½¢çŠ¶
    compile_options.input_type = 'uint8'                  # è¾“å…¥å›¾åƒæ•°æ®ç±»å‹
    compile_options.input_range = [0, 1]                  # è¾“å…¥å›¾åƒåé‡åŒ–èŒƒå›´
    compile_options.mean = [0, 0, 0]                      # é¢„å¤„ç†å‡å€¼
    compile_options.std = [1, 1, 1]                       # æ ‡å‡†å·®è®¾ä¸º1ï¼Œä¸è¿›è¡Œå½’ä¸€åŒ–
    compile_options.input_layout = "NCHW"                 # è¾“å…¥æ•°æ®æ ¼å¼

    # åˆå§‹åŒ–ç¼–è¯‘å™¨
    compiler = nncase.Compiler(compile_options)

    # å¯¼å…¥ONNXæ¨¡å‹ä¸ºIR
    model_content = read_model_file(model_file)
    import_options = nncase.ImportOptions()
    compiler.import_onnx(model_content, import_options)

    # PTQé€‰é¡¹è®¾ç½®ï¼ˆåè®­ç»ƒé‡åŒ–ï¼‰
    ptq_options = nncase.PTQTensorOptions()
    ptq_options.samples_count = 10  # æ ¡å‡†æ ·æœ¬æ•°é‡

    # æ”¯æŒ6ç§é‡åŒ–æ–¹æ¡ˆï¼ˆæ ¹æ®ç²¾åº¦ä¸æ€§èƒ½æƒè¡¡é€‰æ‹©ï¼‰
    if args.ptq_option == 0:
        ptq_options.calibrate_method = 'NoClip'
        ptq_options.quant_type = 'uint8'
        ptq_options.w_quant_type = 'uint8'
    elif args.ptq_option == 1:
        ptq_options.calibrate_method = 'NoClip'
        ptq_options.quant_type = 'uint8'
        ptq_options.w_quant_type = 'int16'
    elif args.ptq_option == 2:
        ptq_options.calibrate_method = 'NoClip'
        ptq_options.quant_type = 'int16'
        ptq_options.w_quant_type = 'uint8'
    elif args.ptq_option == 3:
        ptq_options.calibrate_method = 'Kld'
        ptq_options.quant_type = 'uint8'
        ptq_options.w_quant_type = 'uint8'
    elif args.ptq_option == 4:
        ptq_options.calibrate_method = 'Kld'
        ptq_options.quant_type = 'uint8'
        ptq_options.w_quant_type = 'int16'
    elif args.ptq_option == 5:
        ptq_options.calibrate_method = 'Kld'
        ptq_options.quant_type = 'int16'
        ptq_options.w_quant_type = 'uint8'

    # è®¾ç½®PTQæ ¡å‡†æ•°æ®
    ptq_options.set_tensor_data(generate_data(input_shape, ptq_options.samples_count, args.dataset_path))

    # åº”ç”¨PTQ
    compiler.use_ptq(ptq_options)

    # ç¼–è¯‘æ¨¡å‹
    compiler.compile()

    # å¯¼å‡ºKModelæ–‡ä»¶
    base, ext = os.path.splitext(args.model)
    kmodel_name = base + ".kmodel"
    with open(kmodel_name, 'wb') as f:
        f.write(compiler.gencode_tobytes())

# Pythonç¨‹åºä¸»å…¥å£
if __name__ == '__main__':
    main()
```

å°†ä¸Šè¿°ä»£ç ä¿å­˜ä¸º`to_kmodel.py`è„šæœ¬ï¼Œä½¿ç”¨å¦‚ä¸‹è½¬æ¢å‘½ä»¤å®Œæˆç¼–è¯‘ï¼š

```shell
# ä½ éœ€è¦å°†onnxæ¨¡å‹æ¢æˆä½ è®­ç»ƒå¥½çš„æ¨¡å‹
python to_kmodel.py --target k230 --model best.onnx --dataset_path test --input_width 320 --input_height 320 --ptq_option 0
```

é€šè¿‡ä¸Šé¢çš„ä»£ç ï¼Œæˆ‘ä»¬å·²ç»æˆåŠŸæ‹¿åˆ°äº†ç”¨äºè¯†åˆ«å››ç±»æ•°å­—çš„ Kmodel æ¨¡å‹ã€‚é‚£ä¹ˆä½ å¯èƒ½ä¼šå¥½å¥‡ï¼šåœ¨æŠŠæ¨¡å‹è½¬æ¢æˆ Kmodel çš„è¿‡ç¨‹ä¸­ï¼Œé‡Œé¢ç”¨åˆ°çš„é‚£äº›å‚æ•°åˆ°åº•æ˜¯å•¥æ„æ€ï¼Ÿå¦‚æœä»¥åæˆ‘æƒ³æ¢ä¸ªæ¨¡å‹æ¥è½¬ï¼Œæ˜¯ä¸æ˜¯ä¹Ÿè¦æ”¹å‚æ•°å‘¢ï¼Ÿåˆ«ç€æ€¥ï¼Œæ¥ä¸‹æ¥çš„ç« èŠ‚æˆ‘ä»¬å°±ä¼šå¸¦ä½ ææ‡‚è¿™äº›è½¬æ¢å‚æ•°çš„å…·ä½“å«ä¹‰ï¼Œè¿˜ä¼šæ•™ä½ åœ¨è½¬æ¢å…¶ä»–æ¨¡å‹æ—¶è¯¥æ€ä¹ˆæ­£ç¡®é…ç½®ï¼Œä¸€æ­¥æ­¥å¸¦ä½ ä¸Šæ‰‹ï¼Œä¸è¿·è·¯ï¼

#### ç¼–è¯‘å‚æ•°è¯´æ˜

ä½¿ç”¨ `nncase compiler` å°† `tflite/onnx` æ¨¡å‹è½¬æ¢æˆ `kmodel` ï¼Œæ¨¡å‹è½¬æ¢ä»£ç çš„å…³é”®åœ¨äºæ ¹æ®è‡ªèº«éœ€æ±‚è¿›è¡Œé€‰é¡¹é…ç½®ï¼Œä¸»è¦æ˜¯ `CompileOptions` ã€ `PTQTensorOptions` å’Œ `ImportOptions`ã€‚

`nncase` ç”¨æˆ·æŒ‡å—æ–‡æ¡£è§ï¼š[github: user_guide](https://github.com/kendryte/nncase/tree/master/examples/user_guide) æˆ– [gitee: user_guide](https://gitee.com/kendryte/nncase/tree/master/examples/user_guide) ã€‚

- **ç¼–è¯‘é€‰é¡¹ CompileOptions**

`CompileOptions` ç±», ç”¨äºé…ç½® `nncase` ç¼–è¯‘é€‰é¡¹ï¼Œå„å±æ€§è¯´æ˜å¦‚ä¸‹ï¼š

| å±æ€§åç§°                    |         ç±»å‹          | æ˜¯å¦å¿…é¡» | æè¿°                                                                                                                   |
| :-------------------------- | :-------------------: | :------: | ---------------------------------------------------------------------------------------------------------------------- |
| target                      |        string         |    æ˜¯    | æŒ‡å®šç¼–è¯‘ç›®æ ‡, å¦‚'cpu', 'k230'                                                                                          |
| dump_ir                     |         bool          |    å¦    | æŒ‡å®šæ˜¯å¦dump IR, é»˜è®¤ä¸ºFalse                                                                                           |
| dump_asm                    |         bool          |    å¦    | æŒ‡å®šæ˜¯å¦dump asmæ±‡ç¼–æ–‡ä»¶, é»˜è®¤ä¸ºFalse                                                                                  |
| dump_dir                    |        string         |    å¦    | å‰é¢æŒ‡å®šdump_irç­‰å¼€å…³å, è¿™é‡ŒæŒ‡å®šdumpçš„ç›®å½•, é»˜è®¤ä¸º""                                                                  |
| input_file                  |        string         |    å¦    | ONNXæ¨¡å‹è¶…è¿‡2GBæ—¶ï¼Œç”¨äºæŒ‡å®šå‚æ•°æ–‡ä»¶è·¯å¾„ï¼Œé»˜è®¤ä¸º""                                                                      |
| preprocess                  |         bool          |    å¦    | æ˜¯å¦å¼€å¯å‰å¤„ç†ï¼Œé»˜è®¤ä¸ºFalseã€‚ä»¥ä¸‹å‚æ•°ä»…åœ¨ `preprocess=True`æ—¶ç”Ÿæ•ˆ                                                      |
| input_type                  |        string         |    å¦    | å¼€å¯å‰å¤„ç†æ—¶æŒ‡å®šè¾“å…¥æ•°æ®ç±»å‹ï¼Œé»˜è®¤ä¸º"float"ã€‚å½“ `preprocess`ä¸º `True`æ—¶ï¼Œå¿…é¡»æŒ‡å®šä¸º"uint8"æˆ–è€…"float32"                |
| input_shape                 |       list[int]       |    å¦    | å¼€å¯å‰å¤„ç†æ—¶æŒ‡å®šè¾“å…¥æ•°æ®çš„shapeï¼Œé»˜è®¤ä¸º[]ã€‚å½“ `preprocess`ä¸º `True`æ—¶ï¼Œå¿…é¡»æŒ‡å®š                                        |
| input_range                 |      list[float]      |    å¦    | å¼€å¯å‰å¤„ç†æ—¶æŒ‡å®šè¾“å…¥æ•°æ®åé‡åŒ–åçš„æµ®ç‚¹æ•°èŒƒå›´ï¼Œé»˜è®¤ä¸º[ ]ã€‚å½“ `preprocess`ä¸º `True`ä¸” `input_type`ä¸º `uint8`æ—¶ï¼Œå¿…é¡»æŒ‡å®š |
| input_layout                |        string         |    å¦    | æŒ‡å®šè¾“å…¥æ•°æ®çš„layoutï¼Œé»˜è®¤ä¸º""                                                                                         |
| swapRB                      |         bool          |    å¦    | æ˜¯å¦åœ¨ `channel`ç»´åº¦åè½¬æ•°æ®ï¼Œé»˜è®¤ä¸ºFalse                                                                              |
| mean                        |      list[float]      |    å¦    | å‰å¤„ç†æ ‡å‡†åŒ–å‚æ•°å‡å€¼ï¼Œé»˜è®¤ä¸º[0,0,0]                                                                                    |
| std                         |      list[float]      |    å¦    | å‰å¤„ç†æ ‡å‡†åŒ–å‚æ•°æ–¹å·®ï¼Œé»˜è®¤ä¸º[1,1,1]                                                                                    |
| letterbox_value             |         float         |    å¦    | æŒ‡å®šå‰å¤„ç†letterboxçš„å¡«å……å€¼ï¼Œé»˜è®¤ä¸º0                                                                                   |
| output_layout               |        string         |    å¦    | æŒ‡å®šè¾“å‡ºæ•°æ®çš„layout, é»˜è®¤ä¸º""                                                                                         |
| shape_bucket_enable         |         bool          |    æ˜¯    | æ˜¯å¦å¼€å¯ShapeBucketåŠŸèƒ½ï¼Œé»˜è®¤ä¸ºFalseã€‚åœ¨ `dump_ir=True`æ—¶ç”Ÿæ•ˆ                                                          |
| shape_bucket_range_info     | Dict[str, [int, int]] |    æ˜¯    | æ¯ä¸ªè¾“å…¥shapeç»´åº¦ä¿¡æ¯ä¸­çš„å˜é‡çš„èŒƒå›´ï¼Œæœ€å°å€¼å¿…é¡»å¤§äºç­‰äº1                                                               |
| shape_bucket_segments_count |          int          |    æ˜¯    | è¾“å…¥å˜é‡çš„èŒƒå›´åˆ’åˆ†ä¸ºå‡ æ®µ                                                                                               |
| shape_bucket_fix_var_map    |    Dict[str, int]     |    å¦    | å›ºå®šshapeç»´åº¦ä¿¡æ¯ä¸­çš„å˜é‡ä¸ºç‰¹å®šçš„å€¼|

å…³äºå‰å¤„ç†çš„é…ç½®è¯´æ˜ï¼Œè¯·å‚è€ƒ API æ–‡æ¡£ï¼š[nncase æ¨¡å‹ç¼–è¯‘APIæ‰‹å†Œå‰å¤„ç†æµç¨‹](https://www.kendryte.com/k230_rtos/zh/main/api_reference/nncase/nncase_compile.html#id2)ã€‚å°†éƒ¨åˆ†å‰å¤„ç†æ“ä½œå°è£…åœ¨æ¨¡å‹å†…å¯ä»¥æé«˜å¼€å‘æ¿æ¨ç†æ—¶çš„å‰å¤„ç†æ•ˆç‡ï¼Œæ”¯æŒçš„å‰å¤„ç†åŒ…æ‹¬ï¼š`swapRB`(RGB->BGR or BGR->RGB)ã€`Transpose`(NHWC->NCHW or NCHW->NHWC)ã€`Normalization`ï¼ˆå‡å‡å€¼é™¤æ–¹å·®ï¼‰ã€`Dequantize`ç­‰ã€‚æ¯”å¦‚ï¼šonnxæ¨¡å‹éœ€è¦çš„è¾“å…¥æ˜¯`RGB`çš„ï¼Œæˆ‘ä»¬ä½¿ç”¨`opencv`è¯»å–çš„å›¾ç‰‡æ˜¯`BGR`ï¼Œæ­£å¸¸onnxæ¨¡å‹æ¨ç†çš„é¢„å¤„ç†æˆ‘ä»¬éœ€è¦å…ˆå°†`BGR`è½¬æˆ`RGB`ç»™onnxæ¨¡å‹ä½¿ç”¨ã€‚è½¬kmodelçš„æ—¶å€™æˆ‘ä»¬å°±å¯ä»¥è®¾ç½® `swapRB` ä¸º `True` ï¼Œè¿™æ ·kmodelä¸­è‡ªå¸¦äº¤æ¢`RB`é€šé“çš„é¢„å¤„ç†æ­¥éª¤ï¼Œåœ¨è¿›è¡Œkmodelæ¨ç†çš„é¢„å¤„ç†æ—¶ï¼Œæˆ‘ä»¬å°±å¯ä»¥å¿½ç•¥äº¤æ¢`RB`é€šé“çš„æ­¥éª¤ï¼Œå°†æ­¤æ­¥éª¤æ”¾åˆ°kmodelå†…éƒ¨ã€‚

- **å¯¼å…¥é€‰é¡¹ ImportOptions**

ImportOptionsç±», ç”¨äºé…ç½®nncaseå¯¼å…¥é€‰é¡¹ï¼Œé…ç½®ç¼–è¯‘å™¨çš„å¾…è½¬æ¢æ¨¡å‹ã€‚å¯ä»¥é…ç½® `tflite/onnx`ã€‚ä½¿ç”¨ç¤ºä¾‹å¦‚ä¸‹ï¼š

```python
# è¯»å–å¹¶å¯¼å…¥tfliteæ¨¡å‹
model_content = read_model_file(model)
compiler.import_tflite(model_content, import_options)

# è¯»å–å¹¶å¯¼å…¥onnxæ¨¡å‹
model_content = read_model_file(model)
compiler.import_onnx(model_content, import_options)
```

- **è®­ç»ƒåé‡åŒ–é€‰é¡¹ PTQTensorOptions**

`PTQTensorOptions` ç±», ç”¨äºé…ç½® `nncase PTQ` é€‰é¡¹ï¼š

| åç§°                           | ç±»å‹   | æ˜¯å¦å¿…é¡» | æè¿° |
| ------------------------------ | ------ | -------- | ---- |
| samples_count                  | int    |    å¦    |  æŒ‡å®šç”¨äºé‡åŒ–çš„æ ¡æ­£é›†æ•°é‡    |
| calibrate_method               | string |    å¦    |  æŒ‡å®šé‡åŒ–æ–¹æ³•ï¼Œå¯é€‰'NoClip'ã€'Kld'ï¼Œé»˜è®¤ä¸º'Kld'   |
| finetune_weights_method        | string |    å¦    |  æŒ‡å®šæ˜¯å¦å¯¹æƒé‡è¿›è¡Œå¾®è°ƒï¼Œå¯é€‰'NoFineTuneWeights'ã€'UseSquant'ï¼Œé»˜è®¤ä¸º'NoFineTuneWeights'  |
| quant_type                     | string |    å¦    |  æŒ‡å®šæ•°æ®é‡åŒ–ç±»å‹ï¼Œå¯é€‰'uint8'ï¼Œ'int8'ï¼Œ'int16'ï¼Œ`quant_type`å’Œ`w_quant_type`ä¸¤ç§ç±»å‹ä¸å¯åŒæ—¶ä¸º'int16'  |
| w_quant_type                   | string |    å¦    |  æŒ‡å®šæƒé‡é‡åŒ–ç±»å‹ï¼Œå¯é€‰'uint8'ï¼Œ'int8'ï¼Œ'int16'ï¼Œ`quant_type`å’Œ`w_quant_type`ä¸¤ç§ç±»å‹ä¸å¯åŒæ—¶ä¸º'int16' |
| quant_scheme                   | string |    å¦    |  å¯¼å…¥é‡åŒ–å‚æ•°é…ç½®æ–‡ä»¶çš„è·¯å¾„ |
| quant_scheme_strict_mode       | bool   |    å¦    |  æ˜¯å¦ä¸¥æ ¼æŒ‰ç…§quant_schemeæ‰§è¡Œé‡åŒ–  |
| export_quant_scheme            | bool   |    å¦    |  æ˜¯å¦å¯¼å‡ºé‡åŒ–å‚æ•°é…ç½®æ–‡ä»¶  |
| export_weight_range_by_channel | bool   |    å¦    |  æ˜¯å¦å¯¼å‡º `bychannel`å½¢å¼çš„weightsé‡åŒ–å‚æ•°ï¼Œè¯¥å‚æ•°å»ºè®®è®¾ç½®ä¸º `True`  |

æ··åˆé‡åŒ–å…·ä½“ä½¿ç”¨æµç¨‹è§ [MixQuantè¯´æ˜](https://github.com/kendryte/nncase/blob/release/2.0/docs/MixQuant.md)ã€‚

å…³äºé‡åŒ–çš„é…ç½®è¯´æ˜ï¼Œè¯·å‚è€ƒä¸Šè¡¨ã€‚å¦‚æœè½¬æ¢çš„kmodelè¾¾ä¸åˆ°æ•ˆæœï¼Œå¯ä»¥ä¿®æ”¹ `quant_type` å’Œ `w_quant_type` å‚æ•°ï¼Œä¿®æ”¹æ¨¡å‹æ•°æ®å’Œæƒé‡çš„é‡åŒ–ç±»å‹ï¼Œä½†æ˜¯è¿™ä¸¤ä¸ªå‚æ•°ä¸èƒ½åŒæ—¶è®¾ç½®ä¸º `int16`ã€‚

- **é‡åŒ–æ ¡æ­£é›†è®¾ç½®**

| åç§° | ç±»å‹                  | æè¿°           |
| ---- | --------------------- | -------------- |
| data | List[List[np.ndarray]] | è¯»å–çš„æ ¡å‡†æ•°æ® |

é‡åŒ–è¿‡ç¨‹ä¸­ä½¿ç”¨çš„æ ¡æ­£æ•°æ®é€šè¿‡ `set_tensor_data` æ–¹æ³•è¿›è¡Œè®¾ç½®ï¼Œæ¥å£å‚æ•°ç±»å‹ä¸º `List[List[np.ndarray]]`ï¼Œæ¯”å¦‚ï¼šæ¨¡å‹æœ‰ä¸€ä¸ªè¾“å…¥ï¼Œæ ¡æ­£æ•°æ®é‡è®¾ç½®ä¸º10ï¼Œä¼ å…¥çš„æ ¡æ­£æ•°æ®ç»´åº¦ä¸º `[10,1,3,320,320]`ï¼›å¦‚æœæ¨¡å‹æœ‰ä¸¤ä¸ªè¾“å…¥ï¼Œæ ¡æ­£æ•°æ®é‡è®¾ç½®ä¸º10ï¼Œä¼ å…¥çš„æ ¡æ­£æ•°æ®ç»´åº¦ä¸º `[[10,1,3,224,224],[10,1,3,320,320]]`ã€‚

### ä½¿ç”¨ nncase æ¨¡æ‹Ÿå™¨éªŒè¯è½¬æ¢æ•ˆæœ

å‰é¢æˆ‘ä»¬è¯´äº†æ€ä¹ˆæŠŠæ¨¡å‹è½¬æ¢æˆ Kmodelï¼Œç°åœ¨æˆ‘ä»¬è¦æ¥â€œä½“æ£€â€ä¸€ä¸‹è¿™ä¸ªæ¨¡å‹ï¼Œçœ‹å®ƒè½¬å¾—å¥½ä¸å¥½ï¼

å› ä¸º ONNX å’Œ Kmodel åœ¨é¢„å¤„ç†çš„æ—¶å€™å¯èƒ½ä¸å¤ªä¸€æ ·ï¼Œæ‰€ä»¥æˆ‘ä»¬å¾—åˆ†åˆ«æŒ‰å®ƒä»¬å„è‡ªçš„è¦æ±‚æ¥å‡†å¤‡è¾“å…¥æ•°æ®ã€‚ç„¶åï¼Œç”¨ ONNX æ¨¡å‹å’Œ Kmodel æ¨¡å‹å„è·‘ä¸€éæ¨ç†ï¼ŒæŠŠç»“æœéƒ½ä¿å­˜ä¸‹æ¥ï¼Œæ¥ç€ç®—ä¸€ä¸‹å®ƒä»¬ä¹‹é—´çš„ **Cosine ç›¸ä¼¼åº¦**â€”â€”è¿™å°±åƒæ˜¯åœ¨å¯¹æ¯”å®ƒä¿©è¾“å‡ºçš„â€œç›¸ä¼¼åº¦â€ã€‚

ä¸€å¥è¯æ€»ç»“å°±æ˜¯ï¼šæˆ‘ä»¬è¦çœ‹çœ‹è½¬æ¢åçš„ Kmodel å’ŒåŸæ¥çš„ ONNX æ¨¡å‹ï¼Œè¾“å‡ºå·®ä¸å¤šä¸ï¼Ÿå¦‚æœç›¸å·®å¤ªå¤§ï¼Œè¯´æ˜è½¬æ¢è¿‡ç¨‹ä¸­å¯èƒ½æœ‰é—®é¢˜ï¼Œé‚£å°±è¦å›å¤´æ£€æŸ¥å‚æ•°è®¾ç½®ï½

æ¨¡å‹è½¬æ¢æˆåŠŸåï¼Œå¯ä»¥ä½¿ç”¨`nncase.Simulator` åœ¨æœ¬åœ°PCä¸ŠåŠ è½½Kmodelè¿›è¡Œæ¨ç†ï¼Œé€šè¿‡è®¡ç®—onnxæ¨¡å‹å’Œkmodelæ¨¡å‹çš„ä½™å¼¦ç›¸ä¼¼åº¦åˆ¤æ–­kmodelè¾“å‡ºæ˜¯å¦æ­£ç¡®ã€‚**è¿™é‡Œéœ€è¦æ³¨æ„çš„æ˜¯ï¼Œè¯¥è¿‡ç¨‹æ˜¯åœ¨æœ¬åœ°è®¡ç®—æœºä¸Šè¿è¡Œçš„ï¼Œè€Œä¸æ˜¯åœ¨k230å¼€å‘æ¿ä¸Šè¿è¡Œçš„ã€‚**

é¦–å…ˆéœ€è¦åœ¨pythonç¯å¢ƒä¸‹å®‰è£…onnxç›¸å…³çš„åŒ…ï¼š

```shell
pip install onnx
pip install onnxruntime
pip install onnxsim
```

æ‰§è¡Œæ¨¡æ‹Ÿå™¨æ¨ç†è„šæœ¬éœ€è¦æ·»åŠ nncaseæ’ä»¶ç¯å¢ƒå˜é‡ï¼š

- **linux**ï¼š

```shell
# ä¸‹è¿°å‘½ä»¤ä¸­çš„è·¯å¾„ä¸ºå®‰è£… nncase çš„ Python ç¯å¢ƒçš„è·¯å¾„ï¼Œè¯·æŒ‰ç…§æ‚¨çš„ç¯å¢ƒé€‚é…ä¿®æ”¹
export NNCASE_PLUGIN_PATH=$NNCASE_PLUGIN_PATH:/usr/local/lib/python3.9/site-packages/
export PATH=$PATH:/usr/local/lib/python3.9/site-packages/
source /etc/profile
```

- **windows**ï¼š

å°†å®‰è£… `nncase` çš„ `Python` ç¯å¢ƒä¸‹çš„ `Lib/site-packages` è·¯å¾„æ·»åŠ åˆ°ç¯å¢ƒå˜é‡çš„ç³»ç»Ÿå˜é‡ `Path` ä¸­ã€‚

é’ˆå¯¹**4ç±»æ‰“å°æ•°å­—è¯†åˆ«**åœºæ™¯ï¼ŒéªŒè¯è¾“å‡ºç›¸ä¼¼åº¦çš„ç¤ºä¾‹ä»£ç ï¼š

```python
import os
import cv2
import numpy as np
import onnxruntime as ort
import nncase
import math

def get_onnx_input(img_path,mean,std,model_input_size):
    # è¯»å–å›¾ç‰‡ï¼Œå›¾ç‰‡æ•°æ®ä¸€èˆ¬æ˜¯RGBä¸‰é€šé“ï¼Œé¢œè‰²èŒƒå›´ä¸º[0, 255.0]
    image_fp32=cv2.imread(img_path)
    # å¦‚æœæ¨¡å‹è¾“å…¥è¦æ±‚æ˜¯RGBçš„ï¼Œåˆ™è½¬æ¢ä¸ºRGBæ ¼å¼ï¼Œå¦‚æœè¦æ±‚æ˜¯BGRçš„ï¼Œåˆ™ä¸éœ€è¦è½¬æ¢
    image_fp32=cv2.cvtColor(image_fp32, cv2.COLOR_BGR2RGB)
    # ç¼©æ”¾æˆæ¨¡å‹è¾“å…¥å¤§å°
    image_fp32 = cv2.resize(image_fp32, (model_input_size[0], model_input_size[1]))
    # æ•°æ®ç±»å‹ä¸ºfloat32,
    image_fp32 = np.asarray(image_fp32, dtype=np.float32)
    # æ•°æ®æ ‡å‡†åŒ–,å…ˆå½’ä¸€åŒ–åˆ°[0,1]èŒƒå›´å†…ï¼Œç„¶åå‡å‡å€¼é™¤æ–¹å·®
    image_fp32/=255.0
    for i in range(3):
        image_fp32[:, :, i] -= mean[i]
        image_fp32[:, :, i] /= std[i]
    # æŒ‰ç…§æ¨¡å‹è¾“å…¥è¦æ±‚å¤„ç†æˆNCHWæ’å¸ƒæˆ–è€…NHWCæ’å¸ƒ
    image_fp32 = np.transpose(image_fp32, (2, 0, 1))
    return image_fp32.copy()

def get_kmodel_input(img_path,mean,std,model_input_size):
    # è¯»å–å›¾ç‰‡ï¼Œå›¾ç‰‡æ•°æ®ä¸€èˆ¬æ˜¯RGBä¸‰é€šé“ï¼Œé¢œè‰²èŒƒå›´ä¸º[0, 255.0]
    image_uint8=cv2.imread(img_path)
    # å¦‚æœæ¨¡å‹è¾“å…¥è¦æ±‚æ˜¯RGBçš„ï¼Œåˆ™è½¬æ¢ä¸ºRGBæ ¼å¼ï¼Œå¦‚æœè¦æ±‚æ˜¯BGRçš„ï¼Œåˆ™ä¸éœ€è¦è½¬æ¢
    image_uint8=cv2.cvtColor(image_uint8, cv2.COLOR_BGR2RGB)
    # ç¼©æ”¾æˆæ¨¡å‹è¾“å…¥å¤§å°
    image_uint8 = cv2.resize(image_uint8, (model_input_size[0], model_input_size[1]))
    # æ•°æ®ç±»å‹ä¸ºuint8,å› ä¸ºè½¬æ¢kmodelçš„æ—¶å€™å¼€å¯äº†é¢„å¤„ç†ï¼Œå¹¶ä¸”è®¾å®šäº†æ ‡å‡†åŒ–å‚æ•°ï¼Œå› æ­¤è¿™é‡Œçš„è¾“å…¥å°±ä¸éœ€è¦å®ç°æ ‡å‡†åŒ–äº†
    image_uint8 = np.asarray(image_uint8, dtype=np.uint8)
    # æŒ‰ç…§æ¨¡å‹è¾“å…¥è¦æ±‚å¤„ç†æˆNCHWæ’å¸ƒæˆ–è€…NHWCæ’å¸ƒ
    image_uint8 = np.transpose(image_uint8, (2, 0, 1))
    return image_uint8.copy()

def onnx_inference(onnx_path,onnx_input_data):
    # åˆ›å»º ONNX æ¨ç†ä¼šè¯ï¼ˆåŠ è½½æ¨¡å‹ï¼‰
    ort_session = ort.InferenceSession(onnx_path)
    # è·å–æ¨¡å‹è¾“å‡ºåç§°åˆ—è¡¨ï¼Œç”¨äºåç»­è°ƒç”¨æ¨ç†
    output_names = []
    model_outputs = ort_session.get_outputs()
    for i in range(len(model_outputs)):
        output_names.append(model_outputs[i].name)

    # è·å–æ¨¡å‹çš„è¾“å…¥ä¿¡æ¯
    model_input = ort_session.get_inputs()[0]             # ç¬¬ä¸€ä¸ªè¾“å…¥ï¼ˆé€šå¸¸åªæœ‰ä¸€ä¸ªï¼‰
    model_input_name = model_input.name                   # è¾“å…¥çš„åç§°ï¼ˆé”®ï¼‰
    model_input_type = np.float32                         # è¾“å…¥æ•°æ®ç±»å‹ï¼Œè¿™é‡Œå‡è®¾æ˜¯ float32
    model_input_shape = model_input.shape                 # è¾“å…¥å¼ é‡çš„å½¢çŠ¶ï¼ˆç»´åº¦ï¼‰

    # å¤„ç†è¾“å…¥æ•°æ®,éœ€ç¡®ä¿å’Œæ¨¡å‹è¾“å…¥å½¢çŠ¶ä¸€è‡´
    model_input_data = onnx_input_data.astype(model_input_type).reshape(model_input_shape)

    # æ‰§è¡Œæ¨ç†ï¼Œä¼ å…¥è¾“å…¥åç§°å’Œæ•°æ®ï¼Œè¿”å›æ‰€æœ‰è¾“å‡ºç»“æœ
    onnx_results = ort_session.run(output_names, { model_input_name : model_input_data })
    return onnx_results

def kmodel_inference(kmodel_path,kmodel_input_data,model_input_size):
    # åˆå§‹åŒ–nncase æ¨¡æ‹Ÿå™¨
    sim = nncase.Simulator()
    # è¯»å–kmodel
    with open(kmodel_path, 'rb') as f:
        kmodel = f.read()
    # åŠ è½½kmodel
    sim.load_model(kmodel)
    # è¯»å–è¾“å…¥æ•°æ®
    input_shape = [1, 3, model_input_size[1], model_input_size[0]]
    dtype = sim.get_input_desc(0).dtype
    # å¤„ç†è¾“å…¥æ•°æ®,éœ€ç¡®ä¿å’Œæ¨¡å‹è¾“å…¥å½¢çŠ¶ä¸€è‡´
    kmodel_input = kmodel_input_data.astype(dtype).reshape(input_shape)
    # è®¾ç½®æ¨¡æ‹Ÿå™¨è¾“å…¥tensor,æ­¤å¤„ä¸ºå•è¾“å…¥
    sim.set_input_tensor(0, nncase.RuntimeTensor.from_numpy(kmodel_input))
    # æ¨¡æ‹Ÿå™¨æ¨ç†kmodelæ¨¡å‹
    sim.run()
    # è·å–æ¨ç†è¾“å‡º
    kmodel_results = []
    for i in range(sim.outputs_size):
        kmodel_result = sim.get_output_tensor(i).to_numpy()  # è½¬æ¢ä¸ºnumpyæ•°ç»„
        kmodel_results.append(kmodel_result)  # ä¿å­˜åˆ°åˆ—è¡¨ä¸­
    return kmodel_results

def cosine_similarity(onnx_results,kmodel_results):
    output_size=len(kmodel_results)
    # å°†æ¯ä¸ªè¾“å‡ºå±•æˆä¸€ç»´ï¼Œç„¶åè®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
    for i in range(output_size):
        onnx_i=np.reshape(onnx_results[i], (-1))
        kmodel_i=np.reshape(kmodel_results[i], (-1))
        cos = (onnx_i @ kmodel_i) / (np.linalg.norm(onnx_i, 2) * np.linalg.norm(kmodel_i, 2))
        print('output {0} cosine similarity : {1}'.format(i, cos))
    return

if __name__ == '__main__':
    img_path="test.jpg"
    mean=[0,0,0]
    std=[1,1,1]
    model_input_size=[320,320]
    # ONNX æ¨¡å‹æ–‡ä»¶
    onnx_model = "best.onnx"
    # kmodel æ¨¡å‹æ–‡ä»¶
    kmodel_path="best.kmodel"
    # ç”Ÿæˆonnxæ¨¡å‹è¾“å…¥æ•°æ®
    onnx_input_data = get_onnx_input(img_path,mean,std,model_input_size)
    # ç”Ÿæˆkmodelæ¨¡å‹è¾“å…¥æ•°æ®
    kmodel_input_data = get_kmodel_input(img_path,mean,std,model_input_size)
    # onnxæ¨¡å‹æ¨ç†
    onnx_results = onnx_inference(onnx_model,onnx_input_data)
    # kmodelæ¨¡å‹æ¨ç†
    nncase_results = kmodel_inference(kmodel_path,kmodel_input_data,model_input_size)
    # è®¡ç®—è¾“å‡ºç›¸ä¼¼åº¦
    cosine_similarity(onnx_results,nncase_results)
```

å°†ä¸Šè¿°ä»£ç ä¿å­˜æˆæ–‡ä»¶ï¼Œå¹¶å°†ä»£ç å†…çš„æ¨¡å‹æ¢æˆæ‚¨è‡ªå·±è½¬æ¢çš„æ¨¡å‹åï¼Œè¿è¡Œè„šæœ¬å¾—åˆ°å¦‚ä¸‹è¾“å‡ºï¼š

```shell
output 0 cosine similarity : 0.9995334148406982
```

ä¸€èˆ¬æˆ‘ä»¬è®¤ä¸ºå½“ç›¸ä¼¼åº¦å¤§äº0.99æ—¶ï¼Œè¡¨ç¤ºè¯¥æ¨¡å‹è½¬æ¢æˆåŠŸï¼Œåœ¨å®é™…éƒ¨ç½²åœºæ™¯ä¸‹æ˜¯å¯ç”¨çš„ã€‚

#### ç”Ÿæˆè¾“å…¥æ•°æ®

âš ï¸ **æ³¨æ„**ï¼šåœ¨ä½¿ç”¨ ONNX æ¨¡å‹å’Œ KModel è¿›è¡Œæ¨ç†æ—¶ï¼Œ**å¿…é¡»è°¨æ…å¤„ç†è¾“å…¥æ•°æ®çš„é¢„å¤„ç†æ­¥éª¤**ã€‚è‹¥ KModel ä¸­å·²å°è£…äº†ç‰¹å®šçš„é¢„å¤„ç†æ“ä½œï¼Œåˆ™åœ¨æ¨ç†å‰æ— éœ€å¯¹å…¶è¾“å…¥æ•°æ®æ‰‹åŠ¨æ‰§è¡Œè¿™äº›é¢„å¤„ç†ï¼›ä½†åœ¨ä½¿ç”¨ ONNX æ¨¡å‹æ¨ç†æ—¶ï¼Œåˆ™éœ€æ˜¾å¼åœ°åœ¨æ¨¡å‹å¤–éƒ¨å®Œæˆæ‰€æœ‰å¿…è¦çš„é¢„å¤„ç†æµç¨‹ã€‚

KModel æ‰€æ”¯æŒå¹¶å¯å°è£…çš„é¢„å¤„ç†æ“ä½œåŒ…æ‹¬ï¼š

- é€šé“é¡ºåºå˜æ¢ï¼ˆå¦‚ RGB â†” BGRï¼‰ï¼Œå¯¹åº” `SwapRB` å‚æ•°ï¼›
- å¸ƒå±€è½¬æ¢ï¼ˆNCHW â†” NHWCï¼‰ï¼Œå¯¹åº” `input_shape` ä¸ `input_layout` å‚æ•°ï¼›
- æ•°æ®æ ‡å‡†åŒ–å¤„ç†ï¼Œä¾èµ– `mean` å’Œ `std` å‚æ•°ï¼›
- è¾“å…¥åé‡åŒ–å¤„ç†ï¼Œä¾èµ– `input_type` å’Œ `input_range` å‚æ•°ï¼›

å…³äº ONNX ä¸ KModel æ¨ç†æµç¨‹çš„å·®å¼‚ï¼Œå¯å‚è€ƒä»¥ä¸‹æµç¨‹å›¾ï¼š

![inference_diff_onnx_kmodel](https://www.kendryte.com/api/post/attachment?id=612)

åœ¨ä½¿ç”¨ ONNX æ¨¡å‹æ¨ç†æ—¶ï¼Œç”±äºå…¶æœ¬ä½“ä¸åŒ…å«ä»»ä½•é¢„å¤„ç†é€»è¾‘ï¼Œç”¨æˆ·å¿…é¡»åœ¨è¾“å…¥å‰å®Œæˆæ‰€éœ€çš„å…¨éƒ¨é¢„å¤„ç†æ­¥éª¤ã€‚
è€Œå¯¹äº KModelï¼Œå¦‚æœåœ¨æ¨¡å‹ç¼–è¯‘æ—¶å¯ç”¨äº† `preprocess` é€‰é¡¹ï¼Œåˆ™ç›¸å…³é¢„å¤„ç†æ“ä½œå°†è¢«è‡ªåŠ¨å°è£…è¿›æ¨¡å‹å†…éƒ¨ï¼Œæ¨ç†æ—¶ä¸å†éœ€è¦ç”¨æˆ·æ‰‹åŠ¨å¤„ç†ã€‚
å¦‚æœæœªå¯ç”¨ `preprocess`ï¼Œå…¶ä½¿ç”¨æ–¹å¼ä¸ ONNX æ¨¡å‹ç›¸åŒï¼Œä»éœ€åœ¨æ¨¡å‹å¤–éƒ¨å®Œæˆæ‰€æœ‰é¢„å¤„ç†è¿‡ç¨‹ã€‚

æ ¹æ®ä¸Šè¿°æµç¨‹ï¼Œå¼€å‘è€…å¯æŒ‰ç…§æ¨¡å‹è¦æ±‚æ„é€ ç¬¦åˆè¾“å…¥è§„èŒƒçš„æ¨ç†æ•°æ®ï¼Œä»¥ä¾¿åœ¨æ¨ç†è¿‡ç¨‹ä¸­ä½¿ç”¨ã€‚
**è¯·æ³¨æ„ï¼šæ•°æ®ç”Ÿæˆè¿‡ç¨‹å¿…é¡»ä¸¥æ ¼ç¬¦åˆæ¨¡å‹è¦æ±‚ï¼Œä¸åŒæ¨¡å‹ä¹‹é—´çš„è¾“å…¥å¤„ç†æµç¨‹å¯èƒ½å­˜åœ¨æ˜¾è‘—å·®å¼‚ï¼Œä¸èƒ½æ··ç”¨ã€‚**

ä»¥ä¸‹ä¸ºæ•°æ®é¢„å¤„ç†çš„ç¤ºä¾‹ä»£ç ï¼š

```python
def get_onnx_input(img_path,mean,std,model_input_size):
    # è¯»å–å›¾ç‰‡ï¼Œå›¾ç‰‡æ•°æ®ä¸€èˆ¬æ˜¯RGBä¸‰é€šé“ï¼Œé¢œè‰²èŒƒå›´ä¸º[0, 255.0]
    image_fp32=cv2.imread(img_path)
    # å¦‚æœæ¨¡å‹è¾“å…¥è¦æ±‚æ˜¯RGBçš„ï¼Œåˆ™è½¬æ¢ä¸ºRGBæ ¼å¼ï¼Œå¦‚æœè¦æ±‚æ˜¯BGRçš„ï¼Œåˆ™ä¸éœ€è¦è½¬æ¢
    image_fp32=cv2.cvtColor(image_fp32, cv2.COLOR_BGR2RGB)
    # ç¼©æ”¾æˆæ¨¡å‹è¾“å…¥å¤§å°
    image_fp32 = cv2.resize(image_fp32, (model_input_size[0], model_input_size[1]))
    # æ•°æ®ç±»å‹ä¸ºfloat32,
    image_fp32 = np.asarray(image_fp32, dtype=np.float32)
    # æ•°æ®æ ‡å‡†åŒ–,å…ˆå½’ä¸€åŒ–åˆ°[0,1]èŒƒå›´å†…ï¼Œç„¶åå‡å‡å€¼é™¤æ–¹å·®
    image_fp32/=255.0
    for i in range(3):
        image_fp32[:, :, i] -= mean[i]
        image_fp32[:, :, i] /= std[i]
    # æŒ‰ç…§æ¨¡å‹è¾“å…¥è¦æ±‚å¤„ç†æˆNCHWæ’å¸ƒæˆ–è€…NHWCæ’å¸ƒ
    image_fp32 = np.transpose(image_fp32, (2, 0, 1))
    return image_fp32.copy()

def get_kmodel_input(img_path,mean,std,model_input_size):
    # è¯»å–å›¾ç‰‡ï¼Œå›¾ç‰‡æ•°æ®ä¸€èˆ¬æ˜¯RGBä¸‰é€šé“ï¼Œé¢œè‰²èŒƒå›´ä¸º[0, 255.0]
    image_uint8=cv2.imread(img_path)
    # å¦‚æœæ¨¡å‹è¾“å…¥è¦æ±‚æ˜¯RGBçš„ï¼Œåˆ™è½¬æ¢ä¸ºRGBæ ¼å¼ï¼Œå¦‚æœè¦æ±‚æ˜¯BGRçš„ï¼Œåˆ™ä¸éœ€è¦è½¬æ¢
    image_uint8=cv2.cvtColor(image_uint8, cv2.COLOR_BGR2RGB)
    # ç¼©æ”¾æˆæ¨¡å‹è¾“å…¥å¤§å°
    image_uint8 = cv2.resize(image_uint8, (model_input_size[0], model_input_size[1]))
    # æ•°æ®ç±»å‹ä¸ºuint8,å› ä¸ºè½¬æ¢kmodelçš„æ—¶å€™å¼€å¯äº†é¢„å¤„ç†ï¼Œå¹¶ä¸”è®¾å®šäº†æ ‡å‡†åŒ–å‚æ•°ï¼Œå› æ­¤è¿™é‡Œçš„è¾“å…¥å°±ä¸éœ€è¦å®ç°æ ‡å‡†åŒ–äº†
    image_uint8 = np.asarray(image_uint8, dtype=np.uint8)
    # æŒ‰ç…§æ¨¡å‹è¾“å…¥è¦æ±‚å¤„ç†æˆNCHWæ’å¸ƒæˆ–è€…NHWCæ’å¸ƒ
    image_uint8 = np.transpose(image_uint8, (2, 0, 1))
    return image_uint8.copy()
```

åœ¨ä½¿ç”¨ ONNX æ¨¡å‹å’Œ KModel è¿›è¡Œæ¨ç†æ—¶ï¼Œè¾“å…¥æ•°æ®çš„é¢„å¤„ç†å­˜åœ¨è‹¥å¹²å…³é”®å·®å¼‚ï¼Œä¸»è¦ä½“ç°åœ¨ä»¥ä¸‹å‡ ä¸ªæ–¹é¢ï¼š

- **æ ‡å‡†åŒ–å¤„ç†**ï¼šONNX æ¨¡å‹æœ¬èº«ä¸åŒ…å«ä»»ä½•é¢„å¤„ç†é€»è¾‘ï¼Œå› æ­¤å…¶è¾“å…¥æ•°æ®å¿…é¡»åœ¨å¤–éƒ¨å®Œæˆæ ‡å‡†åŒ–ï¼ˆä¾‹å¦‚å‡å‡å€¼é™¤æ ‡å‡†å·®ï¼‰ã€‚è€Œå¯¹äº KModelï¼Œå¦‚æœåœ¨æ¨¡å‹è½¬æ¢é˜¶æ®µå·²é…ç½®äº†å½’ä¸€åŒ–å‚æ•°ï¼ˆå¦‚ `mean` å’Œ `std`ï¼‰ï¼Œåˆ™è¿™éƒ¨åˆ†æ ‡å‡†åŒ–æ“ä½œä¼šè¢«å°è£…è¿›æ¨¡å‹å†…éƒ¨ï¼Œ**æ¨ç†å‰æ— éœ€é‡å¤å¤„ç†**ã€‚

- **æ•°æ®ç±»å‹å·®å¼‚**ï¼šONNX æ¨¡å‹çš„è¾“å…¥é€šå¸¸ä¸º `float32` ç±»å‹ï¼Œè€Œ KModel çš„è¾“å…¥ç±»å‹åˆ™ä¾èµ–æ¨¡å‹è½¬æ¢æ—¶æŒ‡å®šçš„ `input_type`ï¼ˆä¾‹å¦‚ `uint8`ï¼‰åŠ `input_range`ã€‚KModel ä¼šåœ¨æ¨ç†å†…éƒ¨è¿›è¡Œåé‡åŒ–å¤„ç†ï¼Œå°†æ•´æ•°ç±»å‹è¿˜åŸä¸ºè¿‘ä¼¼çš„æµ®ç‚¹è¡¨è¾¾ã€‚

- **é€šé“é¡ºåºå¤„ç†**ï¼šè‹¥åœ¨æ¨¡å‹è½¬æ¢è¿‡ç¨‹ä¸­æœªå¯ç”¨ `SwapRB`ï¼ˆå³å‚æ•°ä¸º `False`ï¼‰ï¼Œåˆ™éœ€è¦åœ¨å¤–éƒ¨é¢„å¤„ç†é˜¶æ®µå°†è¾“å…¥å›¾åƒçš„é€šé“é¡ºåºä» BGR è½¬æ¢ä¸º RGBã€‚è‹¥ `SwapRB=True`ï¼Œè¯¥é€šé“å˜æ¢æ“ä½œå°†è‡ªåŠ¨ç”± KModel å†…éƒ¨å¤„ç†ï¼Œ**æ— éœ€åœ¨å¤–éƒ¨æ‰§è¡Œ**ã€‚

ç»¼åˆæ¥çœ‹ï¼ŒONNX æ¨¡å‹æ‰€éœ€çš„å¤–éƒ¨é¢„å¤„ç†æ“ä½œç­‰äº KModel çš„å¤–éƒ¨é¢„å¤„ç† **åŠ ä¸Š** å†…éƒ¨é¢„å¤„ç†ï¼Œä¸¤è€…çš„å…³ç³»å¯è¡¨ç¤ºå¦‚ä¸‹ï¼š

```shell
ONNX æ¨¡å‹å¤–éƒ¨é¢„å¤„ç† = KModel å¤–éƒ¨é¢„å¤„ç† + KModel å†…éƒ¨é¢„å¤„ç†
```

#### åŠ è½½onnxæ¨¡å‹å¹¶æ¨ç†

é¦–å…ˆéœ€è¦ä½¿ç”¨onnxæ¨¡å‹å®Œæˆæ¨ç†ï¼Œè·å–onnxæ¨¡å‹çš„æ¨ç†ç»“æœã€‚ç¤ºä¾‹ä»£ç å¦‚ä¸‹ï¼š

```python
def onnx_inference(onnx_path,onnx_input_data):
    # åˆ›å»º ONNX æ¨ç†ä¼šè¯ï¼ˆåŠ è½½æ¨¡å‹ï¼‰
    ort_session = ort.InferenceSession(onnx_path)
    # è·å–æ¨¡å‹è¾“å‡ºåç§°åˆ—è¡¨ï¼Œç”¨äºåç»­è°ƒç”¨æ¨ç†
    output_names = []
    model_outputs = ort_session.get_outputs()
    for i in range(len(model_outputs)):
        output_names.append(model_outputs[i].name)

    # è·å–æ¨¡å‹çš„è¾“å…¥ä¿¡æ¯
    model_input = ort_session.get_inputs()[0]             # ç¬¬ä¸€ä¸ªè¾“å…¥ï¼ˆé€šå¸¸åªæœ‰ä¸€ä¸ªï¼‰
    model_input_name = model_input.name                   # è¾“å…¥çš„åç§°ï¼ˆé”®ï¼‰
    model_input_type = np.float32                         # è¾“å…¥æ•°æ®ç±»å‹ï¼Œè¿™é‡Œå‡è®¾æ˜¯ float32
    model_input_shape = model_input.shape                 # è¾“å…¥å¼ é‡çš„å½¢çŠ¶ï¼ˆç»´åº¦ï¼‰

    # å¤„ç†è¾“å…¥æ•°æ®,éœ€ç¡®ä¿å’Œæ¨¡å‹è¾“å…¥å½¢çŠ¶ä¸€è‡´
    model_input_data = onnx_input_data.astype(model_input_type).reshape(model_input_shape)

    # æ‰§è¡Œæ¨ç†ï¼Œä¼ å…¥è¾“å…¥åç§°å’Œæ•°æ®ï¼Œè¿”å›æ‰€æœ‰è¾“å‡ºç»“æœ
    onnx_results = ort_session.run(output_names, { model_input_name : model_input_data })
    return onnx_results
```

#### åŠ è½½kmodelæ¨¡å‹å¹¶æ¨ç†

ç„¶åä½¿ç”¨è½¬æ¢æˆåŠŸçš„kmodelè¿›è¡Œæ¨ç†ï¼Œè·å¾—kmodelçš„æ¨ç†ç»“æœã€‚ç¤ºä¾‹ä»£ç å¦‚ä¸‹ï¼š

```python
def kmodel_inference(kmodel_path,kmodel_input_data,model_input_size):
    # åˆå§‹åŒ–nncase æ¨¡æ‹Ÿå™¨
    sim = nncase.Simulator()
    # è¯»å–kmodel
    with open(kmodel_path, 'rb') as f:
        kmodel = f.read()
    # åŠ è½½kmodel
    sim.load_model(kmodel)
    # è¯»å–è¾“å…¥æ•°æ®
    input_shape = [1, 3, model_input_size[1], model_input_size[0]]
    dtype = sim.get_input_desc(0).dtype
    # å¤„ç†è¾“å…¥æ•°æ®,éœ€ç¡®ä¿å’Œæ¨¡å‹è¾“å…¥å½¢çŠ¶ä¸€è‡´
    kmodel_input = kmodel_input_data.astype(dtype).reshape(input_shape)
    # è®¾ç½®æ¨¡æ‹Ÿå™¨è¾“å…¥tensor,æ­¤å¤„ä¸ºå•è¾“å…¥
    sim.set_input_tensor(0, nncase.RuntimeTensor.from_numpy(kmodel_input))
    # æ¨¡æ‹Ÿå™¨æ¨ç†kmodelæ¨¡å‹
    sim.run()
    # è·å–æ¨ç†è¾“å‡º
    kmodel_results = []
    for i in range(sim.outputs_size):
        kmodel_result = sim.get_output_tensor(i).to_numpy()  # è½¬æ¢ä¸ºnumpyæ•°ç»„
        kmodel_results.append(kmodel_result)  # ä¿å­˜åˆ°åˆ—è¡¨ä¸­
    return kmodel_results
```

#### è®¡ç®—è¾“å‡ºçš„ä½™å¼¦ç›¸ä¼¼åº¦

å¾—åˆ°onnxæ¨¡å‹å’Œkmodelæ¨¡å‹çš„æ¨ç†ç»“æœåï¼Œé€ä¸ªè®¡ç®—æ¯ä¸ªè¾“å‡ºçš„ä½™å¼¦ç›¸ä¼¼åº¦ã€‚ä¸€èˆ¬ç›¸ä¼¼åº¦åœ¨0.99ä»¥ä¸Šå¯ä»¥è®¤ä¸ºè¯¥æ¨¡å‹è½¬æ¢æˆåŠŸï¼Œå¯éƒ¨ç½²ä½¿ç”¨ã€‚ç¤ºä¾‹ä»£ç å¦‚ä¸‹ï¼š

```python
def cosine_similarity(onnx_results,kmodel_results):
    output_size=len(kmodel_results)
    # å°†æ¯ä¸ªè¾“å‡ºå±•æˆä¸€ç»´ï¼Œç„¶åè®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
    for i in range(output_size):
        onnx_i=np.reshape(onnx_results[i], (-1))
        kmodel_i=np.reshape(kmodel_results[i], (-1))
        cos = (onnx_i @ kmodel_i) / (np.linalg.norm(onnx_i, 2) * np.linalg.norm(kmodel_i, 2))
        print('output {0} cosine similarity : {1}'.format(i, cos))
    return
```

## æ¨¡å‹éƒ¨ç½²

```{note}
ğŸ‘‰ å‰é¢æˆ‘ä»¬æŠŠkmodelæ¨¡å‹è½¬å¥½äº†ã€ä¹ŸéªŒè¯è¿‡äº†ï¼Œæ¥ä¸‹æ¥å½“ç„¶å°±æ˜¯â€”â€”â€”**ä¸Šæ¿å­è·‘èµ·æ¥å•¦ï¼** è¿™ä¸€ç« æˆ‘ä»¬å°±æ¥èŠèŠæ€ä¹ˆåœ¨ K230 çš„ MicroPython ç¯å¢ƒä¸‹ï¼Œç”¨æä¾›çš„ nncase runtime API æŠŠæ¨¡å‹åŠ è½½è¿›æ¥å¹¶å®ç°æ¨ç†ã€‚

é‚£é—®é¢˜æ¥äº†ï¼šæ¨¡å‹æ˜¯æœ‰äº†ï¼Œé‚£è¾“å…¥æ•°æ®è¦æ€ä¹ˆå‡†å¤‡ï¼Ÿæˆ‘ä»¬è¦æ ¹æ®æ¨¡å‹çš„â€œå£å‘³â€å¯¹è¾“å…¥å›¾åƒåšä¸€äº›å¤„ç†ï¼Œæ¯”å¦‚å°ºå¯¸ã€æ ¼å¼ã€å½’ä¸€åŒ–ç­‰ç­‰ï¼Œç¡®ä¿å®ƒèƒ½â€œåƒå¾—å¯¹â€ã€‚ç„¶åæŠŠå¤„ç†å¥½çš„æ•°æ®å–‚è¿›å»ï¼Œè®©æ¨¡å‹å¼€å§‹æ¨ç†ã€‚æ¨ç†å®Œä¹‹åï¼Œæ¨¡å‹ä¼šç»™æˆ‘ä»¬ä¸€å †â€œè¾“å‡ºç»“æœâ€ï¼Œè¿™äº›ç»“æœæ˜¯å•¥æ„æ€ï¼Ÿæˆ‘ä»¬è¿˜å¾—åšä¸€ç•ªè§£æï¼Œæ¯”å¦‚æ‹¿å‡ºç±»åˆ«ã€åæ ‡è¿™äº›æœ‰ç”¨çš„ä¿¡æ¯ã€‚

æœ€åå˜›ï¼Œå½“ç„¶ä¸èƒ½è—ç€æ–ç€ï¼æˆ‘ä»¬ä¼šæŠŠè¿™äº›è¯†åˆ«å‡ºæ¥çš„å†…å®¹æ˜¾ç¤ºåœ¨å±å¹•ä¸Šï¼Œæ¯”å¦‚ç”»æ¡†ã€æ ‡æ•°å­—ï¼Œè®©æ•´ä¸ªæµç¨‹ä»å›¾åƒé‡‡é›†ã€æ¨¡å‹æ¨ç†ï¼Œåˆ°ç»“æœå±•ç¤º**ä¸€æ°”å‘µæˆã€å…¨æµç¨‹è·‘é€š**ï¼

è¿™ä¸€ç« å°±ä¼šå¸¦ä½ æŠŠè¿™ä¸ªå®Œæ•´è¿‡ç¨‹ææ˜ç™½ï¼Œè®©æ¨¡å‹çœŸçš„å¼€å§‹â€œåŠ¨èµ·æ¥â€ï½
```

å¯¹äºä¸€ä¸ªå®ç”¨çš„ AI ç¨‹åºï¼Œä¸ä»…åŒ…æ‹¬æ¨¡å‹æ¨ç†ï¼Œè¿˜åŒ…æ‹¬æœ‰å›¾åƒè¾“å…¥ã€å‰åå¤„ç†ç¨‹åºã€ç»“æœæ˜¾ç¤ºç­‰ä¸åŒæ¨¡å—ã€‚ä¸‹å›¾å±•ç¤ºäº†ä¸€ä¸ªå…¸å‹çš„AIåº”ç”¨ç¨‹åºçš„å®Œæ•´æ¡†å›¾ï¼š

![deploy_pipeline](https://www.kendryte.com/api/post/attachment?id=630)

ğŸš€ éƒ¨ç½²æµç¨‹è®²è§£ï¼šéƒ¨ç½²å…¶å®å¯ä»¥ç†è§£ä¸ºâ€œè®©æ¨¡å‹çœŸæ­£å·¥ä½œèµ·æ¥â€çš„è¿‡ç¨‹ï¼Œä¸‹é¢æˆ‘ä»¬æŒ‰ç…§æµç¨‹ï¼Œåˆ†æ­¥ä»‹ç»ã€‚

**1ï¸âƒ£ è·å–å›¾åƒæ•°æ®ï¼ˆè¾“å…¥æ•°æ®æºï¼‰**
æˆ‘ä»¬å…ˆå¾—æ‹¿åˆ°ä¸€å¼ å›¾åƒï¼Œé€šå¸¸æ˜¯ä»æ‘„åƒå¤´ä¸­å®æ—¶é‡‡é›†ï¼Œä¹Ÿå¯ä»¥ä»æœ¬åœ°åŠ è½½ä¸€å¼ æµ‹è¯•å›¾ç‰‡ã€‚æ‹¿åˆ°å›¾åƒåï¼Œä¼šå¾—åˆ°ä¸€ä¸ª Image å¯¹è±¡ã€‚åœ¨ K230 å¼€å‘æ¿ä¸Šï¼Œé€šå¸¸ä½ ä¼šé€šè¿‡ sensor.snapshot() æ¥è·å–å›¾åƒã€‚

**2ï¸âƒ£ æ„é€ è¾“å…¥ Tensorï¼ˆå‡†å¤‡æŠ•å–‚æ¨¡å‹çš„æ•°æ®ï¼‰**
æœ‰äº†å›¾åƒä¹‹åï¼Œæˆ‘ä»¬è¦æŠŠå®ƒâ€œæ‰“åŒ…â€æˆæ¨¡å‹èƒ½å¤„ç†çš„æ ¼å¼nncase_runtime.runtime_tensorã€‚è¿™ä¸€æ­¥ï¼Œæ˜¯ä¸ºäº†å–‚ç»™æ¨¡å‹ä¸€ä¸ªæ ‡å‡†ç»“æ„çš„æ•°æ®ã€‚

**3ï¸âƒ£ é¢„å¤„ç†ï¼ˆai2d æ¨¡å—ï¼‰**
æ¨¡å‹å¯¹è¾“å…¥å›¾åƒæœ‰ç‰¹å®šè¦æ±‚ï¼Œæ¯”å¦‚å¤§å°ã€æ ¼å¼ã€é€šé“é¡ºåºç­‰ç­‰ã€‚è¿™ä¸€æ­¥æˆ‘ä»¬å°±ç”¨ ai2d æ¨¡å—æŠŠå›¾åƒtensorå¤„ç†æˆæ¨¡å‹éœ€è¦çš„â€œæ ·å­â€ã€‚

**4ï¸âƒ£ æ¨¡å‹æ¨ç†ï¼ˆä½¿ç”¨ KPU æ¨ç†æ¨¡å—ï¼‰**
å›¾åƒå¤„ç†å¥½åï¼Œå–‚è¿› KPUï¼ˆK230 çš„ç¥ç»ç½‘ç»œåŠ é€Ÿæ¨¡å—ï¼‰è¿›è¡Œæ¨ç†ã€‚KPU ä¼šè¿”å›ä¸€ä¸ªç»“æœ tensorï¼Œè¿™é‡Œé¢åŒ…å«äº†æ¨¡å‹çš„è¾“å‡ºï¼Œæ¯”å¦‚æ£€æµ‹æ¡†ã€åˆ†ç±»æ¦‚ç‡ç­‰ç­‰ã€‚

**5ï¸âƒ£ åå¤„ç†ï¼ˆæå–æœ‰ç”¨ä¿¡æ¯ï¼‰**
KPU è¾“å‡ºçš„æ˜¯ä¸€å †æ•°å­—ï¼Œæˆ‘ä»¬å¾—æŠŠè¿™äº›â€œå¹²è´§â€è§£æå‡ºæ¥ã€‚æ¯”å¦‚è¯†åˆ«åˆ°çš„æ•°å­—æ˜¯å‡ ï¼Ÿæ¡†åœ¨å›¾åƒä¸Šçš„ä½ç½®åœ¨å“ªï¼Ÿè¿™äº›éƒ½éœ€è¦ç”¨åå¤„ç†ç®—æ³•æ¥æå®šã€‚å¯¹ YOLO æ¨¡å‹æ¥è¯´ï¼Œåå¤„ç†åŒ…æ‹¬ç½®ä¿¡åº¦è¿‡æ»¤ã€NMS éæå¤§å€¼æŠ‘åˆ¶ç­‰ã€‚

**6ï¸âƒ£ æ˜¾ç¤ºè¯†åˆ«ç»“æœï¼ˆå¯è§†åŒ–ï¼‰**
æœ€åä¸€æ­¥ï¼ŒæŠŠè¯†åˆ«åˆ°çš„å†…å®¹â€œç”»â€å‡ºæ¥ï¼æˆ‘ä»¬å¯ä»¥åœ¨å±å¹•ä¸Šç”»å‡ºæ£€æµ‹æ¡†ã€æ•°å­—æ ‡ç­¾ç­‰ï¼Œè®©ç»“æœä¸€ç›®äº†ç„¶ã€‚ä¸€èˆ¬ä¼šç”¨ä¸¤ä¸ªå›¾å±‚æ¥æ˜¾ç¤ºï¼Œä¸€å±‚æ˜¯åŸå§‹å›¾åƒï¼Œå¦ä¸€å±‚æ˜¯è¯†åˆ«ç»“æœï¼ˆå¦‚æ¡†å’Œæ•°å­—ï¼‰ï¼Œå åŠ æ˜¾ç¤ºå¯ä»¥ä¿è¯æ•ˆæœæ›´æ¸…æ™°ä¹Ÿæ›´çµæ´»ã€‚

æ€»ç»“ï¼šéƒ¨ç½²çš„æ ¸å¿ƒæµç¨‹å°±æ˜¯ï¼šæ‹¿å›¾åƒ â†’ å¤„ç†æˆè¾“å…¥ â†’ æ‰”ç»™æ¨¡å‹ â†’ æ‹¿ç»“æœ â†’ è§£è¯»ç»“æœ â†’ æ˜¾ç¤ºå‡ºæ¥ï¼è¿™å¥—æµç¨‹è·‘é€šäº†ï¼Œä½ çš„æ¨¡å‹å°±ç­‰äºçœŸæ­£â€œä¸Šçº¿å·¥ä½œâ€äº†ï¼ğŸ‰

ğŸ’¡ **å›ºä»¶ä»‹ç»**ï¼šè¯·åœ¨ `github` æŒ‰ç…§æ‚¨çš„å¼€å‘æ¿ç±»å‹ä¸‹è½½æœ€æ–°çš„ [PreReleaseå›ºä»¶](https://github.com/kendryte/canmv_k230/releases/tag/PreRelease) ä»¥ä¿è¯**æœ€æ–°çš„ç‰¹æ€§**è¢«æ”¯æŒï¼æˆ–è€…ä½¿ç”¨æœ€æ–°çš„ä»£ç è‡ªè¡Œç¼–è¯‘å›ºä»¶ï¼Œæ•™ç¨‹è§ï¼š[å›ºä»¶ç¼–è¯‘](https://www.kendryte.com/k230_canmv/zh/main/zh/userguide/how_to_build.html)ã€‚

### è·å–è¾“å…¥å¹¶åˆ›å»ºtensor

å‰é¢æˆ‘ä»¬è¯´äº†ï¼Œæ¨¡å‹è·‘èµ·æ¥ä¹‹åï¼Œéœ€è¦è¾“å…¥æ•°æ®æ‰èƒ½å¼€å§‹æ¨ç†å¯¹å§ï¼Ÿé‚£è¿™äº›å›¾åƒæ•°æ®ä»å“ªå„¿æ¥å‘¢ï¼Ÿè¿™èŠ‚æˆ‘ä»¬å°±æ¥èŠèŠâ€”â€”**å›¾åƒæ˜¯æ€ä¹ˆæ¥çš„ï¼Œåˆæ˜¯æ€ä¹ˆä¸€æ­¥æ­¥å˜æˆæ¨¡å‹èƒ½â€œåƒâ€çš„æ ¼å¼çš„ï¼**

å›¾åƒæ¥æºå…¶å®æœ‰ä¸‰ç§æ–¹å¼ï¼šå¯ä»¥ç”¨æ¿å­ä¸Šæå‰æ”¾å¥½çš„æœ¬åœ°å›¾ç‰‡ï¼ˆæ¯”å¦‚ä½ äº‹å…ˆæ‹·è¿›å»çš„æµ‹è¯•å›¾ï¼‰ï¼Œä¹Ÿå¯ä»¥ç”¨æ¿è½½çš„ MIPI æ‘„åƒå¤´æ‹æ‘„å®æ—¶ç”»é¢ï¼Œæˆ–è€…æ¥ä¸ª UVC æ‘„åƒå¤´æ¥å–å›¾ã€‚ä¸ç®¡ä½ é€‰å“ªç§æ–¹å¼ï¼Œæœ€ç»ˆæˆ‘ä»¬éƒ½è¦æ‹¿åˆ°ä¸€ä¸ª **Image å¯¹è±¡**â€”â€”è¿™ä¸ªå°±åƒæ˜¯â€œåŸææ–™â€ã€‚

æ‹¿åˆ°å›¾åƒä¹‹åï¼Œæˆ‘ä»¬è¿˜ä¸èƒ½ç›´æ¥é€ç»™æ¨¡å‹ã€‚ä¸­é—´è¿˜è¦â€œåŠ å·¥ä¸€ä¸‹â€ï¼æˆ‘ä»¬ä¼šç”¨ `ulab.numpy.ndarray` æŠŠå›¾ç‰‡è½¬æˆä¸€ä¸ªæ•°ç»„æ ¼å¼ï¼Œé€šè¿‡è¿™ä¸ªæ ¼å¼æˆ‘ä»¬å¯ä»¥æŸ¥çœ‹æ•°æ®çš„é€šé“é¡ºåºç­‰ä¿¡æ¯ã€‚

æœ€åï¼Œæˆ‘ä»¬ç”¨ `nncase_runtime` æ¨¡å—æä¾›çš„ APIï¼ŒæŠŠè¿™ä¸ªæ•°ç»„è½¬æˆ **tensorï¼ˆå¼ é‡ï¼‰**ã€‚è¿™æ—¶å€™æ•°æ®å°±â€œæ‰“åŒ…â€å¥½äº†ï¼Œå¯ä»¥å®‰å¿ƒé€è¿›æ¨¡å‹åšæ¨ç†äº†ï¼

é‚£ä»€ä¹ˆæ˜¯ tensor å‘¢ï¼Ÿä½ å¯ä»¥æŠŠå®ƒæƒ³è±¡æˆæ˜¯æ¨¡å‹èƒ½å¬æ‡‚çš„â€œè¯­è¨€â€â€”â€”å®ƒå°±åƒä¸€ä¸ªè£…æ•°æ®çš„ç›’å­ï¼Œæ¨¡å‹åƒè¿›å»çš„æ˜¯ tensorï¼Œæ¨ç†ä¹‹ååå‡ºæ¥çš„ç»“æœä¹Ÿæ˜¯ tensorã€‚åœ¨ `nncase_runtime` æ¨¡å—é‡Œï¼Œè¿™ä¸ªä¸œè¥¿è¢«å°è£…æˆäº† `runtime_tensor`ï¼Œä½ åªè¦æŒ‰ç…§è¦æ±‚æ„é€ å¥½ï¼Œå°±èƒ½ç›´æ¥ç”¨äº†ï¼Œç‰¹åˆ«æ–¹ä¾¿ã€‚

![image2tensor](https://www.kendryte.com/api/post/attachment?id=629)

ä¸Šå›¾è¯´æ˜äº†åœ¨è·å–è¾“å…¥å›¾åƒå¹¶åˆ›å»ºtensorçš„è¿‡ç¨‹ã€‚æ¨¡å‹æ¨ç†è¾“å…¥ä¸º`nncase_runtime runtime_tensor`ç±»å‹ï¼Œå¯ä»¥ä»`ulab.numpy.ndarray`æ•°æ®åˆ›å»ºï¼Œ`ulab.numpy.ndarray`æ•°æ®å¯ä»¥æ¥è‡ª`Image`å®ä¾‹ï¼Œ`Image`å®ä¾‹å¯ä»¥æ¥è‡ªä»¥ä¸‹ä¸‰ç§ï¼š

- å›¾ç‰‡æ–‡ä»¶
- MIPIæ‘„åƒå¤´
- UVCæ‘„åƒå¤´

æœ¬èŠ‚å°±è¿™ä¸‰ç§è¾“å…¥æ•°æ®æ¥æºè¿›è¡Œè¯¦ç»†ä»‹ç»ã€‚
  
#### å›¾ç‰‡æ–‡ä»¶è¾“å…¥

ä»å¼€å‘æ¿è¯»å…¥ä¸€å¼ å›¾ç‰‡æ•°æ®ï¼Œåˆ›å»º`Image`å®ä¾‹ï¼Œå¹¶å°†`Image`å®ä¾‹è½¬æ¢ä¸º`nncase_runtime tensor`ç±»å‹ã€‚ç¤ºä¾‹ä»£ç å¦‚ä¸‹ï¼š

```python
import os,sys
import nncase_runtime as nn
import ulab.numpy as np
import time,image,random,gc

# è¯·è‡ªè¡Œå°†æµ‹è¯•å›¾ç‰‡æ‹·è´åˆ°å¼€å‘æ¿dataç›®å½•ä¸‹
img_path="/data/test.jpg"

# ä½¿ç”¨å›¾ç‰‡åˆ›å»ºImageå®ä¾‹ï¼Œç±»å‹ä¸ºjpeg
img_data = image.Image(img_path)
print(img_data)
# å°†å›¾ç‰‡æ•°æ®è½¬æ¢æˆrgb888æ ¼å¼çš„Imageå®ä¾‹ï¼Œè¯¥ç±»å‹æ•°æ®æ˜¯RGBä¸‰é€šé“ï¼Œé¢œè‰²èŒƒå›´ä¸º[0,255]
img_rgb888=img_data.to_rgb888()
print(img_rgb888)
# å°†Imageå®ä¾‹è½¬æ¢æˆulab.numpy.ndarrayç±»å‹,è¿™æ˜¯æ•°æ®æ˜¯HWCç±»å‹çš„
img_hwc=img_rgb888.to_numpy_ref()
print(img_hwc.shape)
# è·å–hwcæ’å¸ƒçš„shape,ä½¿ç”¨ulab.numpyçš„transposeæ–¹æ³•å°†hwcè½¬æ¢ä¸ºchwæ’å¸ƒ
shape=img_hwc.shape
img_tmp = img_hwc.reshape((shape[0] * shape[1], shape[2]))
img_trans = img_tmp.transpose()
img_tmp=img_trans.copy()
img_chw=img_tmp.reshape((shape[2],shape[0],shape[1]))
print(img_chw.shape)
# ä½¿ç”¨chwæ•°æ®åˆ›å»ºnncase_runtime runtime_tensorï¼Œå¯ä»¥ç»™kmodelæ¨¡å‹æ¨ç†ä½¿ç”¨
input_tensor=nn.from_numpy(img_chw)
print(type(input_tensor))
```

ä¸Šè¿°ä»£ç çš„IDEæ‰“å°ä¿¡æ¯å¦‚ä¸‹ï¼š

```shell
{"w":1024, "h":1024, "type":"jpeg", "size":200610}
{"w":1024, "h":1024, "type":"rgb888", "size":3145728}
(1024, 1024, 3)
(3, 1024, 1024)
<class 'runtime_tensor'>
```
  
#### MIPIè§†é¢‘æµè¾“å…¥

k230 Sensoræ¨¡å—è´Ÿè´£å›¾åƒé‡‡é›†å’Œæ•°æ®å¤„ç†ï¼Œæ”¯æŒMIPIæ¥å£æ‘„åƒå¤´ã€‚MIPIæ‘„åƒå¤´å¯ä»¥é€šè¿‡Sensoræ¨¡å—é‡‡é›†å›¾åƒæ•°æ®ï¼ŒSensoræ¨¡å—æ”¯æŒå¤šé€šé“é‡‡å›¾ï¼Œå¯ä»¥å°†é‡‡é›†åˆ°çš„å›¾åƒæ•°æ®è½¬æ¢ä¸º`nncase_runtime runtime_tensor`ç±»å‹ï¼Œä¾›kmodelæ¨¡å‹æ¨ç†ä½¿ç”¨ã€‚Sensoræ¨¡å—çš„é…ç½®å’Œä½¿ç”¨è¯·å‚è€ƒ [Sensor APIæ–‡æ¡£](./api/mpp/K230_CanMV_Sensoræ¨¡å—APIæ‰‹å†Œ.md)ã€‚

ğŸ·ï¸ **å•é€šé“é‡‡å›¾**

æ¯ä¸ªMIPIæ‘„åƒå¤´æœ€å¤šå¯ä»¥å‡º3è·¯å›¾åƒé€šé“ï¼ˆå„è·¯é€šé“å¯ä»¥å…·æœ‰ä¸åŒåˆ†è¾¨ç‡æˆ–ä¸åŒæ ¼å¼ï¼‰ã€‚
è¿™é‡Œæˆ‘ä»¬é‡‡ç”¨ä¸€è·¯é€šé“è¾“å‡ºä½œä¸ºç¤ºä¾‹ï¼Œæ•°æ®å¤„ç†æµç¨‹å›¾ä¸‹å›¾æ‰€ç¤ºï¼š

![1_chn_process](https://www.kendryte.com/api/post/attachment?id=613)

æ¨¡å‹æ¨ç†è¿‡ç¨‹ä¸­çš„è¾“å…¥æ•°æ®ä¹Ÿå¯ä»¥æ¥è‡ªMIPIæ‘„åƒå¤´çš„è§†é¢‘æµï¼Œä¸ºäº†ä¿è¯è¾“å‡ºæ•°æ®ä¸ºCHWæ’å¸ƒï¼Œæˆ‘ä»¬ä¸€èˆ¬æŒ‡å®šæ‘„åƒå¤´æµå‡ºæ•°æ®æ ¼å¼ä¸º`Sensor.RGBP888`ã€‚ä»£ç å¦‚ä¸‹ï¼š

```python
import os,sys
from media.sensor import *
from media.media import *
import nncase_runtime as nn
import ulab.numpy as np
import time,image,random,gc

#-----------------------------Sensoråˆå§‹åŒ–éƒ¨åˆ†-------------------------------
# å®šä¹‰AIæ¨ç†å¸§åˆ†è¾¨ç‡
AI_RGB888P_WIDTH = ALIGN_UP(1280, 16)
AI_RGB888P_HEIGHT = 720

sensor = Sensor()
sensor.reset()
# è®¾ç½®æ°´å¹³é•œåƒå’Œå‚ç›´ç¿»è½¬ï¼Œä¸åŒå¼€å‘æ¿çš„æ–¹å‘ä¸åŒï¼Œé€šè¿‡é…ç½®è¿™ä¸¤ä¸ªå‚æ•°ä½¿ç”»é¢è½¬æ­£
#sensor.set_hmirror(False)
#sensor.set_vflip(False)

# é…ç½®sensorçš„å¤šé€šé“å‡ºå›¾ï¼Œæ¯ä¸ªé€šé“çš„å‡ºå›¾æ ¼å¼å’Œåˆ†è¾¨ç‡å¯ä»¥ä¸åŒï¼Œæœ€å¤šå¯ä»¥å‡ºä¸‰è·¯å›¾ï¼Œå‚è€ƒsensor APIæ–‡æ¡£
# é€šé“1ç»™åˆ°AIåšç®—æ³•å¤„ç†ï¼Œæ ¼å¼ä¸ºRGB888P
sensor.set_framesize(width = AI_RGB888P_WIDTH , height = AI_RGB888P_HEIGHT, chn=CAM_CHN_ID_1)
# è®¾ç½®1é€šé“çš„å‡ºå›¾æ ¼å¼
sensor.set_pixformat(Sensor.RGBP888, chn=CAM_CHN_ID_1)

# MediaManageråˆå§‹åŒ–
MediaManager.init()
# å¯åŠ¨sensor
sensor.run()
while True:
    #------------------------ä»æ‘„åƒå¤´dumpä¸€å¸§å›¾åƒå¹¶å¤„ç†----------------------------------
    print("-----------------------------------")
    # ä»æ‘„åƒå¤´1é€šé“dumpä¸€å¸§RGB888Pæ ¼å¼çš„Imageå›¾åƒ
    img=sensor.snapshot(chn=CAM_CHN_ID_1)
    print(img)
    # è½¬æ¢æˆulab.numpy.ndarrayæ ¼å¼çš„æ•°æ®ï¼ŒCHW
    img_np=img.to_numpy_ref()
    print(img_np.shape)
    # åˆ›å»ºnncase_runtime.runtime_tensorç”¨äºè¿›è¡Œåç»­çš„é¢„å¤„ç†
    runtime_tensor=nn.from_numpy(img_np)
    print(type(runtime_tensor))
    print("-----------------------------------")

sensor.stop()
time.sleep_ms(50)
MediaManager.deinit()
nn.shrink_memory_pool()
```

CanMV IDEçš„ä¸²å£è¾“å‡ºä¸ºï¼š

```shell
-----------------------------------
{"w":1280, "h":720, "type":"rgbp888", "size":2764800}
(3, 720, 1280)
<class 'runtime_tensor'>
-----------------------------------
-----------------------------------
{"w":1280, "h":720, "type":"rgbp888", "size":2764800}
(3, 720, 1280)
<class 'runtime_tensor'>
-----------------------------------
```

ğŸ·ï¸ **åŒé€šé“é‡‡å›¾**

åœ¨è¾¹ç¼˜è®¾å¤‡ä¸Šæ‰§è¡Œ AI æ¨¡å‹æ¨ç†æ—¶ï¼Œç”±äºæ¨¡å‹è®¡ç®—é‡è¾ƒå¤§ï¼Œ**æ¨ç†è¿‡ç¨‹é€šå¸¸è¾ƒè€—æ—¶**ï¼Œè€—æ—¶èŒƒå›´ä»å‡ æ¯«ç§’åˆ°æ•°ç™¾æ¯«ç§’ä¸ç­‰ã€‚è‹¥é‡‡ç”¨å•é€šé“å¤„ç†æµç¨‹ï¼š

```text
å›¾åƒé‡‡é›† â†’ æ ¼å¼è½¬æ¢ â†’ æ•°æ®é¢„å¤„ç† â†’ æ¨¡å‹æ¨ç† â†’ ç»“æœåå¤„ç† â†’ åŸå›¾ç»˜åˆ¶ â†’ å›¾åƒæ˜¾ç¤º
```

è¿™ç§ä¸²è¡Œæ‰§è¡Œæ–¹å¼ä¼šå¯¼è‡´å›¾åƒæ˜¾ç¤ºå»¶è¿Ÿè¾ƒé«˜ï¼Œå°¤å…¶æ˜¯å½“æ¨¡å‹è¾ƒå¤§æˆ–ç³»ç»Ÿèµ„æºæœ‰é™æ—¶ï¼Œç”»é¢æ›´æ–°æ˜æ˜¾å˜æ…¢ï¼Œå½±å“ç”¨æˆ·ä½“éªŒã€‚

ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œ**æ¨èä½¿ç”¨åŒé€šé“å¤„ç†æ¶æ„**ï¼Œå³é‡‡ç”¨â€œ**ä¸€é€šé“ç”¨äºå®æ—¶æ˜¾ç¤ºï¼Œå¦ä¸€é€šé“ç”¨äºæ¨¡å‹æ¨ç†**â€çš„å¼‚æ­¥å¤„ç†ç­–ç•¥ã€‚è¯¥æ¶æ„é€šè¿‡å¹¶è¡Œå¤„ç†å›¾åƒé‡‡é›†ä¸æ¨¡å‹æ¨ç†ï¼Œæœ‰æ•ˆå‡å°‘äº†æ˜¾ç¤ºå»¶è¿Ÿï¼Œæå‡äº†ç”»é¢æµç•…æ€§ã€‚åŒé€šé“å¤„ç†æœºåˆ¶å¦‚ä¸‹ï¼š

- **æ˜¾ç¤ºé€šé“**ï¼šç›´æ¥é‡‡é›†å›¾åƒå¹¶æ¨é€è‡³å±å¹•ï¼Œå®ç°ä½å»¶è¿Ÿçš„å®æ—¶ç”»é¢æ˜¾ç¤ºã€‚
- **æ¨ç†é€šé“**ï¼šç‹¬ç«‹é‡‡é›†å›¾åƒå¹¶æ‰§è¡Œå®Œæ•´çš„ AI æ¨ç†æµç¨‹ï¼ˆåŒ…æ‹¬æ ¼å¼è½¬æ¢ã€é¢„å¤„ç†ã€æ¨¡å‹æ¨ç†ä¸åå¤„ç†ï¼‰ã€‚
- **OSD å›¾å±‚åˆæˆ**ï¼šå°†æ¨¡å‹æ¨ç†ç»“æœï¼ˆå¦‚æ£€æµ‹æ¡†ã€å…³é”®ç‚¹ç­‰ï¼‰ç»˜åˆ¶ä¸º OSD å›¾å±‚ï¼Œå¹¶é€šè¿‡ç¡¬ä»¶å åŠ ä¸åŸå§‹å›¾åƒåˆæˆåå†è¾“å‡ºæ˜¾ç¤ºã€‚

è™½ç„¶æ¨ç†ç»“æœåœ¨è§†è§‰ä¸Šä¼šå­˜åœ¨ä¸€å®šå»¶è¿Ÿï¼ˆå³ä¸Šä¸€å¸§çš„æ£€æµ‹æ¡†æ˜¾ç¤ºåœ¨å½“å‰å¸§å›¾åƒä¸Šï¼‰ï¼Œä½†æ•´ä½“ç”»é¢è¿ç»­æ€§æ›´å¥½ï¼Œç”¨æˆ·ä½“éªŒæ›´åŠ æµç•…ã€‚

![2_chn_process](https://www.kendryte.com/api/post/attachment?id=614)

ä»£ç å¦‚ä¸‹ï¼š

```python
import os,sys
from media.sensor import *
from media.display import *
from media.media import *
import nncase_runtime as nn
import ulab.numpy as np
import time,image,random,gc

#-----------------------------Sensor/Displayåˆå§‹åŒ–éƒ¨åˆ†-------------------------------

# å®šä¹‰å±å¹•æ˜¾ç¤ºåˆ†è¾¨ç‡
DISPLAY_WIDTH = ALIGN_UP(800, 16)
DISPLAY_HEIGHT = 480

# å®šä¹‰AIæ¨ç†å¸§åˆ†è¾¨ç‡
AI_RGB888P_WIDTH = ALIGN_UP(1280, 16)
AI_RGB888P_HEIGHT = 720

sensor = Sensor()
sensor.reset()
# è®¾ç½®æ°´å¹³é•œåƒå’Œå‚ç›´ç¿»è½¬ï¼Œä¸åŒæ¿å­çš„æ–¹å‘ä¸åŒï¼Œé€šè¿‡é…ç½®è¿™ä¸¤ä¸ªå‚æ•°ä½¿ç”»é¢è½¬æ­£
#sensor.set_hmirror(False)
#sensor.set_vflip(False)

# é…ç½®sensorçš„å¤šé€šé“å‡ºå›¾ï¼Œæ¯ä¸ªé€šé“çš„å‡ºå›¾æ ¼å¼å’Œåˆ†è¾¨ç‡å¯ä»¥ä¸åŒï¼Œæœ€å¤šå¯ä»¥å‡ºä¸‰è·¯å›¾ï¼Œå‚è€ƒsensor APIæ–‡æ¡£
# é€šé“0ç›´æ¥ç»™åˆ°æ˜¾ç¤ºVOï¼Œæ ¼å¼ä¸ºYUV420
sensor.set_framesize(width = DISPLAY_WIDTH, height = DISPLAY_HEIGHT,chn=CAM_CHN_ID_0)
sensor.set_pixformat(Sensor.YUV420SP,chn=CAM_CHN_ID_0)
# é€šé“1ç»™åˆ°AIåšç®—æ³•å¤„ç†ï¼Œæ ¼å¼ä¸ºRGB888P
sensor.set_framesize(width = AI_RGB888P_WIDTH , height = AI_RGB888P_HEIGHT, chn=CAM_CHN_ID_1)
# set chn2 output format
sensor.set_pixformat(Sensor.RGBP888, chn=CAM_CHN_ID_1)

# ç»‘å®šé€šé“0çš„æ‘„åƒå¤´å›¾åƒåˆ°å±å¹•ï¼Œé˜²æ­¢å¦ä¸€ä¸ªé€šé“çš„AIæ¨ç†è¿‡ç¨‹å¤ªæ…¢å½±å“æ˜¾ç¤ºè¿‡ç¨‹ï¼Œå¯¼è‡´å‡ºç°å¡é¡¿æ•ˆæœ
sensor_bind_info = sensor.bind_info(x = 0, y = 0, chn = CAM_CHN_ID_0)
Display.bind_layer(**sensor_bind_info, layer = Display.LAYER_VIDEO1)

# OSDå›¾åƒåˆå§‹åŒ–,åˆ›å»ºä¸€å¸§å’Œå±å¹•åˆ†è¾¨ç‡åŒæ ·å¤§çš„é€æ˜å›¾åƒï¼Œç”¨äºç»˜åˆ¶AIæ¨ç†ç»“æœ
osd_img = image.Image(DISPLAY_WIDTH, DISPLAY_HEIGHT, image.ARGB8888)

# è®¾ç½®ä¸ºLT9611æ˜¾ç¤ºï¼Œé»˜è®¤1920x1080
#Display.init(Display.LT9611,width=DISPLAY_WIDTH,height=DISPLAY_HEIGHT,osd_num=1, to_ide = True)
## å¦‚æœä½¿ç”¨ST7701çš„LCDå±å¹•æ˜¾ç¤ºï¼Œé»˜è®¤800*480,è¿˜æ”¯æŒ640*480ç­‰ï¼Œå…·ä½“å‚è€ƒDisplayæ¨¡å—APIæ–‡æ¡£
Display.init(Display.ST7701, width=DISPLAY_WIDTH,height=DISPLAY_HEIGHT,osd_num=1, to_ide=True)

# é™åˆ¶bindé€šé“çš„å¸§ç‡ï¼Œé˜²æ­¢ç”Ÿäº§è€…å¤ªå¿«
sensor._set_chn_fps(chn = CAM_CHN_ID_0, fps = Display.fps())

# mediaåˆå§‹åŒ–
MediaManager.init()
# å¯åŠ¨sensor
sensor.run()
while True:
    #------------------------ä»æ‘„åƒå¤´dumpä¸€å¸§å›¾åƒå¹¶å¤„ç†----------------------------------
    print("---------------------------------")
    # ä»æ‘„åƒå¤´1é€šé“dumpä¸€å¸§RGB888Pæ ¼å¼çš„Imageå›¾åƒ
    img=sensor.snapshot(chn=CAM_CHN_ID_1)
    print(img)
    # è½¬æ¢æˆulab.numpy.ndarrayæ ¼å¼çš„æ•°æ®ï¼ŒCHW
    img_np=img.to_numpy_ref()
    print(img_np.shape)
    # åˆ›å»ºnncase_runtime.runtime_tensorç”¨äºè¿›è¡Œåç»­çš„é¢„å¤„ç†
    runtime_tensor=nn.from_numpy(img_np)
    print(type(runtime_tensor))
    osd_img.clear()
    osd_img.draw_string_advanced( 20 , 20, 32, "è¿™é‡Œæ¨¡æ‹Ÿç»˜åˆ¶ç»“æœ", color=(0,255,0))
    print("---------------------------------")
    #------------------------åœ¨å±å¹•æ˜¾ç¤ºæ£€æµ‹æ¡†ç»“æœ----------------------------------------
    Display.show_image(osd_img)
    gc.collect()

sensor.stop()
Display.deinit()
time.sleep_ms(50)
MediaManager.deinit()
nn.shrink_memory_pool()
```

CanMV IDEçš„ä¸²å£è¾“å‡ºä¸ºï¼š

```shell
---------------------------------
{"w":1280, "h":720, "type":"rgbp888", "size":2764800}
(3, 720, 1280)
<class 'runtime_tensor'>
---------------------------------
---------------------------------
{"w":1280, "h":720, "type":"rgbp888", "size":2764800}
(3, 720, 1280)
<class 'runtime_tensor'>
---------------------------------
```
  
#### UVCè§†é¢‘æµè¾“å…¥

k230 MicroPythonåœ¨1.3ç‰ˆæœ¬ä¹‹åæ”¯æŒUSBæ‘„åƒå¤´ã€‚UVCæ¨¡å—æä¾›äº†æ‘„åƒå¤´æ£€æµ‹ã€é…ç½®å’Œå›¾åƒé‡‡é›†åŠŸèƒ½ï¼Œæ”¯æŒå•æ‘„åƒå¤´æ“ä½œã€‚è·å–çš„è§†é¢‘æµå›¾åƒä¹Ÿå¯ä»¥ä½œä¸ºkmodelæ¨¡å‹çš„è¾“å…¥å®ç°æ¨ç†ã€‚UVCæ¨ç†æµç¨‹å¦‚ä¸‹å›¾æ‰€ç¤ºï¼š

![uvc_process](https://www.kendryte.com/api/post/attachment?id=615)

è¿™é‡Œç»™å‡ºåˆ›å»º`runtime_tensor`çš„ä»£ç ï¼Œå…¶ä»–æ­¥éª¤åœ¨åé¢ç« èŠ‚ä»‹ç»ã€‚ç¤ºä¾‹ä»£ç å¦‚ä¸‹ï¼š

```python
from libs.Utils import *
import os,sys,ujson,gc,math, urandom
from media.display import *
from media.media import *
from media.uvc import *
import nncase_runtime as nn
import ulab.numpy as np
import image
from nonai2d import CSC

# æ˜¾ç¤ºå±å¹•åˆ†è¾¨ç‡
DISPLAY_WIDTH = ALIGN_UP(800, 16)
DISPLAY_HEIGHT = 480

# å®šä¹‰AIæ¨ç†å¸§åˆ†è¾¨ç‡,ä»…æ”¯æŒusbæ‘„åƒå¤´æ”¯æŒçš„åˆ†è¾¨ç‡
AI_RGB888P_WIDTH = 640
AI_RGB888P_HEIGHT = 480

# CSCæ¨¡å—å®ç°æ ¼å¼è½¬æ¢
csc = CSC(0, CSC.PIXEL_FORMAT_RGB_888)

# ä½¿ç”¨ST7701çš„LCDå±å¹•æ˜¾ç¤ºï¼Œé»˜è®¤800*480,è¿˜æ”¯æŒ640*480ç­‰ï¼Œå…·ä½“å‚è€ƒDisplayæ¨¡å—APIæ–‡æ¡£
Display.init(Display.ST7701, width=DISPLAY_WIDTH, height=DISPLAY_HEIGHT, to_ide=True)

# MediaManageråˆå§‹åŒ–
MediaManager.init()

# ç­‰å¾…USBæ‘„åƒå¤´è¢«æ£€æµ‹åˆ°
while True:
    plugin, dev = UVC.probe()
    if plugin:
        print(f"detect USB Camera {dev}")
        break
    time.sleep_ms(100)

# è®¾ç½®UVCè¾“å‡º: 640x480 @ 30 FPS, MJPEG æ ¼å¼
mode = UVC.video_mode(640, 480, UVC.FORMAT_MJPEG, 30)
succ, mode = UVC.select_video_mode(mode)
print(f"select mode success: {succ}, mode: {mode}")

# å¯åŠ¨UVC
UVC.start(cvt=True)

while True:
    print("-------------------------------------------")
    # ä»UVCè·å–ä¸€å¸§å›¾åƒ
    img = UVC.snapshot()
    print(type(img))
    if img is not None:
        # CSCå°†å›¾ç‰‡è½¬æ¢æˆRGB888
        img = csc.convert(img)
        print(img)
        #è½¬æ¢æˆUlab.Numpy.ndarray
        img_np_hwc = img.to_numpy_ref()
        print(img_np_hwc.shape)
        # HWC->CHW,ä½¿ç”¨libs.Utilsä¸­çš„hwc2chwæ–¹æ³•
        img_np_chw = hwc2chw(img_np_hwc)
        print(img_np_chw.shape)
        # åˆ›å»ºnncase_runtime.runtime_tensor
        runtime_tensor=nn.from_numpy(img_np_chw)
        print(type(runtime_tensor))
        ############################################
        # è¿™é‡Œå¯ä»¥å®ç°æ¨¡å‹é¢„å¤„ç†->æ¨ç†->åå¤„ç†->ç»˜åˆ¶ç»“æœ
        ############################################
        # å±å¹•æ˜¾ç¤ºå›¾åƒ
        Display.show_image(img)
        # é‡Šæ”¾imgç¼“å­˜
        img.__del__()
        gc.collect()
    print("-------------------------------------------")
Display.deinit()
csc.destroy()
UVC.stop()
time.sleep_ms(100)
MediaManager.deinit()
```

CanMV IDEçš„ä¸²å£è¾“å‡ºä¸ºï¼š

```shell
-------------------------------------------
<class 'py_video_frame_info'>
{"w":640, "h":480, "type":"rgb888", "size":921600}
(480, 640, 3)
(3, 480, 640)
<class 'runtime_tensor'>
-------------------------------------------
-------------------------------------------
<class 'py_video_frame_info'>
{"w":640, "h":480, "type":"rgb888", "size":921600}
(480, 640, 3)
(3, 480, 640)
<class 'runtime_tensor'>
-------------------------------------------
```
  
### å›¾åƒtensoré¢„å¤„ç†

æˆ‘ä»¬ä¹‹å‰å·²ç»æˆåŠŸæŠŠå›¾åƒæ•°æ®å˜æˆäº†ä¸€ä¸ª tensorï¼Œä½†é—®é¢˜æ¥äº†â€”â€”è¿™ä¸ª tensor å¯èƒ½è·Ÿæ¨¡å‹â€œèƒƒå£ä¸åˆâ€ã€‚æ¯”å¦‚å¤§å°ä¸å¯¹ã€é¢œè‰²é€šé“ä¸å¯¹ã€‚è¿™æ—¶å€™ï¼Œå°±éœ€è¦æˆ‘ä»¬å‡ºé©¬ï¼ŒæŠŠ tensor åŠ å·¥ä¸€ä¸‹ï¼Œè®©å®ƒå˜æˆæ¨¡å‹å¯ä»¥æ¥å—çš„æ ¼å¼ã€‚è¿™æ•´ä¸ªå¤„ç†è¿‡ç¨‹å°±å«â€œé¢„å¤„ç†â€ï¼Œè€Œå®Œæˆè¿™ä¸ªå·¥ä½œçš„ï¼Œå°±æ˜¯æˆ‘ä»¬ä»Šå¤©çš„ä¸»è§’ â€”â€” ai2d æ¨¡å—ï¼

**ğŸ› ï¸ ä¸ºä»€ä¹ˆè¦åšé¢„å¤„ç†ï¼Ÿ**
æ¨¡å‹æ˜¯â€œæŒ‘é£Ÿâ€çš„ï¼Œå®ƒåªæ¥å—ç‰¹å®šå°ºå¯¸ã€æ ¼å¼çš„æ•°æ®ï¼Œæ¯”å¦‚ï¼šè¾“å…¥è¦æ˜¯ 320x320 å¤§å°ï¼›è¦æ˜¯ RGB é¡ºåºï¼Œè€Œä¸æ˜¯ BGRï¼›é€šé“åœ¨å‰ï¼ˆCHWï¼‰è¿˜æ˜¯é€šé“åœ¨åï¼ˆHWCï¼‰ä¹Ÿå¾—å¯¹ä¸Šã€‚å¦‚æœä¸å¯¹ï¼Œå°±ä¼šè¯†åˆ«é”™è¯¯ï¼Œç”šè‡³æ¨¡å‹ç›´æ¥ç½¢å·¥æŠ¥é”™ã€‚

**âš¡ ai2d æ¨¡å—ï¼šç¡¬ä»¶åŠ é€Ÿï¼Œé£å¿«å¤„ç†ï¼**
ai2d æ˜¯ K230 å¹³å°ä¸Šä¸“é—¨ç”¨äºå›¾åƒtensoré¢„å¤„ç†çš„æ¨¡å—ï¼Œè¿è¡Œåœ¨ç¡¬ä»¶ä¸Šï¼Œéå¸¸å¿«ï¼Œé€‚åˆåµŒå…¥å¼å®æ—¶ä»»åŠ¡ã€‚å®ƒå¯ä»¥å¸®ä½ å®Œæˆï¼šç¼©æ”¾ã€è£å‰ªã€å¡«å……ã€ä»¿å°„å˜æ¢ç­‰æ“ä½œï¼Œä½¿å¾—å›¾åƒæ•°æ®è¢«å¤„ç†æˆç¬¦åˆæ¨¡å‹è¾“å…¥è¦æ±‚çš„tensoræ•°æ®ã€‚

ä¸‹å›¾å±•ç¤ºäº†åœ¨ K230 å¹³å°ä¸Šé€šè¿‡ ai2d æ¨¡å—è¿›è¡Œé¢„å¤„ç†çš„è¾“å…¥è¾“å‡ºæµç¨‹å’Œæ ¼å¼ï¼š

![preprocess](https://www.kendryte.com/api/post/attachment?id=628)

#### é¢„å¤„ç†è¿‡ç¨‹ä»‹ç»

åœ¨éƒ¨ç½²æ¨¡å‹æ—¶ï¼Œè¾“å…¥å›¾åƒçš„ `runtime_tensor` å¹¶ä¸ä¸€å®šç¬¦åˆæ¨¡å‹çš„è¾“å…¥è§„æ ¼ã€‚ä¾‹å¦‚ï¼Œæ‘„åƒå¤´é‡‡é›†çš„å›¾åƒå°ºå¯¸å¯èƒ½ä¸º `1280Ã—720`ï¼Œè€Œæ¨¡å‹çš„è¾“å…¥è¦æ±‚æ˜¯ `320Ã—320`ï¼Œæ­¤æ—¶å°±éœ€è¦å¯¹å›¾åƒè¿›è¡Œ**é¢„å¤„ç†**ã€‚

é¢„å¤„ç†æ“ä½œåŒ…æ‹¬ä½†ä¸é™äºä»¥ä¸‹å¸¸è§æ–¹å¼ï¼š

- **ç¼©æ”¾ï¼ˆResizeï¼‰**ï¼šå°†åŸå§‹å›¾åƒè°ƒæ•´ä¸ºæ¨¡å‹è¾“å…¥æ‰€éœ€å°ºå¯¸ï¼›
- **è£å‰ªï¼ˆCropï¼‰**ï¼šä¿ç•™å›¾åƒçš„å…³é”®åŒºåŸŸï¼Œå»é™¤å†—ä½™éƒ¨åˆ†ï¼›
- **å½’ä¸€åŒ–ï¼ˆNormalizationï¼‰**ï¼šå°†åƒç´ å€¼æ˜ å°„åˆ°æŒ‡å®šåŒºé—´ï¼ˆå¦‚ `[0, 1]` æˆ– `[-1, 1]`ï¼‰ï¼›
- **å¡«å……ï¼ˆPaddingï¼‰**ï¼šä¸ºä¿æŒå›¾åƒçºµæ¨ªæ¯”è¿›è¡Œè¾¹ç¼˜å¡«å……ï¼Œé¿å…æ‹‰ä¼¸å˜å½¢ã€‚

å…·ä½“åº”é‡‡ç”¨å“ªäº›é¢„å¤„ç†æ–¹å¼ï¼Œéœ€æ ¹æ® **ONNX æ¨¡å‹çš„è®­ç»ƒé¢„å¤„ç†æµç¨‹**è¿›è¡Œå¯¹æ ‡è®¾ç½®ã€‚åŒæ—¶ï¼Œåœ¨å°† ONNX æ¨¡å‹è½¬æ¢ä¸º KModel çš„è¿‡ç¨‹ä¸­ï¼Œéƒ¨åˆ†é¢„å¤„ç†æ­¥éª¤ï¼ˆå¦‚æ ‡å‡†åŒ–ã€é¢œè‰²é€šé“è½¬æ¢ç­‰ï¼‰å¯é€šè¿‡ç¼–è¯‘å™¨å‚æ•°å°è£…è¿›æ¨¡å‹å†…éƒ¨ï¼Œè¿™äº›æ“ä½œåœ¨éƒ¨ç½²æ—¶**æ— éœ€å†æ¬¡å®ç°**ï¼Œç”± KModel è‡ªåŠ¨å®Œæˆã€‚

> âš ï¸ **æ³¨æ„**ï¼š
> å¯¹é¢„å¤„ç†æµç¨‹éœ€æœ‰æ¸…æ™°ç†è§£ï¼Œå°¤å…¶åœ¨è¿›è¡Œå›¾åƒ**ç­‰æ¯”ä¾‹å¡«å……ï¼ˆAspect Ratio Paddingï¼‰**æ—¶ï¼Œç”¨æˆ·å¯é€‰æ‹©ä¸åŒç­–ç•¥ï¼š
>
> - **åŒè¾¹å¡«å……**ï¼šåœ¨å›¾åƒçš„ä¸Šä¸‹å’Œå·¦å³ä¸¤ä¾§å‡è¿›è¡Œå¡«å……ï¼Œä½¿å›¾åƒå±…ä¸­ï¼›
> - **å•è¾¹å¡«å……**ï¼šä»…åœ¨å›¾åƒä¸€ä¾§ï¼ˆå¦‚ä¸Š/å·¦æˆ–ä¸‹/å³ï¼‰å¡«å……ï¼Œä¿æŒä¸€è¾¹å¯¹é½ã€‚
>
> ä¸åŒå¡«å……æ–¹å¼ä¼šå½±å“æ¨¡å‹æ¨ç†è¾“å‡ºåæ ‡çš„å¤åŸé€»è¾‘ï¼Œå› æ­¤åœ¨åå¤„ç†é˜¶æ®µéœ€è¦**åŒ¹é…ç›¸åº”çš„åæ ‡å˜æ¢è§„åˆ™**ï¼Œç¡®ä¿ç»“æœæ­£ç¡®æ˜ å°„å›åŸå§‹å›¾åƒã€‚

#### ai2dæ¨¡å—ä»‹ç»

åœ¨ MicroPython æ–¹æ¡ˆä¸­ï¼Œå¸¸è§çš„å›¾åƒé¢„å¤„ç†æ“ä½œé€šå¸¸é€šè¿‡ `nncase_runtime.ai2d` æ¨¡å—ç”±ç¡¬ä»¶åŠ é€Ÿå®ç°ã€‚è¯¥æ¨¡å—æ”¯æŒäº”ç§ä¸»è¦çš„é¢„å¤„ç†æ–¹æ³•ï¼ŒåŒ…æ‹¬ï¼š

- **ç¼©æ”¾ï¼ˆResizeï¼‰**
- **è£å‰ªï¼ˆCropï¼‰**
- **å¡«å……ï¼ˆPadï¼‰**
- **ä»¿å°„å˜æ¢ï¼ˆAffineï¼‰**
- **æ¯”ç‰¹ä½å³ç§»ï¼ˆShiftï¼‰**

ä½¿ç”¨ `ai2d` æ¨¡å—å¯æœ‰æ•ˆé™ä½ CPU è¿ç®—è´Ÿæ‹…ï¼Œæé«˜é¢„å¤„ç†æ•ˆç‡ï¼Œé€‚ç”¨äºæ¨¡å‹æ¨ç†å‰çš„å›¾åƒé€‚é…æ“ä½œã€‚ç›¸å…³ API ä½¿ç”¨æ–¹æ³•è¯¦è§å®˜æ–¹æ–‡æ¡£ï¼š[ai2d API æ–‡æ¡£](./api/nncase/K230_CanMV_nncase_runtime_APIæ‰‹å†Œ.md#24-nncase_runtimeai2d)ã€‚

```{attention}
(1) **Affine ä¸ Resize äº’æ–¥**ï¼šäºŒè€…ä¸å¯åŒæ—¶å¯ç”¨ï¼Œä»…èƒ½é€‰æ‹©å…¶ä¸­ä¸€ç§è¿›è¡Œå‡ ä½•å˜æ¢ã€‚  
(2) **Shift ä»…æ”¯æŒ Raw16 è¾“å…¥æ ¼å¼**ï¼Œç”¨äºç‰¹å®šæ ¼å¼çš„é«˜ä½ç§»ä½æ“ä½œã€‚  
(3) **Pad Value æŒ‰é€šé“é…ç½®**ï¼šåº”æä¾›ä¸è¾“å…¥å›¾åƒé€šé“æ•°ä¸€è‡´çš„åˆ—è¡¨ï¼Œä¾‹å¦‚ RGB å›¾åƒéœ€é…ç½®ä¸‰ä¸ªé€šé“çš„å¡«å……å€¼ã€‚  
(4) **åŠŸèƒ½æ‰§è¡Œé¡ºåºä¸º Crop â†’ Shift â†’ Resize/Affine â†’ Pad**ï¼šé…ç½®å¤šä¸ªé¢„å¤„ç†æ­¥éª¤æ—¶å¿…é¡»éµå¾ªæ­¤é¡ºåºã€‚å¦‚æœé¢„å¤„ç†æµç¨‹ä¸ç¬¦åˆæ­¤é¡ºåºï¼Œå»ºè®®åˆå§‹åŒ–å¤šä¸ª `ai2d` å®ä¾‹ï¼Œé€æ­¥å®Œæˆæ‰€éœ€å¤„ç†ã€‚
```

é€šè¿‡åˆç†é…ç½® `ai2d` æ¨¡å—ï¼Œå¯å®ç°é«˜æ•ˆã€çµæ´»çš„å›¾åƒé¢„å¤„ç†ï¼Œä»¥æ»¡è¶³ä¸åŒæ¨¡å‹å¯¹è¾“å…¥æ•°æ®çš„è¦æ±‚ã€‚

è¿™é‡Œä»¥**æ‰“å°æ•°å­—è¯†åˆ«**ä»»åŠ¡ä½¿ç”¨çš„ç­‰æ¯”ä¾‹ç¼©æ”¾å¡«å……é¢„å¤„ç†è¿‡ç¨‹ä¸ºä¾‹ï¼Œä»‹ç»`ai2d`æ¨¡å—çš„ä½¿ç”¨æ–¹æ³•ã€‚**æ ¸å¿ƒä»£ç **(æ­¤ä»£ç ä»…ç”¨äºè¯´æ˜ï¼Œæ— æ³•ç›´æ¥è¿è¡Œ)å¦‚ä¸‹ï¼š

```python
import os,sys
import nncase_runtime as nn
import ulab.numpy as np
import time,image,random,gc

# è®¡ç®—paddingç¼©æ”¾æ¯”ä¾‹å’Œä¸Šä¸‹å·¦å³å››ä¸ªæ–¹å‘å¡«å……çš„å¤§å°ï¼Œè¿™é‡Œæ˜¯å•ä¾§å¡«å……ï¼Œä¸Šå·¦å¡«å……å¤§å°å‡ä¸º0ï¼Œåœ¨ä¸‹å³è¿›è¡Œå¡«å……
def letterbox_pad_param(input_size,output_size):
    ratio_w = output_size[0] / input_size[0]  # å®½åº¦ç¼©æ”¾æ¯”ä¾‹
    ratio_h = output_size[1] / input_size[1]   # é«˜åº¦ç¼©æ”¾æ¯”ä¾‹
    ratio = min(ratio_w, ratio_h)  # å–è¾ƒå°çš„ç¼©æ”¾æ¯”ä¾‹
    new_w = int(ratio * input_size[0])  # æ–°å®½åº¦
    new_h = int(ratio * input_size[1])  # æ–°é«˜åº¦
    dw = (output_size[0] - new_w) / 2  # å®½åº¦å·®
    dh = (output_size[1] - new_h) / 2  # é«˜åº¦å·®
    top = int(round(0))
    bottom = int(round(dh * 2 + 0.1))
    left = int(round(0))
    right = int(round(dw * 2 - 0.1))
    return top, bottom, left, right,ratio


# å®šä¹‰AIæ¨ç†å¸§åˆ†è¾¨ç‡
AI_RGB888P_WIDTH = ALIGN_UP(1280, 16)
AI_RGB888P_HEIGHT = 720

# æ¨¡å‹è¾“å…¥åˆ†è¾¨ç‡
model_input_size=[320,320]

# å‡è®¾è¿™é‡Œæœ‰ä¸€ä¸ªå¤§å°ä¸º[AI_RGB888P_WIDTH,AI_RGB888P_HEIGHT]çš„å›¾åƒtensorï¼Œå®ƒå¯ä»¥ä»ä¸Šä¸€èŠ‚çš„æ•°æ®æºä¸­å¾—åˆ°
ai2d_input_tensor
# åˆå§‹åŒ–ä¸€ä¸ªç©ºçš„tensorï¼Œç”¨äºai2dè¾“å‡º
input_init_data = np.ones((1,3,model_input_size[1],model_input_size[0]),dtype=np.uint8)
ai2d_output_tensor = nn.from_numpy(input_init_data)

#------------------------é…ç½®ai2dé¢„å¤„ç†æ–¹æ³•----------------------------------------
# åˆå§‹åŒ–ai2dé¢„å¤„ç†ï¼Œå¹¶é…ç½®ai2d pad+resizeé¢„å¤„ç†ï¼Œé¢„å¤„ç†è¿‡ç¨‹è¾“å…¥åˆ†è¾¨ç‡ä¸ºå›¾ç‰‡åˆ†è¾¨ç‡ï¼Œè¾“å‡ºåˆ†è¾¨ç‡æ¨¡å‹è¾“å…¥çš„éœ€æ±‚åˆ†è¾¨ç‡ï¼Œå®ç°tensor->ai2d preprocess->tensor->kmodelçš„è¿‡ç¨‹
ai2d=nn.ai2d()
# é…ç½®ai2dæ¨¡å—çš„è¾“å…¥è¾“å‡ºæ•°æ®ç±»å‹å’Œæ ¼å¼
ai2d.set_dtype(nn.ai2d_format.NCHW_FMT, nn.ai2d_format.NCHW_FMT, np.uint8, np.uint8)
# æ ¹æ®é•¿è¾¹æ¯”ä¾‹è®¡ç®—å››ä¸ªæ–¹å‘éœ€è¦å¡«å……çš„å¤§å°
top,bottom,left,right,ratio=letterbox_pad_param([AI_RGB888P_WIDTH,AI_RGB888P_HEIGHT],model_input_size)
# è®¾ç½®å¡«å……padçš„å‚æ•°ï¼Œä¸Šä¸‹å·¦å³å¡«å……çš„å¤§å°å’Œä¸‰ä¸ªé€šé“å¡«å……çš„å…·ä½“åƒç´ å€¼
ai2d.set_pad_param(True,[0,0,0,0,top,bottom,left,right], 0, [128,128,128])
# è®¾ç½®resizeå‚æ•°ï¼Œé…ç½®æ’å€¼æ–¹æ³•
ai2d.set_resize_param(True,nn.interp_method.tf_bilinear, nn.interp_mode.half_pixel)
# è®¾ç½®ai2dæ¨¡å—çš„è¾“å…¥è¾“å‡ºç»´åº¦ï¼Œå¹¶æ„å»ºbuilderå®ä¾‹
ai2d_builder = ai2d.build([1,3,AI_RGB888P_HEIGHT,AI_RGB888P_WIDTH], [1,3,model_input_size[1],model_input_size[0]])

#------------------------æ‰§è¡Œai2dé¢„å¤„ç†æ­¥éª¤----------------------------------------
# æ‰§è¡Œé¢„å¤„ç†è¿‡ç¨‹
ai2d_builder.run(ai2d_input_tensor, ai2d_output_tensor)
# å°†é¢„å¤„ç†åçš„runtime_tensorè½¬æ¢æˆulab.numpy.ndarrayæ ¼å¼
ai2d_output_np=ai2d_output_tensor.to_numpy()
print("ai2d output shape:",ai2d_output_np.shape)

#é€€å‡ºå¾ªç¯ï¼Œé‡Šæ”¾èµ„æº
del ai2d
nn.shrink_memory_pool()
```

é¢„å¤„ç†åçš„æ•°æ®çš„shapeå¦‚ä¸‹ï¼š

```shell
ai2d output shape: (1, 3, 320, 320)
```

#### AIDemoä¸­çš„Ai2dæ¨¡å—

åŸºäº `nncase_runtime` æ¨¡å—æä¾›çš„æ¥å£ï¼Œåº”ç”¨å±‚å¯¹ `nncase_runtime.ai2d` è¿›è¡Œäº†**äºŒæ¬¡å°è£…**ï¼Œå…¶åº•å±‚å®ç°å’Œä½¿ç”¨`nncase_runtime.ai2d`æ˜¯ä¸€æ ·çš„ã€‚

å°è£…æ¨¡å—åœ¨çƒ§å½•å›ºä»¶åçš„ `/sdcard/libs/AI2D.py` å†…ï¼Œæä¾›çš„æ¥å£è§ï¼š[Ai2d æ¨¡å— API æ‰‹å†Œ](https://www.kendryte.com/k230_canmv/zh/main/zh/api/aidemo/Ai2d%20%E6%A8%A1%E5%9D%97%20API%20%E6%89%8B%E5%86%8C.html)ã€‚

ä¸ºäº†å¸®åŠ©ç”¨æˆ·æ›´å¥½çš„å®ç°é¢„å¤„ç†è¿‡ç¨‹ï¼ŒAi2dæ–‡æ¡£æä¾›äº†é’ˆå¯¹äº”ç§é¢„å¤„ç†æ–¹æ³•çš„ç¤ºä¾‹ï¼Œå¹¶å°†å¤„ç†ç»“æœå®ç°å¯è§†åŒ–ï¼Œç¤ºä¾‹æ–‡æ¡£è§é“¾æ¥ï¼š[Ai2dç¤ºä¾‹æ–‡æ¡£](https://www.kendryte.com/k230_canmv/zh/main/zh/example/ai/Ai2d_Examples.html)ã€‚
  
### KPUæ¨ç†

å‰é¢æˆ‘ä»¬å·²ç»æŠŠå›¾åƒé¢„å¤„ç†å¥½äº†ï¼Œè¾“å…¥ tensor ä¹Ÿå‡†å¤‡å°±ç»ªâ€”â€”ç°åœ¨ç»ˆäºè½®åˆ°**ä¸»è§’ç™»åœº**å•¦ï¼Œé‚£å°±æ˜¯æˆ‘ä»¬çš„â€œç¥ç»ç½‘ç»œåŠ é€Ÿå•å…ƒâ€â€”â€”**KPU**ï¼

KPU æ˜¯ K230 ä¸Šä¸“é—¨ç”¨æ¥è·‘ç¥ç»ç½‘ç»œæ¨¡å‹çš„ç¡¬ä»¶åŠ é€Ÿå™¨ï¼Œå®ƒçš„ä½œç”¨å°±æ˜¯ï¼š**æ¨¡å‹äº¤ç»™æˆ‘ï¼Œæ¨ç†æˆ‘æ¥æï¼**
ä¸è¿‡åœ¨å¼€å§‹ä¹‹å‰ï¼Œæˆ‘ä»¬å¾—å…ˆå‘Šè¯‰å®ƒï¼šå˜¿ï¼Œæˆ‘è¦ç”¨å“ªä¸ªæ¨¡å‹ï¼æ‰€ä»¥ä½ éœ€è¦æå‰æŠŠ `.kmodel` æ–‡ä»¶æ”¾è¿› K230 çš„æ¿å­é‡Œï¼Œç„¶ååœ¨ä»£ç é‡ŒæŠŠè¿™ä¸ªæ¨¡å‹åŠ è½½è¿› KPUã€‚

æ¥ç€ï¼Œå°±è¦è®¾ç½®è¾“å…¥å•¦â€”â€”æˆ‘ä»¬ä¹‹å‰ç”¨ ai2d æ¨¡å—å¤„ç†å¥½çš„ tensor å°±æ´¾ä¸Šç”¨åœºäº†ï¼Œä½œä¸ºæ¨¡å‹è¾“å…¥ä¼ ç»™ KPUã€‚ç„¶åï¼Œå°±å¯ä»¥è®© KPU å¼€å§‹é£é€Ÿåœ°è·‘æ¨¡å‹å•¦ï¼

æ¨¡å‹ä¸€è·‘å®Œï¼ŒKPU ä¼šæŠŠç»“æœè¿”å›ç»™æˆ‘ä»¬ï¼Œè¿™ä¸ªç»“æœæ˜¯ä¸€ä¸ª **è¾“å‡º tensor**ï¼Œé‡Œé¢å°±æ˜¯æ¨¡å‹æ¨ç†å‡ºæ¥çš„åŸå§‹æ•°æ®ã€‚ä½†æ˜¯è¿™ä¸ªæ ¼å¼äººçœ‹ä¸æ‡‚ä¹Ÿä¸å¥½ç”¨ï¼Œæ‰€ä»¥æˆ‘ä»¬è¿˜å¾—åšä¸€æ­¥â€œç¿»è¯‘â€ï¼šæŠŠè¾“å‡º tensor è½¬æˆ `ulab.numpy.ndarray` è¿™ç§æ•°ç»„æ ¼å¼ï¼Œæ–¹ä¾¿æˆ‘ä»¬åšåç»­åˆ†æï¼Œæ¯”å¦‚åˆ¤æ–­è¯†åˆ«å‡ºçš„æ˜¯å“ªä¸ªæ•°å­—ã€å®ƒçš„ä½ç½®åœ¨å“ªå„¿ç­‰ç­‰ã€‚

ä¸‹å›¾æ˜¯ä½¿ç”¨ KPU å®ç°æ¨¡å‹æ¨ç†çš„è¿‡ç¨‹ï¼Œæ¨¡å‹æ¨ç†è¿‡ç¨‹åŒ…æ‹¬åŠ è½½æ¨¡å‹ã€è®¾ç½®æ¨¡å‹è¾“å…¥ã€æ‰§è¡Œæ¨¡å‹æ¨ç†ã€è·å–æ¨¡å‹è¾“å‡ºï¼š

![kpu_run](https://www.kendryte.com/api/post/attachment?id=631)

KPUæ˜¯ä¸€ä¸ªä¸“é—¨ç”¨äºæ·±åº¦å­¦ä¹ çš„åŠ é€Ÿå¼•æ“ï¼Œå®ç°å¯¹ç¥ç»ç½‘ç»œæ¨¡å‹çš„è®¡ç®—è¿‡ç¨‹è¿›è¡ŒåŠ é€Ÿã€‚åœ¨MicroPythonä¸­ï¼Œ`nncase_runtime.kpu` æ¨¡å—æä¾›äº†è°ƒç”¨KPUæ¨ç†æ¨¡å‹çš„æ¥å£ã€‚è¯¥æ¨¡å—çš„APIæ–‡æ¡£è§é“¾æ¥ï¼š[nncase_runtime APIæ–‡æ¡£](https://www.kendryte.com/k230_canmv/zh/main/zh/api/nncase/K230_CanMV_nncase_runtime_API%E6%89%8B%E5%86%8C.html)ã€‚

è¿™é‡Œç»™å‡ºä½¿ç”¨`nncase_runtime.kpu`æ¨¡å—è¿›è¡ŒKPUæ¨ç†çš„æ ¸å¿ƒä»£ç ï¼ˆæ­¤ä»£ç ä»…ç”¨äºè¯´æ˜ï¼Œæ— æ³•ç›´æ¥è¿è¡Œï¼‰å¦‚ä¸‹ï¼š

```python
import os,sys
import nncase_runtime as nn
import ulab.numpy as np
import time,image,random,gc
from libs.Utils import *

# å‡è®¾è¿™é‡Œæœ‰ä¸€ä¸ªai2dæ¨¡å—å¤„ç†å®Œæˆåçš„tensor
ai2d_output_tensor

#-----------------------------AIæ¨¡å‹åˆå§‹åŒ–+æ¨ç†éƒ¨åˆ†-------------------------------
# Kmodelæ¨¡å‹è·¯å¾„
kmodel_path="/sdcard/best.kmodel"

# åˆ›å»ºkpuå®ä¾‹
kpu=nn.kpu()
# åŠ è½½kmodelæ¨¡å‹
kpu.load_kmodel(kmodel_path)

# è®¾ç½®kpuçš„ç¬¬0ä¸ªè¾“å…¥ä¸ºai2dé¢„å¤„ç†åçš„tensorï¼Œå¦‚æœæœ‰å¤šä¸ªï¼Œå¯ä»¥ä¾æ¬¡è®¾ç½®
kpu.set_input_tensor(0,ai2d_output_tensor)
# åœ¨kpuä¸Šæ‰§è¡Œæ¨¡å‹æ¨ç†
kpu.run()
#------------------------è·å–æ¨¡å‹æ¨ç†ç»“æŸçš„è¾“å‡º----------------------------------------
# è·å–æ¨¡å‹æ¨ç†çš„è¾“å‡ºtensorï¼Œå¹¶å°†å…¶è½¬æ¢æˆulab.numpy.ndarrayæ•°æ®è¿›è¡Œåå¤„ç†
results=[]
for i in range(kpu.outputs_size()):
    output_i_tensor = kpu.get_output_tensor(i)
    result_i = output_i_tensor.to_numpy()
    print(f"output {i}:",result_i.shape)
    results.append(result_i)
    del output_i_tensor
del ai2d
del kpu
time.sleep_ms(50)
nn.shrink_memory_pool()
```

å¯¹äº**å››ç±»æ‰“å°æ•°å­—è¯†åˆ«ä»»åŠ¡**ï¼Œkpuæ¨¡å‹æ¨ç†çš„è¾“å‡ºåªæœ‰ä¸€ä¸ªï¼Œè¾“å‡ºshapeä¸º[1,8,2100]ã€‚è¾“å‡ºçš„æ•°æ®shapeå¦‚ä¸‹å›¾ï¼š

![output_shape](https://www.kendryte.com/api/post/attachment?id=634)

### åå¤„ç†

æ¨¡å‹æ¨ç†å·²ç»è·‘å®Œå•¦ï¼ŒKPU ç»™äº†æˆ‘ä»¬ä¸€å¤§ä¸²â€œæ•°å­—æ•°ç»„â€å½“ä½œç»“æœï¼Œä½†åˆ«é«˜å…´å¤ªæ—©â€”â€”è¿™äº›æ•°å­—ä¹ä¸€çœ‹æ ¹æœ¬ä¸çŸ¥é“æ˜¯ä»€ä¹ˆæ„æ€ã€‚æ‰€ä»¥ï¼Œæ¥ä¸‹æ¥çš„å·¥ä½œï¼Œå°±æ˜¯è¦æŠŠè¿™äº›æ•°æ®**ç¿»è¯‘æˆäººç±»èƒ½çœ‹æ‡‚çš„å†…å®¹**ï¼Œæ¯”å¦‚ï¼šç”»é¢é‡Œå‡ºç°äº†å“ªä¸ªæ•°å­—ï¼Ÿåœ¨ä»€ä¹ˆä½ç½®ï¼Ÿè¿™ä¸ªè¯†åˆ«ç»“æœé ä¸é è°±ï¼Ÿ

ä¸¾ä¸ªä¾‹å­ï¼Œæˆ‘ä»¬è¿™ä¸ªâ€œå››ç±»æ‰“å°æ•°å­—è¯†åˆ«â€æ¨¡å‹çš„è¾“å‡ºå½¢çŠ¶æ˜¯`[1, 8, 2100]`ï¼Œæ„æ€æ˜¯æ€»å…±æœ‰ 2100 ä¸ªå€™é€‰æ¡†ï¼Œæ¯ä¸ªæ¡†ç”¨ 8 ä¸ªæ•°å­—æ¥æè¿°ã€‚å…·ä½“æ˜¯ä»€ä¹ˆå‘¢ï¼Ÿå‰ 4 ä¸ªæ˜¯æ¡†çš„ä½ç½®ï¼ˆä¸­å¿ƒç‚¹çš„ Xã€Y åæ ‡ï¼ŒåŠ ä¸Šå®½åº¦å’Œé«˜åº¦ï¼‰ï¼Œå 4 ä¸ªæ˜¯å››ç§æ•°å­—ï¼ˆ0ã€1ã€2ã€3ï¼‰çš„â€œå¾—åˆ†â€ï¼Œä¹Ÿå°±æ˜¯æ¨¡å‹å¯¹æ¯ç±»çš„åˆ¤æ–­ä¿¡å¿ƒã€‚

æˆ‘ä»¬è¦åšçš„ç¬¬ä¸€æ­¥ï¼Œå°±æ˜¯ä»è¿™ 4 ä¸ªå¾—åˆ†é‡Œï¼ŒæŒ‘å‡ºå¾—åˆ†æœ€é«˜çš„é‚£ä¸ªï¼Œæ‹¿åˆ°å®ƒçš„ç±»åˆ«ç¼–å·å’Œå¯¹åº”çš„åˆ†æ•°ï¼Œè¿™å°±ä»£è¡¨è¿™ä¸ªæ¡†æœ€å¯èƒ½æ˜¯ä»€ä¹ˆæ•°å­—ï¼Œä»¥åŠæ¨¡å‹æœ‰å¤šç¡®å®šæ˜¯è¿™ä¸ªæ•°å­—ã€‚

ç„¶åï¼Œå†å¤„ç†ä¸€ä¸‹ä½ç½®ã€‚æ¨¡å‹è¾“å‡ºçš„æ˜¯æ¡†çš„â€œä¸­å¿ƒç‚¹ + å®½é«˜â€ï¼Œä½†æˆ‘ä»¬é€šå¸¸æ›´ä¹ æƒ¯ç”¨â€œå·¦ä¸Šè§’åæ ‡ + å³ä¸‹è§’åæ ‡â€çš„æ–¹å¼ï¼Œè¿™æ ·æ‰èƒ½æ–¹ä¾¿åé¢åš NMS æ“ä½œã€‚

é‚£ NMSï¼ˆéæå¤§å€¼æŠ‘åˆ¶ï¼‰ æ˜¯å•¥å‘¢ï¼Ÿä½ å¯ä»¥ç†è§£ä¸ºâ€œå»é‡â€ã€‚æœ‰æ—¶å€™æ¨¡å‹å¤ªâ€œçƒ­æƒ…â€ï¼Œå¯¹åŒä¸€ä¸ªæ•°å­—æ¡†å‡ºå¥½å‡ ä¸ªï¼Œæˆ‘ä»¬ä¸éœ€è¦é‚£ä¹ˆå¤šâ€”â€”åªä¿ç•™å¾—åˆ†æœ€é«˜çš„é‚£ä¸€ä¸ªï¼Œå…¶å®ƒé‡å å¤ªå¤šçš„å…¨åˆ æ‰ï¼Œå¹²å¹²å‡€å‡€ï¼è¿™ä¸€æ­¥å°±å«åš NMSï¼Œå‡ ä¹æ‰€æœ‰ç›®æ ‡æ£€æµ‹çš„æ¨¡å‹åå¤„ç†éƒ½ä¼šæœ‰è¿™ä¸€æ­¥ï¼Œéå¸¸å…³é”®ï¼

æœ€åï¼Œè¿˜æœ‰ä¸ªç»†èŠ‚å°±æ˜¯ï¼šæ¨¡å‹æ˜¯å¯¹è¾“å…¥å°ºå¯¸åšæ¨ç†çš„ï¼Œæ¯”å¦‚æˆ‘ä»¬è¾“å…¥çš„æ˜¯ 320Ã—320 çš„å›¾åƒï¼Œä½†åŸå›¾å¯èƒ½æ˜¯åˆ«çš„å¤§å°ï¼Œæ‰€ä»¥æˆ‘ä»¬è¿˜è¦æŠŠè¿™äº›åæ ‡æŒ‰æ¯”ä¾‹â€œå¤åŸâ€åˆ°åŸå›¾ä¸Šï¼Œæ‰èƒ½æ­£ç¡®ç”»æ¡†ã€‚

è¿™æ ·ä¸€é€šæ“ä½œä¸‹æ¥ï¼Œæˆ‘ä»¬å°±ä»æ¨¡å‹è¾“å‡ºçš„ä¸€å †â€œè°œä¹‹æ•°å­—â€ï¼Œå¾—åˆ°äº†æ¸…æ™°çš„è¯†åˆ«ç»“æœï¼š**ç”»é¢ä¸­å‡ºç°äº†å“ªä¸ªæ•°å­—ã€å®ƒåœ¨å“ªå„¿ã€è¯†åˆ«æœ‰å¤šé è°±ï¼Œæ¡†æ¡†ä¹Ÿç”»å¥½äº†ï¼**è¿™ä¸€æ­¥å°±æ˜¯ä¼ è¯´ä¸­çš„â€œåå¤„ç†â€é˜¶æ®µï¼Œæ•´ä¸ªæµç¨‹æ‰ç®—çœŸæ­£è·‘é€šäº†ï¼

ä¸‹å›¾è¯´æ˜äº†åå¤„ç†è¿‡ç¨‹çš„ä¸»è¦å·¥ä½œï¼š

![postprocess](https://www.kendryte.com/api/post/attachment?id=632)

æ¨¡å‹æ¨ç†ç»“æŸåï¼Œæ¨¡å‹çš„è¾“å‡º`tensor`è¢«è½¬æ¢æˆ`ulab.numpy.ndarray`æ ¼å¼å­˜æ”¾åœ¨`results`ä¸­ã€‚ç”¨æˆ·å¯ä»¥æ ¹æ®åº”ç”¨åœºæ™¯çš„éœ€æ±‚å®ç°åå¤„ç†ã€‚æ¯”å¦‚ï¼Œå¯¹YOLOv8æ¨¡å‹çš„è¾“å‡ºå®ç°åå¤„ç†å¾—åˆ°æ£€æµ‹æ¡†çš„åæ ‡å’Œç±»åˆ«ä¿¡æ¯ã€‚é¦–å…ˆè¦äº†è§£è¾“å‡ºçš„å«ä¹‰ï¼Œå¯¹äº[1,8,2100]çš„è¾“å‡ºï¼Œ8è¡¨ç¤º4ä¸ªæ•°æ®æ˜¯åæ ‡ä¿¡æ¯å’Œ4ä¸ªç±»çš„åˆ†æ•°ï¼Œåå¤„ç†è¿‡ç¨‹éœ€è¦æ‰¾åˆ°åˆ†æ•°æœ€å¤§çš„ç±»åˆ«ç´¢å¼•å’Œç±»åˆ«åˆ†æ•°ï¼Œå¹¶å°†åæ ‡ä¿¡æ¯ä½¿ç”¨é¢„å¤„ç†æ—¶è®¡ç®—çš„æ¯”ä¾‹å¤åŸå›åŸå›¾å°ºå¯¸ï¼Œä»**ä¸­å¿ƒç‚¹+å®½é«˜æ ¼å¼**è½¬æ¢æˆ**å·¦ä¸Šå³ä¸‹åæ ‡æ ¼å¼**ï¼Œç„¶åä½¿ç”¨ç½®ä¿¡åº¦é˜ˆå€¼ç­›æ‰ä¸€éƒ¨åˆ†æ¡†ï¼Œå†ä½¿ç”¨NMSï¼ˆéæå¤§å€¼æŠ‘åˆ¶ï¼‰æ–¹æ³•ç­›æ‰å†—ä½™é‡å æ¡†ï¼Œæœ€åå¾—åˆ°çš„æ‰æ˜¯åŸºäºåŸå›¾çš„æ£€æµ‹æ¡†ä¿¡æ¯ã€‚é’ˆå¯¹**å››ç±»æ‰“å°æ•°å­—è¯†åˆ«**ï¼Œæˆ‘ä»¬ç»™å‡ºè¯¥ä»»åŠ¡åå¤„ç†çš„MicroPython**æ ¸å¿ƒä»£ç **ï¼ˆæ­¤ä»£ç ä»…ç”¨äºè¯´æ˜ï¼Œæ— æ³•ç›´æ¥è¿è¡Œï¼‰å¦‚ä¸‹ï¼š

```python
import os,sys
import nncase_runtime as nn
import ulab.numpy as np
import time,image,random,gc
from libs.Utils import *

# å¤šç›®æ ‡æ£€æµ‹éæœ€å¤§å€¼æŠ‘åˆ¶æ–¹æ³•å®ç°
def nms(boxes,scores,thresh):
    """Pure Python NMS baseline."""
    x1,y1,x2,y2 = boxes[:, 0],boxes[:, 1],boxes[:, 2],boxes[:, 3]
    areas = (x2 - x1 + 1) * (y2 - y1 + 1)
    order = np.argsort(scores,axis = 0)[::-1]
    keep = []
    while order.size > 0:
        i = order[0]
        keep.append(i)
        new_x1,new_y1,new_x2,new_y2,new_areas = [],[],[],[],[]
        for order_i in order:
            new_x1.append(x1[order_i])
            new_x2.append(x2[order_i])
            new_y1.append(y1[order_i])
            new_y2.append(y2[order_i])
            new_areas.append(areas[order_i])
        new_x1 = np.array(new_x1)
        new_x2 = np.array(new_x2)
        new_y1 = np.array(new_y1)
        new_y2 = np.array(new_y2)
        xx1 = np.maximum(x1[i], new_x1)
        yy1 = np.maximum(y1[i], new_y1)
        xx2 = np.minimum(x2[i], new_x2)
        yy2 = np.minimum(y2[i], new_y2)
        w = np.maximum(0.0, xx2 - xx1 + 1)
        h = np.maximum(0.0, yy2 - yy1 + 1)
        inter = w * h
        new_areas = np.array(new_areas)
        ovr = inter / (areas[i] + new_areas - inter)
        new_order = []
        for ovr_i,ind in enumerate(ovr):
            if ind < thresh:
                new_order.append(order[ovr_i])
        order = np.array(new_order,dtype=np.uint8)
    return keep

# å‡è®¾resultsä¸­åŒ…å«æ¨¡å‹æ¨ç†çš„è¾“å‡ºæ•°æ®
results=[]

#------------------------æ¨ç†è¾“å‡ºçš„åå¤„ç†æ­¥éª¤----------------------------------------
# æ¨¡å‹è¾“å‡ºåªæœ‰1ä¸ªï¼Œä¹Ÿå°±æ˜¯results[0]çš„shapeä¸º[1, 8ï¼Œ2100]ï¼Œè½¬æ¢æˆ[2100,8]æ–¹ä¾¿ä¾æ¬¡å¤„ç†æ¯ä¸ªæ¡†
output_data=results[0][0].transpose()
# æ¯ä¸ªæ¡†å‰å››ä¸ªæ•°æ®ä¸ºä¸­å¿ƒç‚¹åæ ‡å’Œå®½é«˜
boxes_ori = output_data[:,0:4]
# å‰©ä½™æ•°æ®ä¸ºæ¯ä¸ªç±»åˆ«çš„åˆ†æ•°ï¼Œé€šè¿‡argmaxæ‰¾åˆ°åˆ†æ•°æœ€å¤§çš„ç±»åˆ«ç¼–å·å’Œåˆ†æ•°å€¼
class_ori = output_data[:,4:]
class_res=np.argmax(class_ori,axis=-1)
scores_ = np.max(class_ori,axis=-1)
# é€šè¿‡ç½®ä¿¡åº¦é˜ˆå€¼ç­›é€‰æ¡†ï¼ˆå°äºç½®ä¿¡åº¦é˜ˆå€¼çš„ä¸¢å¼ƒï¼‰ï¼ŒåŒæ—¶å¤„ç†åæ ‡ä¸ºx1,y1,x2,y2ï¼Œä¸ºæ¡†çš„å·¦ä¸Šå’Œå³ä¸‹çš„åæ ‡,æ³¨æ„æ¯”ä¾‹å˜æ¢ï¼Œå°†è¾“å…¥åˆ†è¾¨ç‡åæ ‡(model_input_size)è½¬æ¢æˆåŸå›¾åæ ‡(AI_RGB888P_WIDTH,AI_RGB888P_HEIGHT)
boxes,inds,scores=[],[],[]
for i in range(len(boxes_ori)):
    if scores_[i]>confidence_threshold:
        x,y,w,h=boxes_ori[i][0],boxes_ori[i][1],boxes_ori[i][2],boxes_ori[i][3]
        x1 = int((x - 0.5 * w)/ratio)
        y1 = int((y - 0.5 * h)/ratio)
        x2 = int((x + 0.5 * w)/ratio)
        y2 = int((y + 0.5 * h)/ratio)
        boxes.append([x1,y1,x2,y2])
        inds.append(class_res[i])
        scores.append(scores_[i])
#å¦‚æœç¬¬ä¸€è½®ç­›é€‰åè¿˜æœ‰æ¡†ï¼Œç»§ç»­ä¸‹ä¸€å¸§å¤„ç†
if len(boxes)!=0:
    # å°†listè½¬æ¢æˆulab.numpy.ndarrayæ–¹ä¾¿å¤„ç†
    boxes = np.array(boxes)
    scores = np.array(scores)
    inds = np.array(inds)
    # NMSè¿‡ç¨‹,å»é™¤é‡å çš„å†—ä½™æ¡†ï¼Œkeepä¸ºNMSå¤„ç†åå‰©ä½™æ¡†çš„ç´¢å¼•åˆ—è¡¨
    keep = nms(boxes,scores,nms_threshold)
    dets = np.concatenate((boxes, scores.reshape((len(boxes),1)), inds.reshape((len(boxes),1))), axis=1)
    # å¾—åˆ°æœ€åçš„æ£€æµ‹æ¡†çš„ç»“æœ
    det_res = []
    for keep_i in keep:
        det_res.append(dets[keep_i])
    det_res = np.array(det_res)
    print("boxes number:",det_res.shape[0])
```

ä¸Šè¿°ä»£ç ç»™å‡ºäº†YOLOv8 å››ç±»æ‰“å°æ•°å­—è¯†åˆ«æ¨¡å‹çš„åå¤„ç†æ­¥éª¤ï¼Œè¿™é‡Œçš„åå¤„ç†å…¨éƒ¨ä½¿ç”¨MicroPythonæ¨¡å—å®ç°ï¼Œæ•ˆç‡ä¸é«˜ã€‚

é’ˆå¯¹è¿™ä¸€ç‰¹ç‚¹ï¼Œæˆ‘ä»¬ä½¿ç”¨C++å¯¹YOLOç›¸å…³çš„åå¤„ç†åšäº†å°è£…ã€‚YOLOç›¸å…³çš„æ¨¡å‹å¯ä»¥ä½¿ç”¨è¯¥æ–¹æ³•ï¼Œå‚è€ƒï¼š[YOLOå¤§ä½œæˆ˜](https://www.kendryte.com/k230_canmv/zh/main/zh/example/ai/YOLO%E5%A4%A7%E4%BD%9C%E6%88%98.html)ã€‚
  
### ç»“æœç»˜åˆ¶

ç°åœ¨æˆ‘ä»¬å·²ç»å¾—åˆ°äº†è¯†åˆ«ç»“æœå•¦ï¼æ¯ä¸ªæ•°å­—çš„â€œèº«ä»½â€å’Œâ€œä½ç½®â€æˆ‘ä»¬éƒ½çŸ¥é“äº†ï¼Œæ¥ä¸‹æ¥å°±æ˜¯è®©è¿™äº›ç»“æœ**å˜å¾—â€œçœ‹å¾—è§â€**â€”â€”ä¹Ÿå°±æ˜¯åœ¨å›¾åƒä¸Šç”»å‡ºæ£€æµ‹æ¡†ã€æ ‡ä¸Šæ•°å­—ï¼Œå‘Šè¯‰å¤§å®¶ï¼šâ€œçœ‹ï¼è¿™é‡Œæœ‰ä¸ª 1ï¼â€ã€â€œé‚£è¾¹æ˜¯ä¸ª 3ï¼â€

ä¸è¿‡ï¼Œäº‹æƒ…æ²¡é‚£ä¹ˆç®€å•â€”â€”ä½ çš„æ¨¡å‹æ˜¯å¯¹ 320Ã—320 çš„å›¾åƒåšçš„è¯†åˆ«ï¼Œä½†å±å¹•å¯èƒ½æ˜¯ 800Ã—480ã€1920Ã—1080ï¼Œç”šè‡³åˆ«çš„å°ºå¯¸ã€‚å¦‚æœç›´æ¥æŠŠæ¨¡å‹çš„æ¡†ç”»åœ¨å±å¹•ä¸Šï¼Œé‚£ä½ç½®å¯èƒ½å°±å…¨æ­ªäº†ï¼æ‰€ä»¥æˆ‘ä»¬è¦åšä¸€ä»¶éå¸¸é‡è¦çš„äº‹ï¼š**æŠŠå›¾åƒåæ ‡â€œæ˜ å°„â€æˆå±å¹•åæ ‡**ï¼Œä¹Ÿå°±æ˜¯è¯´æŠŠæ¡†çš„ä½ç½®æŒ‰æ¯”ä¾‹è½¬æ¢ä¸€ä¸‹ï¼Œè®©å®ƒåœ¨å±å¹•ä¸Šåˆšåˆšå¥½ã€‚

ç”»è¿™äº›è¯†åˆ«ä¿¡æ¯çš„æ—¶å€™ï¼Œæˆ‘ä»¬ä¸€èˆ¬ä¸ä¼šç›´æ¥åŠ¨åŸå›¾ï¼Œè€Œæ˜¯åˆ›å»ºä¸€ä¸ªå«åš **OSDï¼ˆOn-Screen Displayï¼‰å’Œå±å¹•ä¸€æ ·å¤§**çš„â€œé€æ˜å›¾å±‚â€ï¼Œå°±åƒåœ¨ç…§ç‰‡ä¸Šè´´äº†ä¸€å¼ ç»ç’ƒè†œï¼Œæˆ‘ä»¬å°±åœ¨è¿™ä¸Šé¢ç”»æ¡†ã€æ ‡ç±»åˆ«ï¼Œä¸ä¼šå½±å“åº•ä¸‹çš„ç”»é¢ã€‚

æœ€åä¸€æ­¥ï¼Œå°±æ˜¯æŠŠè¿™ä¸ª OSD å›¾å±‚å’ŒåŸå§‹å›¾åƒå åŠ åœ¨ä¸€èµ·ï¼Œä¸€èµ·æ˜¾ç¤ºåˆ°å±å¹•ä¸Šï¼è¿™æ ·ä½ å°±èƒ½æ¸…æ¥šåœ°çœ‹åˆ°ï¼šæ¯ä¸ªæ•°å­—è¢«è¯†åˆ«å‡ºæ¥äº†ï¼Œæ¡†ä¹Ÿç”»å¾—å¦¥å¦¥çš„ï¼

ä¸‹å›¾ç»™å‡ºäº†ç»˜åˆ¶ç»“æœçš„æµç¨‹ï¼š

![draw_result](https://www.kendryte.com/api/post/attachment?id=633)

ä»¥**å››ç±»æ‰“å°æ•°å­—è¯†åˆ«**çš„æ£€æµ‹æ¡†ä¸ºä¾‹ï¼Œæˆ‘ä»¬è®¡ç®—å¾—åˆ°çš„æ£€æµ‹æ¡†åæ ‡æ˜¯åŸºäºè¾“å…¥åŸå›¾åˆ†è¾¨ç‡çš„ï¼Œå¦‚æœè¦åœ¨å±å¹•ä¸Šå®ç°æ˜¾ç¤ºï¼Œæˆ‘ä»¬éœ€è¦å°†åæ ‡ç­‰æ¯”ä¾‹è½¬æ¢æˆå±å¹•åæ ‡åˆ†è¾¨ç‡ä¸‹çš„åæ ‡ï¼Œç„¶åå°†æ•ˆæœç»˜åˆ¶åœ¨åˆå§‹åŒ–é€æ˜å›¾åƒçš„`osd_img`ä¸Šï¼Œç„¶åè°ƒç”¨`Display`æ¨¡å—çš„`show_image`æ–¹æ³•å®ç°æ˜¾ç¤ºã€‚è¿™é‡Œç»™å‡ºæ ¸å¿ƒä»£ç ï¼ˆæ­¤ä»£ç ä»…ç”¨äºè¯´æ˜ï¼Œæ— æ³•ç›´æ¥è¿è¡Œï¼‰å¦‚ä¸‹ï¼š

```python
import os,sys
from media.display import *
import ulab.numpy as np
import time,image,random,gc
from libs.Utils import *

#-----------------------------Displayåˆå§‹åŒ–éƒ¨åˆ†-------------------------------

# å®šä¹‰å±å¹•æ˜¾ç¤ºåˆ†è¾¨ç‡
DISPLAY_WIDTH = ALIGN_UP(800, 16)
DISPLAY_HEIGHT = 480

# å®šä¹‰AIæ¨ç†å¸§åˆ†è¾¨ç‡
AI_RGB888P_WIDTH = ALIGN_UP(1280, 16)
AI_RGB888P_HEIGHT = 720
labels=["0","1","2","3"]
max_boxes_num = 30
# è·å–é¢œè‰²å€¼
colors=get_colors(len(labels))

# OSDå›¾åƒåˆå§‹åŒ–,åˆ›å»ºä¸€å¸§å’Œå±å¹•åˆ†è¾¨ç‡åŒæ ·å¤§çš„é€æ˜å›¾åƒï¼Œç”¨äºç»˜åˆ¶AIæ¨ç†ç»“æœ
osd_img = image.Image(DISPLAY_WIDTH, DISPLAY_HEIGHT, image.ARGB8888)

# è®¾ç½®ä¸ºst7701,é»˜è®¤800*480
Display.init(Display.ST7701,width=DISPLAY_WIDTH,height=DISPLAY_HEIGHT,osd_num=1, to_ide = True)

# è¿™é‡Œå–äº†å‰max_boxes_numçš„æ¡†ï¼Œé˜²æ­¢æ¡†æ•°é‡è¿‡å¤š
det_res = det_res[:max_boxes_num, :]
#------------------------ç»˜åˆ¶æ£€æµ‹æ¡†ç»“æœ----------------------------------------
osd_img.clear()
# åˆ†åˆ«å¤„ç†æ¯ä¸€ä¸ªæ¡†ï¼Œå°†åŸå›¾åæ ‡(AI_RGB888P_WIDTH,AI_RGB888P_HEIGHT)è½¬æ¢æˆæ˜¾ç¤ºå±å¹•åæ ‡(DISPLAY_WIDTH,DISPLAY_HEIGHT)
for det in det_res:
    x_1, y_1, x_2, y_2 = map(lambda pos: int(round(pos, 0)), det[:4])
    draw_x= int(x_1 * DISPLAY_WIDTH // AI_RGB888P_WIDTH)
    draw_y= int(y_1 * DISPLAY_HEIGHT // AI_RGB888P_HEIGHT)
    draw_w = int((x_2 - x_1) * DISPLAY_WIDTH // AI_RGB888P_WIDTH)
    draw_h = int((y_2 - y_1) * DISPLAY_HEIGHT // AI_RGB888P_HEIGHT)
    osd_img.draw_rectangle(draw_x,draw_y, draw_w, draw_h, color=colors[int(det[5])],thickness=4)
    osd_img.draw_string_advanced( draw_x , max(0,draw_y-50), 24, labels[int(det[5])] + " {0:.3f}".format(det[4]), color=colors[int(det[5])])
#------------------------åœ¨å±å¹•æ˜¾ç¤ºæ£€æµ‹æ¡†ç»“æœ----------------------------------------
Display.show_image(osd_img)
```

é€šè¿‡ä¸Šè¿°æ­¥éª¤ï¼Œæˆ‘ä»¬åŸºæœ¬ä¸Šå°±å®Œæˆäº†ä½¿ç”¨MicroPythonçš„å¼€å‘ä¸€ä¸ªåº”ç”¨çš„å®Œæ•´æ­¥éª¤ã€‚ç”¨æˆ·ä»è½¬æ¨¡å‹å¼€å§‹ï¼Œéœ€è¦å¯¹æ¨¡å‹æ¨ç†çš„æ•´ä¸ªè¿‡ç¨‹æœ‰æ¯”è¾ƒå¥½çš„äº†è§£ã€‚
  
### æ˜¾ç¤ºè®¾å¤‡ä»‹ç»

å¯¹äºæ˜¾ç¤ºè¾“å‡ºï¼Œk230æä¾›äº†ä¸‰ç§æ˜¾ç¤ºè®¾å¤‡ï¼Œä½ å¯ä»¥é€‰æ‹©ä½¿ç”¨`HDMI/LCDå±å¹•/IDE`ä¸‰ç§æ–¹å¼ä¸­çš„ä¸€ç§ã€‚å¯¹åº”æ¨¡å—çš„APIæ–‡æ¡£è§é“¾æ¥ï¼š[Displayæ¨¡å—APIæ–‡æ¡£](https://www.kendryte.com/k230_canmv/zh/main/zh/api/mpp/K230_CanMV_Display%E6%A8%A1%E5%9D%97API%E6%89%8B%E5%86%8C.html)ã€‚ä¸‹é¢åˆ†åˆ«ä»‹ç»è¿™ä¸‰ç§æ–¹å¼ï¼š

ğŸ·ï¸ **HDMI**ï¼šè®¾å¤‡ç±»å‹ä¸º`LT9611`ï¼Œå¯ä»¥å‚ç…§APIæ–‡æ¡£æŸ¥çœ‹åˆå§‹åŒ–æ—¶æ”¯æŒçš„åˆ†è¾¨ç‡ã€å¸§ç‡ã€osdæ•°ç›®å’Œæ˜¯å¦IDEåŒæ­¥æ˜¾ç¤ºã€‚åœ¨åŒé€šé“AIæ¨ç†ä¸‹ï¼Œä¸€èˆ¬è¿˜ä¼šåˆ›å»ºä¸€å¸§å’Œå±å¹•æ˜¾ç¤ºåˆ†è¾¨ç‡åŒæ ·å¤§çš„OSDé€æ˜å›¾åƒç”¨äºç»˜åˆ¶æ¨ç†ç»“æœã€‚è°ƒç”¨`Display.show_image`æ¥å£æ—¶éœ€è¦æ³¨æ„OSDæ˜¾ç¤ºçš„å›¾å±‚ç¼–å·ï¼ŒOSDä»…æ”¯æŒåœ¨`LAYER_OSD0`/`LAYER_OSD1`/`LAYER_OSD2`/`LAYER_OSD3`å››å±‚æ˜¾ç¤ºã€‚ç¤ºä¾‹ä»£ç å¦‚ä¸‹ï¼š

```python
import os,sys
from media.display import *
from media.media import *

# å®šä¹‰å±å¹•æ˜¾ç¤ºåˆ†è¾¨ç‡
DISPLAY_WIDTH = ALIGN_UP(800, 16)
DISPLAY_HEIGHT = 480

# OSDå›¾åƒåˆå§‹åŒ–,åˆ›å»ºä¸€å¸§å’Œå±å¹•åˆ†è¾¨ç‡åŒæ ·å¤§çš„é€æ˜å›¾åƒï¼Œç”¨äºç»˜åˆ¶AIæ¨ç†ç»“æœ
osd_img = image.Image(DISPLAY_WIDTH, DISPLAY_HEIGHT, image.ARGB8888)

# è®¾ç½®ä¸ºLT9611æ˜¾ç¤ºï¼Œé»˜è®¤1920x1080
Display.init(Display.LT9611,width=DISPLAY_WIDTH,height=DISPLAY_HEIGHT,osd_num=1, to_ide = True)

MediaManager.init()
```

ğŸ·ï¸ **LCD**ï¼šè®¾å¤‡ç±»å‹ä¸º`ST7701`æˆ–`HX8399`ï¼Œå¯ä»¥å‚ç…§APIæ–‡æ¡£æŸ¥çœ‹åˆå§‹åŒ–æ—¶æ”¯æŒçš„åˆ†è¾¨ç‡ã€å¸§ç‡ã€osdæ•°ç›®å’Œæ˜¯å¦IDEåŒæ­¥æ˜¾ç¤ºã€‚åœ¨åŒé€šé“AIæ¨ç†ä¸‹ï¼Œä¸€èˆ¬è¿˜ä¼šåˆ›å»ºä¸€å¸§å’Œå±å¹•æ˜¾ç¤ºåˆ†è¾¨ç‡åŒæ ·å¤§çš„OSDé€æ˜å›¾åƒç”¨äºç»˜åˆ¶æ¨ç†ç»“æœã€‚è°ƒç”¨`Display.show_image`æ¥å£æ—¶éœ€è¦æ³¨æ„OSDæ˜¾ç¤ºçš„å›¾å±‚ç¼–å·ï¼ŒOSDä»…æ”¯æŒåœ¨`LAYER_OSD0`/`LAYER_OSD1`/`LAYER_OSD2`/`LAYER_OSD3`å››å±‚æ˜¾ç¤ºã€‚ç¤ºä¾‹ä»£ç å¦‚ä¸‹ï¼š

```python
import os,sys
from media.display import *
from media.media import *

# å®šä¹‰å±å¹•æ˜¾ç¤ºåˆ†è¾¨ç‡
DISPLAY_WIDTH = ALIGN_UP(800, 16)
DISPLAY_HEIGHT = 480

# OSDå›¾åƒåˆå§‹åŒ–,åˆ›å»ºä¸€å¸§å’Œå±å¹•åˆ†è¾¨ç‡åŒæ ·å¤§çš„é€æ˜å›¾åƒï¼Œç”¨äºç»˜åˆ¶AIæ¨ç†ç»“æœ
osd_img = image.Image(DISPLAY_WIDTH, DISPLAY_HEIGHT, image.ARGB8888)

## å¦‚æœä½¿ç”¨ST7701çš„LCDå±å¹•æ˜¾ç¤ºï¼Œé»˜è®¤800*480,è¿˜æ”¯æŒ640*480ç­‰ï¼Œå…·ä½“å‚è€ƒDisplayæ¨¡å—APIæ–‡æ¡£
Display.init(Display.ST7701, width=DISPLAY_WIDTH,height=DISPLAY_HEIGHT,osd_num=1, to_ide=True)

MediaManager.init()
```

ğŸ·ï¸ **CanMV IDEé¢„è§ˆçª—å£**ï¼šè®¾å¤‡ç±»å‹ä¸º`VIRT`ï¼Œå¯ä»¥å‚ç…§APIæ–‡æ¡£æŸ¥çœ‹åˆå§‹åŒ–æ—¶æ”¯æŒçš„åˆ†è¾¨ç‡ã€å¸§ç‡ã€osdæ•°ç›®ã€‚è¯¥æ¨¡å¼ä¸‹åªä¼šåœ¨IDEçš„å³ä¸Šæ–¹é¢„è§ˆçª—å£ä¸­æŸ¥çœ‹å›¾åƒæ•ˆæœï¼Œä¸åœ¨å¤–æ¥å±å¹•ä¸Šæ˜¾ç¤ºå†…å®¹ã€‚ç”¨æˆ·å¯åœ¨[64,64]åˆ°[4096,4096]å’Œå¸§ç‡1~200ä¹‹é—´è¿›è¡Œé…ç½®ã€‚ç¤ºä¾‹ä»£ç å¦‚ä¸‹ï¼š

```python
import os,sys
from media.display import *
from media.media import *

# å®šä¹‰å±å¹•æ˜¾ç¤ºåˆ†è¾¨ç‡
DISPLAY_WIDTH = ALIGN_UP(800, 16)
DISPLAY_HEIGHT = 480

# OSDå›¾åƒåˆå§‹åŒ–,åˆ›å»ºä¸€å¸§å’Œå±å¹•åˆ†è¾¨ç‡åŒæ ·å¤§çš„é€æ˜å›¾åƒï¼Œç”¨äºç»˜åˆ¶AIæ¨ç†ç»“æœ
osd_img = image.Image(DISPLAY_WIDTH, DISPLAY_HEIGHT, image.ARGB8888)

## å¦‚æœä½¿ç”¨VIRTåœ¨CanMV IDEä¸Šæ˜¾ç¤º
Display.init(Display.VIRT, width=DISPLAY_WIDTH,height=DISPLAY_HEIGHT,osd_num=1)

MediaManager.init()
```

ğŸ·ï¸ **CanMV IDEé¢„è§ˆå›¾ç‰‡**ï¼šè®¾å¤‡ç±»å‹ä¸º`VIRT`ï¼Œå¯ä»¥å‚ç…§APIæ–‡æ¡£æŸ¥çœ‹åˆå§‹åŒ–æ—¶æ”¯æŒçš„åˆ†è¾¨ç‡ã€å¸§ç‡ã€osdæ•°ç›®ã€‚è¯¥æ¨¡å¼ä¸‹åªä¼šåœ¨IDEçš„å³ä¸Šæ–¹é¢„è§ˆçª—å£ä¸­æŸ¥çœ‹å›¾åƒæ•ˆæœï¼Œä¸åœ¨å¤–æ¥å±å¹•ä¸Šæ˜¾ç¤ºå†…å®¹ã€‚ç”¨æˆ·ä½¿ç”¨`image`å®ä¾‹è°ƒç”¨`compress_for_ide()`å®ç°åœ¨CanMV IDEé¢„è§ˆçª—å£æ˜¾ç¤ºé™æ€å›¾åƒã€‚ç¤ºä¾‹ä»£ç å¦‚ä¸‹ï¼š

```python
import os,sys
import image

#-----------------------------è¯»å–å›¾ç‰‡éƒ¨åˆ†-------------------------------
# è¯·è‡ªè¡Œå°†æµ‹è¯•å›¾ç‰‡æ‹·è´åˆ°å¼€å‘æ¿dataç›®å½•ä¸‹
img_path="/data/test.jpg"

# ä½¿ç”¨å›¾ç‰‡åˆ›å»ºImageå®ä¾‹ï¼Œç±»å‹ä¸ºjpeg
img_data = image.Image(img_path)
# å°†å›¾ç‰‡æ•°æ®è½¬æ¢æˆrgb888æ ¼å¼çš„Imageå®ä¾‹ï¼Œè¯¥ç±»å‹æ•°æ®æ˜¯RGBä¸‰é€šé“ï¼Œé¢œè‰²èŒƒå›´ä¸º[0,255]
img_rgb888=img_data.to_rgb888()

img_rgb888.compress_for_ide()
```

### ç±»æ‰“å°æ•°å­—è¯†åˆ«éƒ¨ç½²ä»£ç 

æˆ‘ä»¬å·²ç»ä¸ºä½ å‡†å¤‡å¥½äº†å®Œæ•´çš„â€œ0â€ã€â€œ1â€ã€â€œ2â€ã€â€œ3â€å››ç±»æ‰“å°æ•°å­—è¯†åˆ«çš„ç¤ºä¾‹ä»£ç ï¼Œ**ä¸ä»…æ”¯æŒå•å¼ å›¾ç‰‡çš„æ¨ç†**ï¼Œè¿˜æ”¯æŒ**å®æ—¶è§†é¢‘æµçš„è¿ç»­è¯†åˆ«**ï¼æ— è®ºä½ æ˜¯æƒ³åœ¨é™æ€å›¾ç‰‡ä¸Šæµ‹è¯•æ¨¡å‹æ•ˆæœï¼Œè¿˜æ˜¯åœ¨æ¥å…¥æ‘„åƒå¤´åå®æ—¶æ£€æµ‹ï¼Œéƒ½å¯ä»¥å¿«é€Ÿä¸Šæ‰‹ã€‚ä½ åªéœ€è¦ç”¨å‰é¢æ­¥éª¤ä¸­å¯¼å‡ºçš„ `kmodel` æ¨¡å‹ï¼Œé…åˆæˆ‘ä»¬æä¾›çš„ç¤ºä¾‹è„šæœ¬ï¼Œå°±å¯ä»¥è½»æ¾åœ¨ K230 å¼€å‘æ¿ä¸Šéƒ¨ç½²è¿è¡Œå•¦ï¼

å¦‚æœä½ æƒ³éªŒè¯æ¨¡å‹åœ¨å›¾ç‰‡ä¸Šçš„è¯†åˆ«ç²¾åº¦å’Œå®šä½æ•ˆæœï¼Œå¯ä»¥ç›´æ¥è·‘æˆ‘ä»¬çš„ **å›¾ç‰‡è¯†åˆ«ä»£ç **ï¼›å¦‚æœä½ æƒ³å®æ—¶ä½“éªŒè¯†åˆ«è¿‡ç¨‹ä¸­çš„â€œè§†é¢‘æ•ˆæœâ€ï¼Œé‚£å°±è¯•è¯• **åŒé€šé“è§†é¢‘è¯†åˆ«ä»£ç **ï¼Œçœ‹çœ‹æ•°å­—å‡ºç°åœ¨å±å¹•ä¸Šçš„é‚£ä¸€åˆ»ï¼Œæ¡†æ¡†æ˜¯ä¸æ˜¯èƒ½ç²¾å‡†è¿½è¸ªåˆ°ä½ï¼

æ¥ä¸‹æ¥ä½ å°±å¯ä»¥å¤§èƒ†åŠ¨æ‰‹è¯•è¯•éƒ¨ç½²æµç¨‹ï¼Œæ„Ÿå— K230 ç«¯ä¾§ AI çš„è¿è¡Œæ•ˆæœï¼ŒAI å°±èƒ½è¯»æ‡‚ä½ æ‹ä¸‹çš„æ•°å­—ä¸–ç•Œï¼

#### å›¾ç‰‡è¯†åˆ«ä»£ç 

è¿™é‡Œç»™å‡ºå®Œæ•´çš„**4ç±»æ‰“å°æ•°å­—è¯†åˆ«**å›¾ç‰‡æ¨ç†ä»£ç ï¼Œæ‚¨å¯ä»¥ä½¿ç”¨ä¸Šé¢æ­¥éª¤å¾—åˆ°çš„kmodelè¿›è¡Œæµ‹è¯•ï¼š

```python
import os,sys
from media.sensor import *
from media.display import *
from media.media import *
import nncase_runtime as nn
import ulab.numpy as np
import time,image,random,gc
from libs.Utils import *

#-----------------------------å…¶ä»–å¿…è¦æ–¹æ³•---------------------------------------------
# å¤šç›®æ ‡æ£€æµ‹ éæœ€å¤§å€¼æŠ‘åˆ¶æ–¹æ³•å®ç°
def nms(boxes,scores,thresh):
    """Pure Python NMS baseline."""
    x1,y1,x2,y2 = boxes[:, 0],boxes[:, 1],boxes[:, 2],boxes[:, 3]
    areas = (x2 - x1 + 1) * (y2 - y1 + 1)
    order = np.argsort(scores,axis = 0)[::-1]
    keep = []
    while order.size > 0:
        i = order[0]
        keep.append(i)
        new_x1,new_y1,new_x2,new_y2,new_areas = [],[],[],[],[]
        for order_i in order:
            new_x1.append(x1[order_i])
            new_x2.append(x2[order_i])
            new_y1.append(y1[order_i])
            new_y2.append(y2[order_i])
            new_areas.append(areas[order_i])
        new_x1 = np.array(new_x1)
        new_x2 = np.array(new_x2)
        new_y1 = np.array(new_y1)
        new_y2 = np.array(new_y2)
        xx1 = np.maximum(x1[i], new_x1)
        yy1 = np.maximum(y1[i], new_y1)
        xx2 = np.minimum(x2[i], new_x2)
        yy2 = np.minimum(y2[i], new_y2)
        w = np.maximum(0.0, xx2 - xx1 + 1)
        h = np.maximum(0.0, yy2 - yy1 + 1)
        inter = w * h
        new_areas = np.array(new_areas)
        ovr = inter / (areas[i] + new_areas - inter)
        new_order = []
        for ovr_i,ind in enumerate(ovr):
            if ind < thresh:
                new_order.append(order[ovr_i])
        order = np.array(new_order,dtype=np.uint8)
    return keep

# è®¡ç®—paddingç¼©æ”¾æ¯”ä¾‹å’Œä¸Šä¸‹å·¦å³paddingå¤§å°
def letterbox_pad_param(input_size,output_size):
    ratio_w = output_size[0] / input_size[0]  # å®½åº¦ç¼©æ”¾æ¯”ä¾‹
    ratio_h = output_size[1] / input_size[1]   # é«˜åº¦ç¼©æ”¾æ¯”ä¾‹
    ratio = min(ratio_w, ratio_h)  # å–è¾ƒå°çš„ç¼©æ”¾æ¯”ä¾‹
    new_w = int(ratio * input_size[0])  # æ–°å®½åº¦
    new_h = int(ratio * input_size[1])  # æ–°é«˜åº¦
    dw = (output_size[0] - new_w) / 2  # å®½åº¦å·®
    dh = (output_size[1] - new_h) / 2  # é«˜åº¦å·®
    top = int(round(0))
    bottom = int(round(dh * 2 + 0.1))
    left = int(round(0))
    right = int(round(dw * 2 - 0.1))
    return top, bottom, left, right,ratio


if __name__=="__main__":
    # è¯·è‡ªè¡Œå°†æµ‹è¯•å›¾ç‰‡æ‹·è´åˆ°å¼€å‘æ¿sdcardç›®å½•ä¸‹
    img_path="/sdcard/test.jpg"
    
    # ä½¿ç”¨å›¾ç‰‡åˆ›å»ºImageå®ä¾‹ï¼Œç±»å‹ä¸ºjpeg
    img_data = image.Image(img_path)
    img_width=img_data.width()
    img_height=img_data.height()
    # å°†å›¾ç‰‡æ•°æ®è½¬æ¢æˆrgb888æ ¼å¼çš„Imageå®ä¾‹ï¼Œè¯¥ç±»å‹æ•°æ®æ˜¯RGBä¸‰é€šé“ï¼Œé¢œè‰²èŒƒå›´ä¸º[0,255]
    img_rgb888=img_data.to_rgb888()
    # å°†Imageå®ä¾‹è½¬æ¢æˆulab.numpy.ndarrayç±»å‹,è¿™æ˜¯æ•°æ®æ˜¯HWCç±»å‹çš„
    img_hwc=img_rgb888.to_numpy_ref()
    # è·å–hwcæ’å¸ƒçš„shape,ä½¿ç”¨ulab.numpyçš„transposeæ–¹æ³•å°†hwcè½¬æ¢ä¸ºchwæ’å¸ƒ
    shape=img_hwc.shape
    img_tmp = img_hwc.reshape((shape[0] * shape[1], shape[2]))
    img_trans = img_tmp.transpose()
    img_tmp=img_trans.copy()
    img_chw=img_tmp.reshape((shape[2],shape[0],shape[1]))
    # ä½¿ç”¨chwæ•°æ®åˆ›å»ºnncase_runtime runtime_tensorï¼Œå¯ä»¥ç»™kmodelæ¨¡å‹æ¨ç†ä½¿ç”¨
    ai2d_input_tensor=nn.from_numpy(img_chw)
    
    
    #-----------------------------AIæ¨¡å‹åˆå§‹åŒ–éƒ¨åˆ†-------------------------------
    # Kmodelæ¨¡å‹è·¯å¾„
    kmodel_path="/sdcard/best.kmodel"
    # ç±»åˆ«æ ‡ç­¾
    labels = ["0","1","2","3"]
    # æ¨¡å‹è¾“å…¥åˆ†è¾¨ç‡
    model_input_size=[320,320]
    # å…¶å®ƒå‚æ•°è®¾ç½®ï¼ŒåŒ…æ‹¬é˜ˆå€¼ã€æœ€å¤§æ£€æµ‹æ¡†æ•°é‡ç­‰
    confidence_threshold = 0.5
    nms_threshold = 0.4
    max_boxes_num = 30
    # ä¸åŒç±»åˆ«æ¡†çš„é¢œè‰²
    colors=get_colors(len(labels))
    
    # åˆå§‹åŒ–ai2dé¢„å¤„ç†ï¼Œå¹¶é…ç½®ai2d padding+resizeé¢„å¤„ç†ï¼Œé¢„å¤„ç†è¿‡ç¨‹è¾“å…¥åˆ†è¾¨ç‡ä¸ºå›¾ç‰‡åˆ†è¾¨ç‡ï¼Œè¾“å‡ºåˆ†è¾¨ç‡æ¨¡å‹è¾“å…¥çš„éœ€æ±‚åˆ†è¾¨ç‡ï¼Œå®ç°image->preprocess->modelçš„è¿‡ç¨‹
    ai2d=nn.ai2d()
    # é…ç½®ai2dæ¨¡å—çš„è¾“å…¥è¾“å‡ºæ•°æ®ç±»å‹å’Œæ ¼å¼
    ai2d.set_dtype(nn.ai2d_format.NCHW_FMT, nn.ai2d_format.NCHW_FMT, np.uint8, np.uint8)
    # è®¾ç½®paddingçš„å‚æ•°ï¼Œä¸Šä¸‹å·¦å³paddingçš„å¤§å°å’Œä¸‰ä¸ªé€šé“paddingçš„å…·ä½“å€¼
    top,bottom,left,right,ratio=letterbox_pad_param([img_width,img_height],model_input_size)
    ai2d.set_pad_param(True,[0,0,0,0,top,bottom,left,right], 0, [128,128,128])
    # è®¾ç½®resizeå‚æ•°ï¼Œé…ç½®æ’å€¼æ–¹æ³•
    ai2d.set_resize_param(True,nn.interp_method.tf_bilinear, nn.interp_mode.half_pixel)
    # è®¾ç½®ai2dæ¨¡å—çš„è¾“å…¥è¾“å‡ºç»´åº¦ï¼Œå¹¶æ„å»ºbuilderå®ä¾‹
    ai2d_builder = ai2d.build([1,3,img_height,img_width], [1,3,model_input_size[1],model_input_size[0]])
    # åˆå§‹åŒ–ä¸€ä¸ªç©ºçš„tensorï¼Œç”¨äºai2dè¾“å‡º
    input_init_data = np.ones((1,3,model_input_size[1],model_input_size[0]),dtype=np.uint8)
    kpu_input_tensor = nn.from_numpy(input_init_data)
    
    # åˆ›å»ºkpuå®ä¾‹
    kpu=nn.kpu()
    # åŠ è½½kmodelæ¨¡å‹
    kpu.load_kmodel(kmodel_path)
    
    #------------------------æ¨ç†å‰çš„é¢„å¤„ç†æ­¥éª¤----------------------------------------
    # æ‰§è¡Œé¢„å¤„ç†è¿‡ç¨‹
    ai2d_builder.run(ai2d_input_tensor, kpu_input_tensor)
    #------------------------ä½¿ç”¨kpuå®Œæˆæ¨¡å‹æ¨ç†--------------------------------------
    # è®¾ç½®kpuçš„ç¬¬0ä¸ªè¾“å…¥ä¸ºai2dé¢„å¤„ç†åçš„tensorï¼Œå¦‚æœæœ‰å¤šä¸ªï¼Œå¯ä»¥ä¾æ¬¡è®¾ç½®
    kpu.set_input_tensor(0,kpu_input_tensor)
    # åœ¨kpuä¸Šæ‰§è¡Œæ¨¡å‹æ¨ç†
    kpu.run()
    #------------------------è·å–æ¨¡å‹æ¨ç†ç»“æŸçš„è¾“å‡º----------------------------------------
    # è·å–æ¨¡å‹æ¨ç†çš„è¾“å‡ºtensorï¼Œå¹¶å°†å…¶è½¬æ¢æˆulab.numpy.ndarrayæ•°æ®è¿›è¡Œåå¤„ç†
    results=[]
    for i in range(kpu.outputs_size()):
        output_i_tensor = kpu.get_output_tensor(i)
        result_i = output_i_tensor.to_numpy()
        results.append(result_i)
        del output_i_tensor
    #------------------------æ¨ç†è¾“å‡ºçš„åå¤„ç†æ­¥éª¤----------------------------------------
    # æ¨¡å‹è¾“å‡ºåªæœ‰1ä¸ªï¼Œä¹Ÿå°±æ˜¯results[0]çš„shapeä¸º[1, 8ï¼Œ2100]ï¼Œè½¬æ¢æˆ[2100,8]æ–¹ä¾¿ä¾æ¬¡å¤„ç†æ¯ä¸ªæ¡†
    output_data=results[0][0].transpose()
    # æ¯ä¸ªæ¡†å‰å››ä¸ªæ•°æ®ä¸ºä¸­å¿ƒç‚¹åæ ‡å’Œå®½é«˜
    boxes_ori = output_data[:,0:4]
    # å‰©ä½™æ•°æ®ä¸ºæ¯ä¸ªç±»åˆ«çš„åˆ†æ•°ï¼Œé€šè¿‡argmaxæ‰¾åˆ°åˆ†æ•°æœ€å¤§çš„ç±»åˆ«ç¼–å·å’Œåˆ†æ•°å€¼
    class_ori = output_data[:,4:]
    class_res=np.argmax(class_ori,axis=-1)
    scores_ = np.max(class_ori,axis=-1)
    # é€šè¿‡ç½®ä¿¡åº¦é˜ˆå€¼ç­›é€‰æ¡†ï¼ˆå°äºç½®ä¿¡åº¦é˜ˆå€¼çš„ä¸¢å¼ƒï¼‰ï¼ŒåŒæ—¶å¤„ç†åæ ‡ä¸ºx1,y1,x2,y2ï¼Œä¸ºæ¡†çš„å·¦ä¸Šå’Œå³ä¸‹çš„åæ ‡,æ³¨æ„æ¯”ä¾‹å˜æ¢ï¼Œå°†è¾“å…¥åˆ†è¾¨ç‡åæ ‡(model_input_size)è½¬æ¢æˆåŸå›¾åæ ‡(img_width,img_height)
    boxes,inds,scores=[],[],[]
    for i in range(len(boxes_ori)):
        if scores_[i]>confidence_threshold:
            x,y,w,h=boxes_ori[i][0],boxes_ori[i][1],boxes_ori[i][2],boxes_ori[i][3]
            x1 = int((x - 0.5 * w)/ratio)
            y1 = int((y - 0.5 * h)/ratio)
            x2 = int((x + 0.5 * w)/ratio)
            y2 = int((y + 0.5 * h)/ratio)
            boxes.append([x1,y1,x2,y2])
            inds.append(class_res[i])
            scores.append(scores_[i])
    #å¦‚æœç¬¬ä¸€è½®ç­›é€‰åæœ‰æ¡†ï¼Œç»§ç»­ä¸‹ä¸€å¸§å¤„ç†
    if len(boxes)!=0:
        # å°†listè½¬æ¢æˆulab.numpy.ndarrayæ–¹ä¾¿å¤„ç†
        boxes = np.array(boxes)
        scores = np.array(scores)
        inds = np.array(inds)
        # NMSè¿‡ç¨‹,å»é™¤é‡å çš„å†—ä½™æ¡†ï¼Œkeepä¸ºNMSå»é™¤é‡å æ¡†åçš„ç´¢å¼•åˆ—è¡¨
        keep = nms(boxes,scores,nms_threshold)
        dets = np.concatenate((boxes, scores.reshape((len(boxes),1)), inds.reshape((len(boxes),1))), axis=1)
        # å¾—åˆ°æœ€åçš„æ£€æµ‹æ¡†çš„ç»“æœ
        det_res = []
        for keep_i in keep:
            det_res.append(dets[keep_i])
        det_res = np.array(det_res)
        # å»å‰max_box_numä¸ªï¼Œé˜²æ­¢æ£€æµ‹æ¡†è¿‡å¤š
        det_res = det_res[:max_boxes_num, :]
        #------------------------ç»˜åˆ¶æ£€æµ‹æ¡†ç»“æœ----------------------------------------
        # åˆ†åˆ«å¤„ç†æ¯ä¸€ä¸ªæ¡†,ç»˜åˆ¶ç»“æœ
        for det in det_res:
            x_1, y_1, x_2, y_2 = map(lambda pos: int(round(pos, 0)), det[:4])
            draw_x= int(x_1)
            draw_y= int(y_1)
            draw_w = int((x_2 - x_1))
            draw_h = int((y_2 - y_1))
            img_rgb888.draw_rectangle(draw_x,draw_y, draw_w, draw_h, color=colors[int(det[5])],thickness=4)
            img_rgb888.draw_string_advanced( draw_x , max(0,draw_y-50), 24, "ç±»åˆ«:"+labels[int(det[5])] + "  åˆ†æ•°:{0:.3f}".format(det[4]), color=colors[int(det[5])])
        #------------------------åœ¨å±å¹•æ˜¾ç¤ºæ£€æµ‹æ¡†ç»“æœ----------------------------------------
        img_rgb888.compress_for_ide()
    #é‡Šæ”¾èµ„æº
    del ai2d
    del kpu
    del ai2d_input_tensor
    del kpu_input_tensor
    nn.shrink_memory_pool()
    gc.collect()
```

#### åŒé€šé“è§†é¢‘è¯†åˆ«ä»£ç 

è¿™é‡Œç»™å‡ºå®Œæ•´çš„**4ç±»æ‰“å°æ•°å­—è¯†åˆ«**è§†é¢‘æ¨ç†ä»£ç ï¼Œæ‚¨å¯ä»¥ä½¿ç”¨ä¸Šé¢æ­¥éª¤å¾—åˆ°çš„kmodelè¿›è¡Œæµ‹è¯•ï¼š

```python
import os,sys
from media.sensor import *
from media.display import *
from media.media import *
import nncase_runtime as nn
import ulab.numpy as np
import time,image,random,gc
from libs.Utils import *

#-----------------------------å…¶ä»–å¿…è¦æ–¹æ³•---------------------------------------------
# å¤šç›®æ ‡æ£€æµ‹ éæœ€å¤§å€¼æŠ‘åˆ¶æ–¹æ³•å®ç°
def nms(boxes,scores,thresh):
    """Pure Python NMS baseline."""
    x1,y1,x2,y2 = boxes[:, 0],boxes[:, 1],boxes[:, 2],boxes[:, 3]
    areas = (x2 - x1 + 1) * (y2 - y1 + 1)
    order = np.argsort(scores,axis = 0)[::-1]
    keep = []
    while order.size > 0:
        i = order[0]
        keep.append(i)
        new_x1,new_y1,new_x2,new_y2,new_areas = [],[],[],[],[]
        for order_i in order:
            new_x1.append(x1[order_i])
            new_x2.append(x2[order_i])
            new_y1.append(y1[order_i])
            new_y2.append(y2[order_i])
            new_areas.append(areas[order_i])
        new_x1 = np.array(new_x1)
        new_x2 = np.array(new_x2)
        new_y1 = np.array(new_y1)
        new_y2 = np.array(new_y2)
        xx1 = np.maximum(x1[i], new_x1)
        yy1 = np.maximum(y1[i], new_y1)
        xx2 = np.minimum(x2[i], new_x2)
        yy2 = np.minimum(y2[i], new_y2)
        w = np.maximum(0.0, xx2 - xx1 + 1)
        h = np.maximum(0.0, yy2 - yy1 + 1)
        inter = w * h
        new_areas = np.array(new_areas)
        ovr = inter / (areas[i] + new_areas - inter)
        new_order = []
        for ovr_i,ind in enumerate(ovr):
            if ind < thresh:
                new_order.append(order[ovr_i])
        order = np.array(new_order,dtype=np.uint8)
    return keep

# è®¡ç®—paddingç¼©æ”¾æ¯”ä¾‹å’Œä¸Šä¸‹å·¦å³paddingå¤§å°
def letterbox_pad_param(input_size,output_size):
    ratio_w = output_size[0] / input_size[0]  # å®½åº¦ç¼©æ”¾æ¯”ä¾‹
    ratio_h = output_size[1] / input_size[1]   # é«˜åº¦ç¼©æ”¾æ¯”ä¾‹
    ratio = min(ratio_w, ratio_h)  # å–è¾ƒå°çš„ç¼©æ”¾æ¯”ä¾‹
    new_w = int(ratio * input_size[0])  # æ–°å®½åº¦
    new_h = int(ratio * input_size[1])  # æ–°é«˜åº¦
    dw = (output_size[0] - new_w) / 2  # å®½åº¦å·®
    dh = (output_size[1] - new_h) / 2  # é«˜åº¦å·®
    top = int(round(0))
    bottom = int(round(dh * 2 + 0.1))
    left = int(round(0))
    right = int(round(dw * 2 - 0.1))
    return top, bottom, left, right,ratio


#-----------------------------Sensor/Displayåˆå§‹åŒ–éƒ¨åˆ†-------------------------------

# å®šä¹‰å±å¹•æ˜¾ç¤ºåˆ†è¾¨ç‡
DISPLAY_WIDTH = ALIGN_UP(800, 16)
DISPLAY_HEIGHT = 480

# å®šä¹‰AIæ¨ç†å¸§åˆ†è¾¨ç‡
AI_RGB888P_WIDTH = ALIGN_UP(1280, 16)
AI_RGB888P_HEIGHT = 720

sensor = Sensor()
sensor.reset()
# è®¾ç½®æ°´å¹³é•œåƒå’Œå‚ç›´ç¿»è½¬ï¼Œä¸åŒæ¿å­çš„æ–¹å‘ä¸åŒï¼Œé€šè¿‡é…ç½®è¿™ä¸¤ä¸ªå‚æ•°ä½¿ç”»é¢è½¬æ­£
#sensor.set_hmirror(False)
#sensor.set_vflip(False)

# é…ç½®sensorçš„å¤šé€šé“å‡ºå›¾ï¼Œæ¯ä¸ªé€šé“çš„å‡ºå›¾æ ¼å¼å’Œåˆ†è¾¨ç‡å¯ä»¥ä¸åŒï¼Œæœ€å¤šå¯ä»¥å‡ºä¸‰è·¯å›¾ï¼Œå‚è€ƒsensor APIæ–‡æ¡£
# é€šé“0ç›´æ¥ç»™åˆ°æ˜¾ç¤ºVOï¼Œæ ¼å¼ä¸ºYUV420
sensor.set_framesize(width = DISPLAY_WIDTH, height = DISPLAY_HEIGHT,chn=CAM_CHN_ID_0)
sensor.set_pixformat(Sensor.YUV420SP,chn=CAM_CHN_ID_0)
# é€šé“1ç»™åˆ°AIåšç®—æ³•å¤„ç†ï¼Œæ ¼å¼ä¸ºRGB888P
sensor.set_framesize(width = AI_RGB888P_WIDTH , height = AI_RGB888P_HEIGHT, chn=CAM_CHN_ID_1)
sensor.set_pixformat(Sensor.RGBP888, chn=CAM_CHN_ID_1)

# ç»‘å®šé€šé“0çš„æ‘„åƒå¤´å›¾åƒåˆ°å±å¹•ï¼Œé˜²æ­¢å¦ä¸€ä¸ªé€šé“çš„AIæ¨ç†è¿‡ç¨‹å¤ªæ…¢å½±å“æ˜¾ç¤ºè¿‡ç¨‹ï¼Œå¯¼è‡´å‡ºç°å¡é¡¿æ•ˆæœ
sensor_bind_info = sensor.bind_info(x = 0, y = 0, chn = CAM_CHN_ID_0)
Display.bind_layer(**sensor_bind_info, layer = Display.LAYER_VIDEO1)

# OSDå›¾åƒåˆå§‹åŒ–,åˆ›å»ºä¸€å¸§å’Œå±å¹•åˆ†è¾¨ç‡åŒæ ·å¤§çš„é€æ˜å›¾åƒï¼Œç”¨äºç»˜åˆ¶AIæ¨ç†ç»“æœ
osd_img = image.Image(DISPLAY_WIDTH, DISPLAY_HEIGHT, image.ARGB8888)

## è®¾ç½®ä¸ºLT9611æ˜¾ç¤ºï¼Œé»˜è®¤1920x1080
#Display.init(Display.LT9611,width=DISPLAY_WIDTH,height=DISPLAY_HEIGHT,osd_num=1, to_ide = True)
# å¦‚æœä½¿ç”¨ST7701çš„LCDå±å¹•æ˜¾ç¤ºï¼Œé»˜è®¤800*480,è¿˜æ”¯æŒ640*480ç­‰ï¼Œå…·ä½“å‚è€ƒDisplayæ¨¡å—APIæ–‡æ¡£
Display.init(Display.ST7701, width=DISPLAY_WIDTH,height=DISPLAY_HEIGHT,osd_num=1, to_ide=True)

# é™åˆ¶bindé€šé“çš„å¸§ç‡ï¼Œé˜²æ­¢ç”Ÿäº§è€…å¤ªå¿«
sensor._set_chn_fps(chn = CAM_CHN_ID_0, fps = Display.fps())


#-----------------------------AIæ¨¡å‹åˆå§‹åŒ–éƒ¨åˆ†-------------------------------
# Kmodelæ¨¡å‹è·¯å¾„
kmodel_path="/sdcard/best.kmodel"
# ç±»åˆ«æ ‡ç­¾
labels = ["0","1","2","3"]
# æ¨¡å‹è¾“å…¥åˆ†è¾¨ç‡
model_input_size=[320,320]
# å…¶å®ƒå‚æ•°è®¾ç½®ï¼ŒåŒ…æ‹¬é˜ˆå€¼ã€æœ€å¤§æ£€æµ‹æ¡†æ•°é‡ç­‰
confidence_threshold = 0.3
nms_threshold = 0.4
max_boxes_num = 50
# ä¸åŒç±»åˆ«æ¡†çš„é¢œè‰²
colors=get_colors(len(labels))

# åˆå§‹åŒ–ai2dé¢„å¤„ç†ï¼Œå¹¶é…ç½®ai2d padding+resizeé¢„å¤„ç†ï¼Œé¢„å¤„ç†è¿‡ç¨‹è¾“å…¥åˆ†è¾¨ç‡ä¸ºå›¾ç‰‡åˆ†è¾¨ç‡ï¼Œè¾“å‡ºåˆ†è¾¨ç‡æ¨¡å‹è¾“å…¥çš„éœ€æ±‚åˆ†è¾¨ç‡ï¼Œå®ç°image->preprocess->modelçš„è¿‡ç¨‹
ai2d=nn.ai2d()
# é…ç½®ai2dæ¨¡å—çš„è¾“å…¥è¾“å‡ºæ•°æ®ç±»å‹å’Œæ ¼å¼
ai2d.set_dtype(nn.ai2d_format.NCHW_FMT, nn.ai2d_format.NCHW_FMT, np.uint8, np.uint8)
# è®¾ç½®paddingçš„å‚æ•°ï¼Œä¸Šä¸‹å·¦å³paddingçš„å¤§å°å’Œä¸‰ä¸ªé€šé“paddingçš„å…·ä½“å€¼
top,bottom,left,right,ratio=letterbox_pad_param([AI_RGB888P_WIDTH,AI_RGB888P_HEIGHT],model_input_size)
ai2d.set_pad_param(True,[0,0,0,0,top,bottom,left,right], 0, [128,128,128])
# è®¾ç½®resizeå‚æ•°ï¼Œé…ç½®æ’å€¼æ–¹æ³•
ai2d.set_resize_param(True,nn.interp_method.tf_bilinear, nn.interp_mode.half_pixel)
# è®¾ç½®ai2dæ¨¡å—çš„è¾“å…¥è¾“å‡ºç»´åº¦ï¼Œå¹¶æ„å»ºbuilderå®ä¾‹
ai2d_builder = ai2d.build([1,3,AI_RGB888P_HEIGHT,AI_RGB888P_WIDTH], [1,3,model_input_size[1],model_input_size[0]])
# åˆå§‹åŒ–ä¸€ä¸ªç©ºçš„tensorï¼Œç”¨äºai2dè¾“å‡ºå’Œkpuè¾“å…¥ï¼Œå› ä¸ºä¸€èˆ¬ai2dçš„è¾“å‡ºä¼šç›´æ¥é€ç»™kpuï¼Œå› æ­¤è¿™é‡Œä½¿ç”¨ä¸€ä¸ªå˜é‡å…±ç”¨
input_init_data = np.ones((1,3,model_input_size[1],model_input_size[0]),dtype=np.uint8)
kpu_input_tensor = nn.from_numpy(input_init_data)


# åˆ›å»ºkpuå®ä¾‹
kpu=nn.kpu()
# åŠ è½½kmodelæ¨¡å‹
kpu.load_kmodel(kmodel_path)

# mediaåˆå§‹åŒ–
MediaManager.init()
# å¯åŠ¨sensor
sensor.run()
# æµ‹è¯•å¸§ç‡
fps = time.clock()
while True:
    fps.tick()
    #------------------------ä»æ‘„åƒå¤´dumpä¸€å¸§å›¾åƒå¹¶å¤„ç†----------------------------------
    # ä»æ‘„åƒå¤´1é€šé“dumpä¸€å¸§RGB888Pæ ¼å¼çš„Imageå›¾åƒ
    img=sensor.snapshot(chn=CAM_CHN_ID_1)
    # è½¬æ¢æˆulab.numpy.ndarrayæ ¼å¼çš„æ•°æ®ï¼ŒCHW
    img_np=img.to_numpy_ref()
    # åˆ›å»ºnncase_runtime.tensorç”¨äºç»™åˆ°ai2dè¿›è¡Œé¢„å¤„ç†
    ai2d_input_tensor=nn.from_numpy(img_np)
    #------------------------æ¨ç†å‰çš„é¢„å¤„ç†æ­¥éª¤----------------------------------------
    # æ‰§è¡Œé¢„å¤„ç†è¿‡ç¨‹
    ai2d_builder.run(ai2d_input_tensor, kpu_input_tensor)
    #------------------------ä½¿ç”¨kpuå®Œæˆæ¨¡å‹æ¨ç†--------------------------------------
    # è®¾ç½®kpuçš„ç¬¬0ä¸ªè¾“å…¥ä¸ºai2dé¢„å¤„ç†åçš„tensorï¼Œå¦‚æœæœ‰å¤šä¸ªï¼Œå¯ä»¥ä¾æ¬¡è®¾ç½®
    kpu.set_input_tensor(0,kpu_input_tensor)
    # åœ¨kpuä¸Šæ‰§è¡Œæ¨¡å‹æ¨ç†
    kpu.run()
    #------------------------è·å–æ¨¡å‹æ¨ç†ç»“æŸçš„è¾“å‡º----------------------------------------
    # è·å–æ¨¡å‹æ¨ç†çš„è¾“å‡ºtensorï¼Œå¹¶å°†å…¶è½¬æ¢æˆulab.numpy.ndarrayæ•°æ®è¿›è¡Œåå¤„ç†
    results=[]
    for i in range(kpu.outputs_size()):
        output_i_tensor = kpu.get_output_tensor(i)
        result_i = output_i_tensor.to_numpy()
        results.append(result_i)
        del output_i_tensor
    #------------------------æ¨ç†è¾“å‡ºçš„åå¤„ç†æ­¥éª¤----------------------------------------
    # YOLOv8æ£€æµ‹æ¨¡å‹è¾“å‡ºåªæœ‰1ä¸ªï¼Œä¹Ÿå°±æ˜¯results[0]çš„shapeä¸º[1,box_dimï¼Œbox_num]ï¼Œresults[0][0]è¡¨ç¤º[box_dim,box_num]ï¼Œè½¬æ¢æˆ[box_num,box_dim]æ–¹ä¾¿ä¾æ¬¡å¤„ç†æ¯ä¸ªæ¡†
    output_data=results[0][0].transpose()
    # æ¯ä¸ªæ¡†å‰å››ä¸ªæ•°æ®ä¸ºä¸­å¿ƒç‚¹åæ ‡å’Œå®½é«˜
    boxes_ori = output_data[:,0:4]
    # å‰©ä½™æ•°æ®ä¸ºæ¯ä¸ªç±»åˆ«çš„åˆ†æ•°ï¼Œé€šè¿‡argmaxæ‰¾åˆ°åˆ†æ•°æœ€å¤§çš„ç±»åˆ«ç¼–å·å’Œåˆ†æ•°å€¼
    class_ori = output_data[:,4:]
    class_res=np.argmax(class_ori,axis=-1)
    scores_ = np.max(class_ori,axis=-1)
    # é€šè¿‡ç½®ä¿¡åº¦é˜ˆå€¼ç­›é€‰æ¡†ï¼ˆå°äºç½®ä¿¡åº¦é˜ˆå€¼çš„ä¸¢å¼ƒï¼‰ï¼ŒåŒæ—¶å¤„ç†åæ ‡ä¸ºx1,y1,x2,y2ï¼Œä¸ºæ¡†çš„å·¦ä¸Šå’Œå³ä¸‹çš„åæ ‡,æ³¨æ„æ¯”ä¾‹å˜æ¢ï¼Œå°†è¾“å…¥åˆ†è¾¨ç‡åæ ‡(model_input_size)è½¬æ¢æˆåŸå›¾åæ ‡(AI_RGB888P_WIDTH,AI_RGB888P_HEIGHT)
    boxes,inds,scores=[],[],[]
    for i in range(len(boxes_ori)):
        if scores_[i]>confidence_threshold:
            x,y,w,h=boxes_ori[i][0],boxes_ori[i][1],boxes_ori[i][2],boxes_ori[i][3]
            x1 = int((x - 0.5 * w)/ratio)
            y1 = int((y - 0.5 * h)/ratio)
            x2 = int((x + 0.5 * w)/ratio)
            y2 = int((y + 0.5 * h)/ratio)
            boxes.append([x1,y1,x2,y2])
            inds.append(class_res[i])
            scores.append(scores_[i])
    osd_img.clear()
    #å¦‚æœç¬¬ä¸€è½®ç­›é€‰åæœ‰æ¡†ï¼Œç»§ç»­ä¸‹ä¸€å¸§å¤„ç†
    if len(boxes)!=0:
        # å°†listè½¬æ¢æˆulab.numpy.ndarrayæ–¹ä¾¿å¤„ç†
        boxes = np.array(boxes)
        scores = np.array(scores)
        inds = np.array(inds)
        # NMSè¿‡ç¨‹,å»é™¤é‡å çš„å†—ä½™æ¡†ï¼Œkeepä¸ºNMSå»é™¤é‡å æ¡†åçš„ç´¢å¼•åˆ—è¡¨
        keep = nms(boxes,scores,nms_threshold)
        dets = np.concatenate((boxes, scores.reshape((len(boxes),1)), inds.reshape((len(boxes),1))), axis=1)
        # å¾—åˆ°æœ€åçš„æ£€æµ‹æ¡†çš„ç»“æœ
        det_res = []
        for keep_i in keep:
            det_res.append(dets[keep_i])
        det_res = np.array(det_res)
        # å»å‰max_box_numä¸ªï¼Œé˜²æ­¢æ£€æµ‹æ¡†è¿‡å¤š
        det_res = det_res[:max_boxes_num, :]
        #------------------------ç»˜åˆ¶æ£€æµ‹æ¡†ç»“æœ----------------------------------------
        osd_img.clear()
        # åˆ†åˆ«å¤„ç†æ¯ä¸€ä¸ªæ¡†ï¼Œå°†åŸå›¾åæ ‡(AI_RGB888P_WIDTH,AI_RGB888P_HEIGHT)è½¬æ¢æˆæ˜¾ç¤ºå±å¹•åæ ‡(DISPLAY_WIDTH,DISPLAY_HEIGHT)
        for det in det_res:
            x_1, y_1, x_2, y_2 = map(lambda pos: int(round(pos, 0)), det[:4])
            draw_x= int(x_1 * DISPLAY_WIDTH // AI_RGB888P_WIDTH)
            draw_y= int(y_1 * DISPLAY_HEIGHT // AI_RGB888P_HEIGHT)
            draw_w = int((x_2 - x_1) * DISPLAY_WIDTH // AI_RGB888P_WIDTH)
            draw_h = int((y_2 - y_1) * DISPLAY_HEIGHT // AI_RGB888P_HEIGHT)
            osd_img.draw_rectangle(draw_x,draw_y, draw_w, draw_h, color=colors[int(det[5])],thickness=4)
            osd_img.draw_string_advanced( draw_x , max(0,draw_y-50), 24, "ç±»åˆ«:"+labels[int(det[5])] + " åˆ†æ•°:{0:.3f}".format(det[4]), color=colors[int(det[5])])
    #------------------------åœ¨å±å¹•æ˜¾ç¤ºæ£€æµ‹æ¡†ç»“æœ----------------------------------------
    Display.show_image(osd_img)
    print("det fps:",fps.fps())
    gc.collect()

#é€€å‡ºå¾ªç¯ï¼Œé‡Šæ”¾èµ„æº
del ai2d
del kpu
sensor.stop()
Display.deinit()
time.sleep_ms(50)
MediaManager.deinit()
nn.shrink_memory_pool()
```

## YOLOéƒ¨ç½²åº“

YOLO æ˜¯è§†è§‰ä»»åŠ¡ä¸­å¸¸ç”¨çš„æ¨¡å‹ï¼Œæ”¯æŒåˆ†ç±»ã€æ£€æµ‹ã€åˆ†å‰²ã€æ—‹è½¬ç›®æ ‡æ£€æµ‹ç­‰ä»»åŠ¡ã€‚æˆ‘ä»¬é€‰æ‹©YOLOç³»åˆ—æ¨¡å‹ä¸­ç»å…¸çš„YOLOv5ã€YOLOv8å’ŒYOLO11ä¸ºåŸºç¡€ï¼Œå°è£…äº†YOLOv5ã€YOLOv8å’ŒYOLO11çš„MicroPythonéƒ¨ç½²åº“ï¼Œæ–¹ä¾¿ç”¨æˆ·å¿«é€Ÿéƒ¨ç½²YOLOæ¨¡å‹ã€‚å…·ä½“å†…å®¹è§é“¾æ¥ï¼š[YOLOå¤§ä½œæˆ˜](https://www.kendryte.com/k230_canmv/zh/main/zh/example/ai/YOLO%E5%A4%A7%E4%BD%9C%E6%88%98.html)ã€‚

### YOLOv5çŒ«ç‹—åˆ†ç±»

åŸºäºYOLOv5æ¨¡å‹å®ç°çŒ«ç‹—åˆ†ç±»æ¨¡å‹åœ¨K230ä¸Šçš„éƒ¨ç½²ã€‚

#### YOLOv5æºç åŠè®­ç»ƒç¯å¢ƒæ­å»º

`YOLOv5` è®­ç»ƒç¯å¢ƒæ­å»ºè¯·å‚è€ƒ[ultralytics/yolov5: YOLOv5 ğŸš€ in PyTorch > ONNX > CoreML > TFLite (github.com)](https://github.com/ultralytics/yolov5)

```shell
git clone https://github.com/ultralytics/yolov5.git
cd yolov5
pip install -r requirements.txt
```

å¦‚æœæ‚¨å·²æ­å»ºå¥½ç¯å¢ƒï¼Œè¯·å¿½ç•¥æ­¤æ­¥éª¤ã€‚

#### è®­ç»ƒæ•°æ®å‡†å¤‡

è¯·ä¸‹è½½æä¾›çš„ç¤ºä¾‹æ•°æ®é›†ï¼Œç¤ºä¾‹æ•°æ®é›†ä»¥çŒ«ç‹—åˆ†ç±»ä¸ºåœºæ™¯ï¼Œä½¿ç”¨YOLOv5å®Œæˆè®­ç»ƒã€‚

```shell
cd yolov5
wget https://kendryte-download.canaan-creative.com/developer/k230/yolo_dataset/cat_dog.zip
unzip cat_dog.zip
```

âš ï¸ **windowsç³»ç»Ÿè¯·ç›´æ¥å¤åˆ¶é“¾æ¥åˆ°æµè§ˆå™¨ä¸‹è½½ï¼Œå¹¶è§£å‹åˆ°å¯¹åº”ç›®å½•**ã€‚

å¦‚æœæ‚¨å·²ä¸‹è½½å¥½æ•°æ®ï¼Œè¯·å¿½ç•¥æ­¤æ­¥éª¤ã€‚

#### ä½¿ç”¨YOLOv5è®­ç»ƒçŒ«ç‹—åˆ†ç±»æ¨¡å‹

åœ¨ `yolov5` ç›®å½•ä¸‹æ‰§è¡Œå‘½ä»¤ï¼Œä½¿ç”¨ `yolov5` è®­ç»ƒçŒ«ç‹—åˆ†ç±»æ¨¡å‹ï¼š

```shell
python classify/train.py --model yolov5n-cls.pt --data cat_dog --epochs 100 --batch-size 8 --imgsz 224 --device '0'
```

#### è½¬æ¢çŒ«ç‹—åˆ†ç±»kmodel

æ¨¡å‹è½¬æ¢éœ€è¦åœ¨è®­ç»ƒç¯å¢ƒå®‰è£…å¦‚ä¸‹åº“ï¼š

```Shell
# linuxå¹³å°ï¼šnncaseå’Œnncase-kpuå¯ä»¥åœ¨çº¿å®‰è£…ï¼Œnncase-2.x éœ€è¦å®‰è£… dotnet-7
sudo apt-get install -y dotnet-sdk-7.0
pip install --upgrade pip
pip install nncase==2.9.0
pip install nncase-kpu==2.9.0

# windowså¹³å°ï¼šè¯·è‡ªè¡Œå®‰è£…dotnet-7å¹¶æ·»åŠ ç¯å¢ƒå˜é‡,æ”¯æŒä½¿ç”¨pipåœ¨çº¿å®‰è£…nncaseï¼Œä½†æ˜¯nncase-kpuåº“éœ€è¦ç¦»çº¿å®‰è£…ï¼Œåœ¨https://github.com/kendryte/nncase/releasesä¸‹è½½nncase_kpu-2.*-py2.py3-none-win_amd64.whl
# è¿›å…¥å¯¹åº”çš„pythonç¯å¢ƒï¼Œåœ¨nncase_kpu-2.*-py2.py3-none-win_amd64.whlä¸‹è½½ç›®å½•ä¸‹ä½¿ç”¨pipå®‰è£…
pip install nncase_kpu-2.*-py2.py3-none-win_amd64.whl

# é™¤nncaseå’Œnncase-kpuå¤–ï¼Œè„šæœ¬è¿˜ç”¨åˆ°çš„å…¶ä»–åº“åŒ…æ‹¬ï¼š
pip install onnx
pip install onnxruntime
pip install onnxsim
```

ä¸‹è½½è„šæœ¬å·¥å…·ï¼Œå°†æ¨¡å‹è½¬æ¢è„šæœ¬å·¥å…· `test_yolov5.zip` è§£å‹åˆ° `yolov5` ç›®å½•ä¸‹ï¼›

```shell
wget https://kendryte-download.canaan-creative.com/developer/k230/yolo_files/test_yolov5.zip
unzip test_yolov5.zip
```

æŒ‰ç…§å¦‚ä¸‹å‘½ä»¤ï¼Œå¯¹ `runs/train-cls/exp/weights` ä¸‹çš„ `pt` æ¨¡å‹å…ˆå¯¼å‡ºä¸º `onnx` æ¨¡å‹ï¼Œå†è½¬æ¢æˆ `kmodel` æ¨¡å‹ï¼š

```shell
# å¯¼å‡ºonnxï¼Œptæ¨¡å‹è·¯å¾„è¯·è‡ªè¡Œé€‰æ‹©
python export.py --weight runs/train-cls/exp/weights/best.pt --imgsz 224 --batch 1 --include onnx
cd test_yolov5/classify
# å°†testç›®å½•ä¸‹çš„å›¾ç‰‡æ¢æˆä½ è‡ªå·±çš„è®­ç»ƒæ•°æ®çš„ä¸€éƒ¨åˆ†ï¼Œè½¬æ¢kmodel,onnxæ¨¡å‹è·¯å¾„è¯·è‡ªè¡Œé€‰æ‹©ï¼Œç”Ÿæˆçš„kmodelåœ¨onnxæ¨¡å‹åŒçº§ç›®å½•ä¸‹
python to_kmodel.py --target k230 --model ../../runs/train-cls/exp/weights/best.onnx --dataset ../test --input_width 224 --input_height 224 --ptq_option 0
cd ../../
```

ğŸ’¡ **æ¨¡å‹è½¬æ¢è„šæœ¬(to_kmodel.py)å‚æ•°è¯´æ˜**ï¼š

| å‚æ•°åç§°     | æè¿°     | è¯´æ˜                                                         | ç±»å‹  |
| ------------ | -------- | ------------------------------------------------------------| ----- |
| target       | ç›®æ ‡å¹³å° | å¯é€‰é¡¹ä¸ºk230/cpuï¼Œå¯¹åº”k230 kpuå’Œcpuï¼›                         | str   |
| model        | æ¨¡å‹è·¯å¾„ | å¾…è½¬æ¢çš„ONNXæ¨¡å‹è·¯å¾„ï¼›                                        | str   |
| dataset      | æ ¡å‡†å›¾ç‰‡é›†  | æ¨¡å‹è½¬æ¢æ—¶ä½¿ç”¨çš„å›¾ç‰‡æ•°æ®ï¼Œåœ¨é‡åŒ–é˜¶æ®µä½¿ç”¨ï¼Œå¯ä»¥ä»è®­ç»ƒæ•°æ®ä¸­å–ä¸€éƒ¨åˆ†                    | str   |
| input_width  | è¾“å…¥å®½åº¦ | æ¨¡å‹è¾“å…¥çš„å®½åº¦                                             | int   |
| input_height | è¾“å…¥é«˜åº¦ | æ¨¡å‹è¾“å…¥çš„é«˜åº¦                                             | int   |
| ptq_option   | é‡åŒ–æ–¹å¼ | dataå’Œweightsçš„é‡åŒ–æ–¹å¼ï¼Œ0ä¸º[uint8,uint8], 1ä¸º[uint8,int16], 2ä¸º[int16,uint8] | 0/1/2 |

#### åœ¨k230ä¸Šä½¿ç”¨MicroPythonéƒ¨ç½²æ¨¡å‹

##### çƒ§å½•é•œåƒå¹¶å®‰è£…CanMV IDE

ğŸ’¡ **å›ºä»¶ä»‹ç»**ï¼šè¯·åœ¨ `github` æŒ‰ç…§æ‚¨çš„å¼€å‘æ¿ç±»å‹ä¸‹è½½æœ€æ–°çš„ [PreReleaseå›ºä»¶](https://github.com/kendryte/canmv_k230/releases/tag/PreRelease) ä»¥ä¿è¯**æœ€æ–°çš„ç‰¹æ€§**è¢«æ”¯æŒï¼æˆ–è€…ä½¿ç”¨æœ€æ–°çš„ä»£ç è‡ªè¡Œç¼–è¯‘å›ºä»¶ï¼Œæ•™ç¨‹è§ï¼š[å›ºä»¶ç¼–è¯‘](https://www.kendryte.com/k230_canmv/zh/main/zh/userguide/how_to_build.html)ã€‚

ä¸‹è½½å¹¶å®‰è£… CanMV IDE (ä¸‹è½½é“¾æ¥ï¼š[CanMV IDE download](https://www.kendryte.com/resource?selected=0-2-1))ï¼Œåœ¨ IDE ä¸­ç¼–å†™ä»£ç å¹¶è¿è¡Œã€‚

##### æ¨¡å‹æ–‡ä»¶æ‹·è´

è¿æ¥IDEï¼Œå°†è½¬æ¢å¥½çš„æ¨¡å‹å’Œæµ‹è¯•å›¾ç‰‡æ‹·è´åˆ°è·¯å¾„ `CanMV/data` ç›®å½•ä¸‹ã€‚è¯¥è·¯å¾„å¯ä»¥è‡ªå®šä¹‰ï¼Œåªéœ€è¦åœ¨ç¼–å†™ä»£ç æ—¶ä¿®æ”¹å¯¹åº”è·¯å¾„å³å¯ã€‚

##### YOLOv5 æ¨¡å—

`YOLOv5` ç±»é›†æˆäº† `YOLOv5` çš„ä¸‰ç§ä»»åŠ¡ï¼ŒåŒ…æ‹¬åˆ†ç±»(classify)ã€æ£€æµ‹(detect)ã€åˆ†å‰²(segment)ï¼›æ”¯æŒä¸¤ç§æ¨ç†æ¨¡å¼ï¼ŒåŒ…æ‹¬å›¾ç‰‡(image)å’Œè§†é¢‘æµ(video)ï¼›è¯¥ç±»å°è£…äº† `YOLOv5` çš„ kmodel æ¨ç†æµç¨‹ã€‚

- **å¯¼å…¥æ–¹æ³•**

```python
from libs.YOLO import YOLOv5
```

- **å‚æ•°è¯´æ˜**

| å‚æ•°åç§°         | æè¿°           | è¯´æ˜                                                         | ç±»å‹         |
| ---------------- | -------------- | ------------------------------------------------------------ | ------------ |
| task_type        | ä»»åŠ¡ç±»å‹       | æ”¯æŒä¸‰ç±»ä»»åŠ¡ï¼Œå¯é€‰é¡¹ä¸º'classify'/'detect'/'segment'ï¼›        | str          |
| mode             | æ¨ç†æ¨¡å¼       | æ”¯æŒä¸¤ç§æ¨ç†æ¨¡å¼ï¼Œå¯é€‰é¡¹ä¸º'image'/'video'ï¼Œ'image'è¡¨ç¤ºæ¨ç†å›¾ç‰‡ï¼Œ'video'è¡¨ç¤ºæ¨ç†æ‘„åƒå¤´é‡‡é›†çš„å®æ—¶è§†é¢‘æµï¼› | str          |
| kmodel_path      | kmodelè·¯å¾„     | æ‹·è´åˆ°å¼€å‘æ¿ä¸Škmodelè·¯å¾„ï¼›                                   | str          |
| labels           | ç±»åˆ«æ ‡ç­¾åˆ—è¡¨   | ä¸åŒç±»åˆ«çš„æ ‡ç­¾åç§°ï¼›                                         | list[str]    |
| rgb888p_size     | æ¨ç†å¸§åˆ†è¾¨ç‡   | æ¨ç†å½“å‰å¸§åˆ†è¾¨ç‡ï¼Œå¦‚[1920,1080]ã€[1280,720]ã€[640,640];      | list[int]    |
| model_input_size | æ¨¡å‹è¾“å…¥åˆ†è¾¨ç‡ | YOLOv5æ¨¡å‹è®­ç»ƒæ—¶çš„è¾“å…¥åˆ†è¾¨ç‡ï¼Œå¦‚[224,224]ã€[320,320]ã€[640,640]ï¼› | list[int]    |
| display_size     | æ˜¾ç¤ºåˆ†è¾¨ç‡     | æ¨ç†æ¨¡å¼ä¸º'video'æ—¶è®¾ç½®ï¼Œæ”¯æŒhdmi([1920,1080])å’Œlcd([800,480]); | list[int]    |
| conf_thresh      | ç½®ä¿¡åº¦é˜ˆå€¼     | åˆ†ç±»ä»»åŠ¡ç±»åˆ«ç½®ä¿¡åº¦é˜ˆå€¼ï¼Œæ£€æµ‹åˆ†å‰²ä»»åŠ¡çš„ç›®æ ‡ç½®ä¿¡åº¦é˜ˆå€¼ï¼Œå¦‚0.5ï¼› | floatã€0~1ã€‘ |
| nms_thresh       | nmsé˜ˆå€¼        | éæå¤§å€¼æŠ‘åˆ¶é˜ˆå€¼ï¼Œæ£€æµ‹å’Œåˆ†å‰²ä»»åŠ¡å¿…å¡«ï¼›                       | floatã€0~1ã€‘ |
| mask_thresh      | maské˜ˆå€¼       | åˆ†å‰²ä»»åŠ¡ä¸­çš„å¯¹æ£€æµ‹æ¡†ä¸­å¯¹è±¡åšåˆ†å‰²æ—¶çš„äºŒå€¼åŒ–é˜ˆå€¼ï¼›             | floatã€0~1ã€‘ |
| max_boxes_num    | æœ€å¤§æ£€æµ‹æ¡†æ•°   | ä¸€å¸§å›¾åƒä¸­å…è®¸è¿”å›çš„æœ€å¤šæ£€æµ‹æ¡†æ•°ç›®ï¼›                         | int          |
| debug_mode       | è°ƒè¯•æ¨¡å¼       | è®¡æ—¶å‡½æ•°æ˜¯å¦ç”Ÿæ•ˆï¼Œå¯é€‰é¡¹0/1ï¼Œ0ä¸ºä¸è®¡æ—¶ï¼Œ1ä¸ºè®¡æ—¶ï¼›            | intã€0/1ã€‘   |

##### éƒ¨ç½²æ¨¡å‹å®ç°å›¾ç‰‡æ¨ç†

å›¾ç‰‡æ¨ç†ï¼Œè¯·å‚è€ƒä¸‹è¿°ä»£ç ï¼Œ**æ ¹æ®å®é™…æƒ…å†µä¿®æ”¹ `__main__` ä¸­çš„å®šä¹‰å‚æ•°å˜é‡**ï¼›

```python
from libs.YOLO import YOLOv5
from libs.Utils import *
import os,sys,gc
import ulab.numpy as np
import image

if __name__=="__main__":
    # è¿™é‡Œä»…ä¸ºç¤ºä¾‹ï¼Œè‡ªå®šä¹‰åœºæ™¯è¯·ä¿®æ”¹ä¸ºæ‚¨è‡ªå·±çš„æµ‹è¯•å›¾ç‰‡ã€æ¨¡å‹è·¯å¾„ã€æ ‡ç­¾åç§°ã€æ¨¡å‹è¾“å…¥å¤§å°
    img_path="/data/test.jpg"
    kmodel_path="/data/best.kmodel"
    labels = ["cat","dog"]
    model_input_size=[224,224]

    confidence_threshold = 0.5
    img,img_ori=read_image(img_path)
    rgb888p_size=[img.shape[2],img.shape[1]]
    # åˆå§‹åŒ–YOLOv5å®ä¾‹
    yolo=YOLOv5(task_type="classify",mode="image",kmodel_path=kmodel_path,labels=labels,rgb888p_size=rgb888p_size,model_input_size=model_input_size,conf_thresh=confidence_threshold,debug_mode=0)
    yolo.config_preprocess()
    res=yolo.run(img)
    yolo.draw_result(res,img_ori)
    yolo.deinit()
    gc.collect()
```

##### éƒ¨ç½²æ¨¡å‹å®ç°è§†é¢‘æ¨ç†

è§†é¢‘æ¨ç†ï¼Œè¯·å‚è€ƒä¸‹è¿°ä»£ç ï¼Œ**æ ¹æ®å®é™…æƒ…å†µä¿®æ”¹ `__main__` ä¸­çš„å®šä¹‰å˜é‡**ï¼›

```python
from libs.PipeLine import PipeLine
from libs.YOLO import YOLOv5
from libs.Utils import *
import os,sys,gc
import ulab.numpy as np
import image

if __name__=="__main__":
    # è¿™é‡Œä»…ä¸ºç¤ºä¾‹ï¼Œè‡ªå®šä¹‰åœºæ™¯è¯·ä¿®æ”¹ä¸ºæ‚¨è‡ªå·±çš„æ¨¡å‹è·¯å¾„ã€æ ‡ç­¾åç§°ã€æ¨¡å‹è¾“å…¥å¤§å°
    kmodel_path="/data/best.kmodel"
    labels = ["cat","dog"]
    model_input_size=[224,224]

    # æ·»åŠ æ˜¾ç¤ºæ¨¡å¼ï¼Œé»˜è®¤hdmiï¼Œå¯é€‰hdmi/lcd/lt9611/st7701/hx8399,å…¶ä¸­hdmié»˜è®¤ç½®ä¸ºlt9611ï¼Œåˆ†è¾¨ç‡1920*1080ï¼›lcdé»˜è®¤ç½®ä¸ºst7701ï¼Œåˆ†è¾¨ç‡800*480
    display_mode="lcd"
    rgb888p_size=[640,360]
    confidence_threshold = 0.5
    pl=PipeLine(rgb888p_size=rgb888p_size,display_mode=display_mode)
    pl.create()
    display_size=pl.get_display_size()
    # åˆå§‹åŒ–YOLOv5å®ä¾‹
    yolo=YOLOv5(task_type="classify",mode="video",kmodel_path=kmodel_path,labels=labels,rgb888p_size=rgb888p_size,model_input_size=model_input_size,display_size=display_size,conf_thresh=confidence_threshold,debug_mode=0)
    yolo.config_preprocess()
    while True:
        with ScopedTiming("total",1):
            img=pl.get_frame()
            res=yolo.run(img)
            yolo.draw_result(res,pl.osd_img)
            pl.show_image()
            gc.collect()
    yolo.deinit()
    pl.destroy()
```

##### éƒ¨ç½²æ•ˆæœ

é€‰æ‹©ä¸¤å¼ çŒ«ç‹—å›¾ç‰‡ä½¿ç”¨kmodelè¿›è¡Œåˆ†ç±»ã€‚æ•ˆæœå¦‚ä¸‹å›¾ï¼š

![cat_dog_cls_res](https://www.kendryte.com/api/post/attachment?id=624)

### YOLOv8è·Œå€’æ£€æµ‹

åŸºäºYOLOv8æ¨¡å‹å®ç°è·Œå€’æ£€æµ‹æ¨¡å‹åœ¨K230ä¸Šçš„éƒ¨ç½²ã€‚

#### YOLOv8æºç åŠè®­ç»ƒç¯å¢ƒæ­å»º

`YOLOv8` è®­ç»ƒç¯å¢ƒæ­å»ºè¯·å‚è€ƒ[ultralytics/ultralytics: Ultralytics YOLO ğŸš€ (github.com)](https://github.com/ultralytics/ultralytics)

```shell
# Pip install the ultralytics package including all requirements in a Python>=3.8 environment with PyTorch>=1.8.
pip install ultralytics
```

å¦‚æœæ‚¨å·²æ­å»ºå¥½ç¯å¢ƒï¼Œè¯·å¿½ç•¥æ­¤æ­¥éª¤ã€‚

#### è®­ç»ƒæ•°æ®å‡†å¤‡

ä¸‹è½½æä¾›çš„è·Œå€’æ£€æµ‹æ•°æ®é›†ï¼Œå¹¶è§£å‹ã€‚

```shell
cd yolov8
wget https://kendryte-download.canaan-creative.com/developer/k230/yolo_dataset/fall_det.zip
unzip fall_det.zip
```

âš ï¸ **windowsç³»ç»Ÿè¯·ç›´æ¥å¤åˆ¶é“¾æ¥åˆ°æµè§ˆå™¨ä¸‹è½½ï¼Œå¹¶è§£å‹åˆ°å¯¹åº”ç›®å½•**ã€‚

å¦‚æœæ‚¨å·²ä¸‹è½½å¥½æ•°æ®ï¼Œè¯·å¿½ç•¥æ­¤æ­¥éª¤ã€‚

#### ä½¿ç”¨YOLOv8è®­ç»ƒè·Œå€’æ£€æµ‹æ¨¡å‹

åœ¨ `yolov8` ç›®å½•ä¸‹æ‰§è¡Œå‘½ä»¤ï¼Œä½¿ç”¨ `yolov8` è®­ç»ƒè·Œå€’æ£€æµ‹æ¨¡å‹ï¼š

```shell
yolo detect train data=fall_det.yaml model=yolov8n.pt epochs=300 imgsz=320
```

#### è½¬æ¢è·Œå€’æ£€æµ‹kmodel

æ¨¡å‹è½¬æ¢éœ€è¦åœ¨è®­ç»ƒç¯å¢ƒå®‰è£…å¦‚ä¸‹åº“ï¼š

```Shell
# linuxå¹³å°ï¼šnncaseå’Œnncase-kpuå¯ä»¥åœ¨çº¿å®‰è£…ï¼Œnncase-2.x éœ€è¦å®‰è£… dotnet-7
sudo apt-get install -y dotnet-sdk-7.0
pip install --upgrade pip
pip install nncase==2.9.0
pip install nncase-kpu==2.9.0

# windowså¹³å°ï¼šè¯·è‡ªè¡Œå®‰è£…dotnet-7å¹¶æ·»åŠ ç¯å¢ƒå˜é‡,æ”¯æŒä½¿ç”¨pipåœ¨çº¿å®‰è£…nncaseï¼Œä½†æ˜¯nncase-kpuåº“éœ€è¦ç¦»çº¿å®‰è£…ï¼Œåœ¨https://github.com/kendryte/nncase/releasesä¸‹è½½nncase_kpu-2.*-py2.py3-none-win_amd64.whl
# è¿›å…¥å¯¹åº”çš„pythonç¯å¢ƒï¼Œåœ¨nncase_kpu-2.*-py2.py3-none-win_amd64.whlä¸‹è½½ç›®å½•ä¸‹ä½¿ç”¨pipå®‰è£…
pip install nncase_kpu-2.*-py2.py3-none-win_amd64.whl

# é™¤nncaseå’Œnncase-kpuå¤–ï¼Œè„šæœ¬è¿˜ç”¨åˆ°çš„å…¶ä»–åº“åŒ…æ‹¬ï¼š
pip install onnx
pip install onnxruntime
pip install onnxsim
```

ä¸‹è½½è„šæœ¬å·¥å…·ï¼Œå°†æ¨¡å‹è½¬æ¢è„šæœ¬å·¥å…· `test_yolov8.zip` è§£å‹åˆ° `yolov8` ç›®å½•ä¸‹ï¼›

```shell
wget https://kendryte-download.canaan-creative.com/developer/k230/yolo_files/test_yolov8.zip
unzip test_yolov8.zip
```

æŒ‰ç…§å¦‚ä¸‹å‘½ä»¤ï¼Œå¯¹ `runs/detect/train/weights` ä¸‹çš„ `pt` æ¨¡å‹å…ˆå¯¼å‡ºä¸º `onnx` æ¨¡å‹ï¼Œå†è½¬æ¢æˆ `kmodel` æ¨¡å‹ï¼š

```shell
# å¯¼å‡ºonnxï¼Œptæ¨¡å‹è·¯å¾„è¯·è‡ªè¡Œé€‰æ‹©
yolo export model=runs/detect/train/weights/best.pt format=onnx imgsz=320
cd test_yolov8/detect
# å°†testç›®å½•ä¸‹çš„å›¾ç‰‡æ¢æˆä½ è‡ªå·±çš„è®­ç»ƒæ•°æ®çš„ä¸€éƒ¨åˆ†ï¼Œè½¬æ¢kmodel,onnxæ¨¡å‹è·¯å¾„è¯·è‡ªè¡Œé€‰æ‹©ï¼Œç”Ÿæˆçš„kmodelåœ¨onnxæ¨¡å‹åŒçº§ç›®å½•ä¸‹
python to_kmodel.py --target k230 --model ../../runs/detect/train/weights/best.onnx --dataset ../test --input_width 320 --input_height 320 --ptq_option 1
cd ../../
```

ğŸ’¡ **æ¨¡å‹è½¬æ¢è„šæœ¬(to_kmodel.py)å‚æ•°è¯´æ˜**ï¼š

| å‚æ•°åç§°     | æè¿°     | è¯´æ˜                                                         | ç±»å‹  |
| ------------ | -------- | ------------------------------------------------------------| ----- |
| target       | ç›®æ ‡å¹³å° | å¯é€‰é¡¹ä¸ºk230/cpuï¼Œå¯¹åº”k230 kpuå’Œcpuï¼›                              | str   |
| model        | æ¨¡å‹è·¯å¾„ | å¾…è½¬æ¢çš„ONNXæ¨¡å‹è·¯å¾„ï¼›                                        | str   |
| dataset      | æ ¡å‡†å›¾ç‰‡é›†  | æ¨¡å‹è½¬æ¢æ—¶ä½¿ç”¨çš„å›¾ç‰‡æ•°æ®ï¼Œåœ¨é‡åŒ–é˜¶æ®µä½¿ç”¨ï¼Œå¯ä»¥ä»è®­ç»ƒé›†ä¸­å–ä¸€éƒ¨åˆ†å›¾ç‰‡æ›¿æ¢                   | str   |
| input_width  | è¾“å…¥å®½åº¦ | æ¨¡å‹è¾“å…¥çš„å®½åº¦                                             | int   |
| input_height | è¾“å…¥é«˜åº¦ | æ¨¡å‹è¾“å…¥çš„é«˜åº¦                                             | int   |
| ptq_option   | é‡åŒ–æ–¹å¼ | dataå’Œweightsçš„é‡åŒ–æ–¹å¼ï¼Œ0ä¸º[uint8,uint8], 1ä¸º[uint8,int16], 2ä¸º[int16,uint8] | 0/1/2 |

#### åœ¨k230ä¸Šä½¿ç”¨MicroPythonéƒ¨ç½²æ¨¡å‹

##### çƒ§å½•é•œåƒå¹¶å®‰è£…CanMV IDE

ğŸ’¡ **å›ºä»¶ä»‹ç»**ï¼šè¯·åœ¨ `github` æŒ‰ç…§æ‚¨çš„å¼€å‘æ¿ç±»å‹ä¸‹è½½æœ€æ–°çš„ [PreReleaseå›ºä»¶](https://github.com/kendryte/canmv_k230/releases/tag/PreRelease) ä»¥ä¿è¯**æœ€æ–°çš„ç‰¹æ€§**è¢«æ”¯æŒï¼æˆ–è€…ä½¿ç”¨æœ€æ–°çš„ä»£ç è‡ªè¡Œç¼–è¯‘å›ºä»¶ï¼Œæ•™ç¨‹è§ï¼š[å›ºä»¶ç¼–è¯‘](https://www.kendryte.com/k230_canmv/zh/main/zh/userguide/how_to_build.html)ã€‚

ä¸‹è½½å¹¶å®‰è£… CanMV IDE (ä¸‹è½½é“¾æ¥ï¼š[CanMV IDE download](https://www.kendryte.com/resource?selected=0-2-1))ï¼Œåœ¨ IDE ä¸­ç¼–å†™ä»£ç å¹¶è¿è¡Œã€‚

##### æ¨¡å‹æ–‡ä»¶æ‹·è´

è¿æ¥IDEï¼Œå°†è½¬æ¢å¥½çš„æ¨¡å‹å’Œæµ‹è¯•å›¾ç‰‡æ‹·è´åˆ°è·¯å¾„ `CanMV/data` ç›®å½•ä¸‹ã€‚è¯¥è·¯å¾„å¯ä»¥è‡ªå®šä¹‰ï¼Œåªéœ€è¦åœ¨ç¼–å†™ä»£ç æ—¶ä¿®æ”¹å¯¹åº”è·¯å¾„å³å¯ã€‚

##### YOLOv8 æ¨¡å—

`YOLOv8` ç±»é›†æˆäº† `YOLOv8` çš„å››ç§ä»»åŠ¡ï¼ŒåŒ…æ‹¬åˆ†ç±»(classify)ã€æ£€æµ‹(detect)ã€åˆ†å‰²(segment)ã€æ—‹è½¬ç›®æ ‡æ£€æµ‹(obb)ï¼›æ”¯æŒä¸¤ç§æ¨ç†æ¨¡å¼ï¼ŒåŒ…æ‹¬å›¾ç‰‡(image)å’Œè§†é¢‘æµ(video)ï¼›è¯¥ç±»å°è£…äº† `YOLOv8` çš„ kmodel æ¨ç†æµç¨‹ã€‚

- **å¯¼å…¥æ–¹æ³•**

```python
from libs.YOLO import YOLOv8
```

- **å‚æ•°è¯´æ˜**

| å‚æ•°åç§°         | æè¿°           | è¯´æ˜                                                         | ç±»å‹         |
| ---------------- | -------------- | ------------------------------------------------------------ | ------------ |
| task_type        | ä»»åŠ¡ç±»å‹       | æ”¯æŒå››ç±»ä»»åŠ¡ï¼Œå¯é€‰é¡¹ä¸º'classify'/'detect'/'segment'/'obb'ï¼›        | str          |
| mode             | æ¨ç†æ¨¡å¼       | æ”¯æŒä¸¤ç§æ¨ç†æ¨¡å¼ï¼Œå¯é€‰é¡¹ä¸º'image'/'video'ï¼Œ'image'è¡¨ç¤ºæ¨ç†å›¾ç‰‡ï¼Œ'video'è¡¨ç¤ºæ¨ç†æ‘„åƒå¤´é‡‡é›†çš„å®æ—¶è§†é¢‘æµï¼› | str          |
| kmodel_path      | kmodelè·¯å¾„     | æ‹·è´åˆ°å¼€å‘æ¿ä¸Škmodelè·¯å¾„ï¼›                                   | str          |
| labels           | ç±»åˆ«æ ‡ç­¾åˆ—è¡¨   | ä¸åŒç±»åˆ«çš„æ ‡ç­¾åç§°ï¼›                                         | list[str]    |
| rgb888p_size     | æ¨ç†å¸§åˆ†è¾¨ç‡   | æ¨ç†å½“å‰å¸§åˆ†è¾¨ç‡ï¼Œå¦‚[1920,1080]ã€[1280,720]ã€[640,640];      | list[int]    |
| model_input_size | æ¨¡å‹è¾“å…¥åˆ†è¾¨ç‡ | YOLOv8æ¨¡å‹è®­ç»ƒæ—¶çš„è¾“å…¥åˆ†è¾¨ç‡ï¼Œå¦‚[224,224]ã€[320,320]ã€[640,640]ï¼› | list[int]    |
| display_size     | æ˜¾ç¤ºåˆ†è¾¨ç‡     | æ¨ç†æ¨¡å¼ä¸º'video'æ—¶è®¾ç½®ï¼Œæ”¯æŒhdmi([1920,1080])å’Œlcd([800,480]); | list[int]    |
| conf_thresh      | ç½®ä¿¡åº¦é˜ˆå€¼     | åˆ†ç±»ä»»åŠ¡ç±»åˆ«ç½®ä¿¡åº¦é˜ˆå€¼ï¼Œæ£€æµ‹åˆ†å‰²ä»»åŠ¡çš„ç›®æ ‡ç½®ä¿¡åº¦é˜ˆå€¼ï¼Œå¦‚0.5ï¼› | floatã€0~1ã€‘ |
| nms_thresh       | nmsé˜ˆå€¼        | éæå¤§å€¼æŠ‘åˆ¶é˜ˆå€¼ï¼Œæ£€æµ‹å’Œåˆ†å‰²ä»»åŠ¡å¿…å¡«ï¼›                       | floatã€0~1ã€‘ |
| mask_thresh      | maské˜ˆå€¼       | åˆ†å‰²ä»»åŠ¡ä¸­çš„å¯¹æ£€æµ‹æ¡†ä¸­å¯¹è±¡åšåˆ†å‰²æ—¶çš„äºŒå€¼åŒ–é˜ˆå€¼ï¼›             | floatã€0~1ã€‘ |
| max_boxes_num    | æœ€å¤§æ£€æµ‹æ¡†æ•°   | ä¸€å¸§å›¾åƒä¸­å…è®¸è¿”å›çš„æœ€å¤šæ£€æµ‹æ¡†æ•°ç›®ï¼›                         | int          |
| debug_mode       | è°ƒè¯•æ¨¡å¼       | è®¡æ—¶å‡½æ•°æ˜¯å¦ç”Ÿæ•ˆï¼Œå¯é€‰é¡¹0/1ï¼Œ0ä¸ºä¸è®¡æ—¶ï¼Œ1ä¸ºè®¡æ—¶ï¼›            | intã€0/1ã€‘   |

##### éƒ¨ç½²æ¨¡å‹å®ç°å›¾ç‰‡æ¨ç†

å›¾ç‰‡æ¨ç†ï¼Œè¯·å‚è€ƒä¸‹è¿°ä»£ç ï¼Œ**æ ¹æ®å®é™…æƒ…å†µä¿®æ”¹ `__main__` ä¸­çš„å®šä¹‰å‚æ•°å˜é‡**ï¼›

```python
from libs.YOLO import YOLOv8
from libs.Utils import *
import os,sys,gc
import ulab.numpy as np
import image

if __name__=="__main__":
    # è¿™é‡Œä»…ä¸ºç¤ºä¾‹ï¼Œè‡ªå®šä¹‰åœºæ™¯è¯·ä¿®æ”¹ä¸ºæ‚¨è‡ªå·±çš„æµ‹è¯•å›¾ç‰‡ã€æ¨¡å‹è·¯å¾„ã€æ ‡ç­¾åç§°ã€æ¨¡å‹è¾“å…¥å¤§å°
    img_path="/data/test.jpg"
    kmodel_path="/data/best.kmodel"
    labels = ["fall"]
    model_input_size=[320,320]

    confidence_threshold = 0.5
    nms_threshold=0.45
    img,img_ori=read_image(img_path)
    rgb888p_size=[img.shape[2],img.shape[1]]
    # åˆå§‹åŒ–YOLOv8å®ä¾‹
    yolo=YOLOv8(task_type="detect",mode="image",kmodel_path=kmodel_path,labels=labels,rgb888p_size=rgb888p_size,model_input_size=model_input_size,conf_thresh=confidence_threshold,nms_thresh=nms_threshold,max_boxes_num=50,debug_mode=0)
    yolo.config_preprocess()
    res=yolo.run(img)
    yolo.draw_result(res,img_ori)
    yolo.deinit()
    gc.collect()
```

##### éƒ¨ç½²æ¨¡å‹å®ç°è§†é¢‘æ¨ç†

è§†é¢‘æ¨ç†ï¼Œè¯·å‚è€ƒä¸‹è¿°ä»£ç ï¼Œ**æ ¹æ®å®é™…æƒ…å†µä¿®æ”¹ `__main__` ä¸­çš„å®šä¹‰å˜é‡**ï¼›

```python
from libs.PipeLine import PipeLine
from libs.YOLO import YOLOv8
from libs.Utils import *
import os,sys,gc
import ulab.numpy as np
import image

if __name__=="__main__":
    # è¿™é‡Œä»…ä¸ºç¤ºä¾‹ï¼Œè‡ªå®šä¹‰åœºæ™¯è¯·ä¿®æ”¹ä¸ºæ‚¨è‡ªå·±çš„æ¨¡å‹è·¯å¾„ã€æ ‡ç­¾åç§°ã€æ¨¡å‹è¾“å…¥å¤§å°
    kmodel_path="/data/best.kmodel"
    labels = ["fall"]
    model_input_size=[320,320]

    # æ·»åŠ æ˜¾ç¤ºæ¨¡å¼ï¼Œé»˜è®¤hdmiï¼Œå¯é€‰hdmi/lcd/lt9611/st7701/hx8399,å…¶ä¸­hdmié»˜è®¤ç½®ä¸ºlt9611ï¼Œåˆ†è¾¨ç‡1920*1080ï¼›lcdé»˜è®¤ç½®ä¸ºst7701ï¼Œåˆ†è¾¨ç‡800*480
    display_mode="lcd"
    rgb888p_size=[640,360]
    confidence_threshold = 0.5
    nms_threshold=0.45
    # åˆå§‹åŒ–PipeLine
    pl=PipeLine(rgb888p_size=rgb888p_size,display_mode=display_mode)
    pl.create()
    display_size=pl.get_display_size()
    # åˆå§‹åŒ–YOLOv8å®ä¾‹
    yolo=YOLOv8(task_type="detect",mode="video",kmodel_path=kmodel_path,labels=labels,rgb888p_size=rgb888p_size,model_input_size=model_input_size,display_size=display_size,conf_thresh=confidence_threshold,nms_thresh=nms_threshold,max_boxes_num=50,debug_mode=0)
    yolo.config_preprocess()
    while True:
        with ScopedTiming("total",1):
            # é€å¸§æ¨ç†
            img=pl.get_frame()
            res=yolo.run(img)
            yolo.draw_result(res,pl.osd_img)
            pl.show_image()
            gc.collect()
    yolo.deinit()
    pl.destroy()
```

##### éƒ¨ç½²æ•ˆæœ

é€‰æ‹©ä¸€å¼ è·Œå€’å›¾ç‰‡ä½¿ç”¨kmodelè¿›è¡Œè·Œå€’æ£€æµ‹ã€‚åŸå›¾å’Œæ¨ç†ç»“æœçš„å¯¹æ¯”å¦‚ä¸‹å›¾ï¼š

![fall_det_res](https://www.kendryte.com/api/post/attachment?id=625)

### YOLO11æ°´æœåˆ†å‰²

#### YOLO11æºç åŠè®­ç»ƒç¯å¢ƒæ­å»º

`YOLO11` è®­ç»ƒç¯å¢ƒæ­å»ºè¯·å‚è€ƒ[ultralytics/ultralytics: Ultralytics YOLO ğŸš€ (github.com)](https://github.com/ultralytics/ultralytics)

```shell
# Pip install the ultralytics package including all requirements in a Python>=3.8 environment with PyTorch>=1.8.
pip install ultralytics
```

å¦‚æœæ‚¨å·²æ­å»ºå¥½ç¯å¢ƒï¼Œè¯·å¿½ç•¥æ­¤æ­¥éª¤ã€‚

#### è®­ç»ƒæ•°æ®å‡†å¤‡

ä¸‹è½½æä¾›çš„æ°´æœåˆ†å‰²æ•°æ®é›†ï¼Œå¹¶è§£å‹ã€‚

```shell
cd yolo11
wget https://kendryte-download.canaan-creative.com/developer/k230/yolo_dataset/fruit_seg.zip
unzip fruit_seg.zip
```

âš ï¸ **windowsç³»ç»Ÿè¯·ç›´æ¥å¤åˆ¶é“¾æ¥åˆ°æµè§ˆå™¨ä¸‹è½½ï¼Œå¹¶è§£å‹åˆ°å¯¹åº”ç›®å½•**ã€‚

å¦‚æœæ‚¨å·²ä¸‹è½½å¥½æ•°æ®ï¼Œè¯·å¿½ç•¥æ­¤æ­¥éª¤ã€‚

#### ä½¿ç”¨YOLO11è®­ç»ƒæ°´æœåˆ†å‰²æ¨¡å‹

åœ¨ `yolo11` ç›®å½•ä¸‹æ‰§è¡Œå‘½ä»¤ï¼Œä½¿ç”¨ `yolo11` è®­ç»ƒä¸‰ç±»æ°´æœåˆ†å‰²æ¨¡å‹ï¼š

```shell
yolo segment train data=fruits_seg.yaml model=yolo11n-seg.pt epochs=100 imgsz=320
```

#### è½¬æ¢æ°´æœåˆ†å‰²kmodel

æ¨¡å‹è½¬æ¢éœ€è¦åœ¨è®­ç»ƒç¯å¢ƒå®‰è£…å¦‚ä¸‹åº“ï¼š

```Shell
# linuxå¹³å°ï¼šnncaseå’Œnncase-kpuå¯ä»¥åœ¨çº¿å®‰è£…ï¼Œnncase-2.x éœ€è¦å®‰è£… dotnet-7
sudo apt-get install -y dotnet-sdk-7.0
pip install --upgrade pip
pip install nncase==2.9.0
pip install nncase-kpu==2.9.0

# windowså¹³å°ï¼šè¯·è‡ªè¡Œå®‰è£…dotnet-7å¹¶æ·»åŠ ç¯å¢ƒå˜é‡,æ”¯æŒä½¿ç”¨pipåœ¨çº¿å®‰è£…nncaseï¼Œä½†æ˜¯nncase-kpuåº“éœ€è¦ç¦»çº¿å®‰è£…ï¼Œåœ¨https://github.com/kendryte/nncase/releasesä¸‹è½½nncase_kpu-2.*-py2.py3-none-win_amd64.whl
# è¿›å…¥å¯¹åº”çš„pythonç¯å¢ƒï¼Œåœ¨nncase_kpu-2.*-py2.py3-none-win_amd64.whlä¸‹è½½ç›®å½•ä¸‹ä½¿ç”¨pipå®‰è£…
pip install nncase_kpu-2.*-py2.py3-none-win_amd64.whl

# é™¤nncaseå’Œnncase-kpuå¤–ï¼Œè„šæœ¬è¿˜ç”¨åˆ°çš„å…¶ä»–åº“åŒ…æ‹¬ï¼š
pip install onnx
pip install onnxruntime
pip install onnxsim
```

ä¸‹è½½è„šæœ¬å·¥å…·ï¼Œå°†æ¨¡å‹è½¬æ¢è„šæœ¬å·¥å…· `test_yolo11.zip` è§£å‹åˆ° `yolo11` ç›®å½•ä¸‹ï¼›

```shell
wget https://kendryte-download.canaan-creative.com/developer/k230/yolo_files/test_yolo11.zip
unzip test_yolo11.zip
```

æŒ‰ç…§å¦‚ä¸‹å‘½ä»¤ï¼Œå¯¹ `runs/segment/train/weights` ä¸‹çš„ `pt` æ¨¡å‹å…ˆå¯¼å‡ºä¸º `onnx` æ¨¡å‹ï¼Œå†è½¬æ¢æˆ `kmodel` æ¨¡å‹ï¼š

```shell
# å¯¼å‡ºonnxï¼Œptæ¨¡å‹è·¯å¾„è¯·è‡ªè¡Œé€‰æ‹©
yolo export model=runs/segment/train/weights/best.pt format=onnx imgsz=320
cd test_yolo11/segment
# testä¸­çš„å›¾ç‰‡å¯ä»¥ä»è®­ç»ƒé›†ä¸­é€‰å–ä¸€éƒ¨åˆ†æ›¿æ¢ï¼Œè½¬æ¢kmodel,onnxæ¨¡å‹è·¯å¾„è¯·è‡ªè¡Œé€‰æ‹©ï¼Œç”Ÿæˆçš„kmodelåœ¨onnxæ¨¡å‹åŒçº§ç›®å½•ä¸‹
python to_kmodel.py --target k230 --model ../../runs/segment/train/weights/best.onnx --dataset ../test --input_width 320 --input_height 320 --ptq_option 1
cd ../../
```

ğŸ’¡ **æ¨¡å‹è½¬æ¢è„šæœ¬(to_kmodel.py)å‚æ•°è¯´æ˜**ï¼š

| å‚æ•°åç§°     | æè¿°     | è¯´æ˜                                                         | ç±»å‹  |
| ------------ | -------- | ------------------------------------------------------------| ----- |
| target       | ç›®æ ‡å¹³å° | å¯é€‰é¡¹ä¸ºk230/cpuï¼Œå¯¹åº”k230 kpuå’Œcpuï¼›                              | str   |
| model        | æ¨¡å‹è·¯å¾„ | å¾…è½¬æ¢çš„ONNXæ¨¡å‹è·¯å¾„ï¼›                                        | str   |
| dataset      | æ ¡å‡†å›¾ç‰‡é›†  | æ¨¡å‹è½¬æ¢æ—¶ä½¿ç”¨çš„å›¾ç‰‡æ•°æ®ï¼Œåœ¨é‡åŒ–é˜¶æ®µä½¿ç”¨ï¼Œå¯ä»¥ä»è®­ç»ƒé›†ä¸­å–ä¸€éƒ¨åˆ†æ›¿æ¢                    | str   |
| input_width  | è¾“å…¥å®½åº¦ | æ¨¡å‹è¾“å…¥çš„å®½åº¦                                             | int   |
| input_height | è¾“å…¥é«˜åº¦ | æ¨¡å‹è¾“å…¥çš„é«˜åº¦                                             | int   |
| ptq_option   | é‡åŒ–æ–¹å¼ | dataå’Œweightsçš„é‡åŒ–æ–¹å¼ï¼Œ0ä¸º[uint8,uint8], 1ä¸º[uint8,int16], 2ä¸º[int16,uint8] | 0/1/2 |

#### åœ¨k230ä¸Šä½¿ç”¨MicroPythonéƒ¨ç½²æ¨¡å‹

##### çƒ§å½•é•œåƒå¹¶å®‰è£…CanMV IDE

ğŸ’¡ **å›ºä»¶ä»‹ç»**ï¼šè¯·åœ¨ `github` æŒ‰ç…§æ‚¨çš„å¼€å‘æ¿ç±»å‹ä¸‹è½½æœ€æ–°çš„ [PreReleaseå›ºä»¶](https://github.com/kendryte/canmv_k230/releases/tag/PreRelease) ä»¥ä¿è¯**æœ€æ–°çš„ç‰¹æ€§**è¢«æ”¯æŒï¼æˆ–è€…ä½¿ç”¨æœ€æ–°çš„ä»£ç è‡ªè¡Œç¼–è¯‘å›ºä»¶ï¼Œæ•™ç¨‹è§ï¼š[å›ºä»¶ç¼–è¯‘](https://www.kendryte.com/k230_canmv/zh/main/zh/userguide/how_to_build.html)ã€‚

ä¸‹è½½å¹¶å®‰è£… CanMV IDE (ä¸‹è½½é“¾æ¥ï¼š[CanMV IDE download](https://www.kendryte.com/resource?selected=0-2-1))ï¼Œåœ¨ IDE ä¸­ç¼–å†™ä»£ç å¹¶è¿è¡Œã€‚

##### æ¨¡å‹æ–‡ä»¶æ‹·è´

è¿æ¥IDEï¼Œå°†è½¬æ¢å¥½çš„æ¨¡å‹å’Œæµ‹è¯•å›¾ç‰‡æ‹·è´åˆ°è·¯å¾„ `CanMV/data` ç›®å½•ä¸‹ã€‚è¯¥è·¯å¾„å¯ä»¥è‡ªå®šä¹‰ï¼Œåªéœ€è¦åœ¨ç¼–å†™ä»£ç æ—¶ä¿®æ”¹å¯¹åº”è·¯å¾„å³å¯ã€‚

##### YOLO11 æ¨¡å—

`YOLO11` ç±»é›†æˆäº† `YOLO11` çš„å››ç§ä»»åŠ¡ï¼ŒåŒ…æ‹¬åˆ†ç±»(classify)ã€æ£€æµ‹(detect)ã€åˆ†å‰²(segment)ã€æ—‹è½¬ç›®æ ‡æ£€æµ‹(obb)ï¼›æ”¯æŒä¸¤ç§æ¨ç†æ¨¡å¼ï¼ŒåŒ…æ‹¬å›¾ç‰‡(image)å’Œè§†é¢‘æµ(video)ï¼›è¯¥ç±»å°è£…äº† `YOLO11` çš„ kmodel æ¨ç†æµç¨‹ã€‚

- **å¯¼å…¥æ–¹æ³•**

```python
from libs.YOLO import YOLO11
```

- **å‚æ•°è¯´æ˜**

| å‚æ•°åç§°         | æè¿°           | è¯´æ˜                                                         | ç±»å‹         |
| ---------------- | -------------- | ------------------------------------------------------------ | ------------ |
| task_type        | ä»»åŠ¡ç±»å‹       | æ”¯æŒå››ç±»ä»»åŠ¡ï¼Œå¯é€‰é¡¹ä¸º'classify'/'detect'/'segment'/'obb'ï¼›        | str          |
| mode             | æ¨ç†æ¨¡å¼       | æ”¯æŒä¸¤ç§æ¨ç†æ¨¡å¼ï¼Œå¯é€‰é¡¹ä¸º'image'/'video'ï¼Œ'image'è¡¨ç¤ºæ¨ç†å›¾ç‰‡ï¼Œ'video'è¡¨ç¤ºæ¨ç†æ‘„åƒå¤´é‡‡é›†çš„å®æ—¶è§†é¢‘æµï¼› | str          |
| kmodel_path      | kmodelè·¯å¾„     | æ‹·è´åˆ°å¼€å‘æ¿ä¸Škmodelè·¯å¾„ï¼›                                   | str          |
| labels           | ç±»åˆ«æ ‡ç­¾åˆ—è¡¨   | ä¸åŒç±»åˆ«çš„æ ‡ç­¾åç§°ï¼›                                         | list[str]    |
| rgb888p_size     | æ¨ç†å¸§åˆ†è¾¨ç‡   | æ¨ç†å½“å‰å¸§åˆ†è¾¨ç‡ï¼Œå¦‚[1920,1080]ã€[1280,720]ã€[640,640];      | list[int]    |
| model_input_size | æ¨¡å‹è¾“å…¥åˆ†è¾¨ç‡ | YOLO11æ¨¡å‹è®­ç»ƒæ—¶çš„è¾“å…¥åˆ†è¾¨ç‡ï¼Œå¦‚[224,224]ã€[320,320]ã€[640,640]ï¼› | list[int]    |
| display_size     | æ˜¾ç¤ºåˆ†è¾¨ç‡     | æ¨ç†æ¨¡å¼ä¸º'video'æ—¶è®¾ç½®ï¼Œæ”¯æŒhdmi([1920,1080])å’Œlcd([800,480]); | list[int]    |
| conf_thresh      | ç½®ä¿¡åº¦é˜ˆå€¼     | åˆ†ç±»ä»»åŠ¡ç±»åˆ«ç½®ä¿¡åº¦é˜ˆå€¼ï¼Œæ£€æµ‹åˆ†å‰²ä»»åŠ¡çš„ç›®æ ‡ç½®ä¿¡åº¦é˜ˆå€¼ï¼Œå¦‚0.5ï¼› | floatã€0~1ã€‘ |
| nms_thresh       | nmsé˜ˆå€¼        | éæå¤§å€¼æŠ‘åˆ¶é˜ˆå€¼ï¼Œæ£€æµ‹å’Œåˆ†å‰²ä»»åŠ¡å¿…å¡«ï¼›                       | floatã€0~1ã€‘ |
| mask_thresh      | maské˜ˆå€¼       | åˆ†å‰²ä»»åŠ¡ä¸­çš„å¯¹æ£€æµ‹æ¡†ä¸­å¯¹è±¡åšåˆ†å‰²æ—¶çš„äºŒå€¼åŒ–é˜ˆå€¼ï¼›             | floatã€0~1ã€‘ |
| max_boxes_num    | æœ€å¤§æ£€æµ‹æ¡†æ•°   | ä¸€å¸§å›¾åƒä¸­å…è®¸è¿”å›çš„æœ€å¤šæ£€æµ‹æ¡†æ•°ç›®ï¼›                         | int          |
| debug_mode       | è°ƒè¯•æ¨¡å¼       | è®¡æ—¶å‡½æ•°æ˜¯å¦ç”Ÿæ•ˆï¼Œå¯é€‰é¡¹0/1ï¼Œ0ä¸ºä¸è®¡æ—¶ï¼Œ1ä¸ºè®¡æ—¶ï¼›            | intã€0/1ã€‘   |

##### éƒ¨ç½²æ¨¡å‹å®ç°å›¾ç‰‡æ¨ç†

å›¾ç‰‡æ¨ç†ï¼Œè¯·å‚è€ƒä¸‹è¿°ä»£ç ï¼Œ**æ ¹æ®å®é™…æƒ…å†µä¿®æ”¹ `__main__` ä¸­çš„å®šä¹‰å‚æ•°å˜é‡**ï¼›

```python
from libs.YOLO import YOLO11
from libs.Utils import *
import os,sys,gc
import ulab.numpy as np
import image

if __name__=="__main__":
    # è¿™é‡Œä»…ä¸ºç¤ºä¾‹ï¼Œè‡ªå®šä¹‰åœºæ™¯è¯·ä¿®æ”¹ä¸ºæ‚¨è‡ªå·±çš„æµ‹è¯•å›¾ç‰‡ã€æ¨¡å‹è·¯å¾„ã€æ ‡ç­¾åç§°ã€æ¨¡å‹è¾“å…¥å¤§å°
    img_path="/data/test.jpg"
    kmodel_path="/data/best.kmodel"
    labels = ["apple","banana","orange"]
    model_input_size=[320,320]

    confidence_threshold = 0.5
    nms_threshold=0.45
    mask_threshold=0.5
    img,img_ori=read_image(img_path)
    rgb888p_size=[img.shape[2],img.shape[1]]
    # åˆå§‹åŒ–YOLO11å®ä¾‹
    yolo=YOLO11(task_type="segment",mode="image",kmodel_path=kmodel_path,labels=labels,rgb888p_size=rgb888p_size,model_input_size=model_input_size,conf_thresh=confidence_threshold,nms_thresh=nms_threshold,mask_thresh=mask_threshold,max_boxes_num=50,debug_mode=0)
    yolo.config_preprocess()
    res=yolo.run(img)
    yolo.draw_result(res,img_ori)
    yolo.deinit()
    gc.collect()
```

##### éƒ¨ç½²æ¨¡å‹å®ç°è§†é¢‘æ¨ç†

è§†é¢‘æ¨ç†ï¼Œè¯·å‚è€ƒä¸‹è¿°ä»£ç ï¼Œ**æ ¹æ®å®é™…æƒ…å†µä¿®æ”¹ `__main__` ä¸­çš„å®šä¹‰å˜é‡**ï¼›

```python
from libs.PipeLine import PipeLine
from libs.YOLO import YOLO11
from libs.Utils import *
import os,sys,gc
import ulab.numpy as np
import image

if __name__=="__main__":
    # è¿™é‡Œä»…ä¸ºç¤ºä¾‹ï¼Œè‡ªå®šä¹‰åœºæ™¯è¯·ä¿®æ”¹ä¸ºæ‚¨è‡ªå·±çš„æ¨¡å‹è·¯å¾„ã€æ ‡ç­¾åç§°ã€æ¨¡å‹è¾“å…¥å¤§å°
    kmodel_path="/data/best.kmodel"
    labels = ["apple","banana","orange"]
    model_input_size=[320,320]

    # æ·»åŠ æ˜¾ç¤ºæ¨¡å¼ï¼Œé»˜è®¤hdmiï¼Œå¯é€‰hdmi/lcd/lt9611/st7701/hx8399,å…¶ä¸­hdmié»˜è®¤ç½®ä¸ºlt9611ï¼Œåˆ†è¾¨ç‡1920*1080ï¼›lcdé»˜è®¤ç½®ä¸ºst7701ï¼Œåˆ†è¾¨ç‡800*480
    display_mode="lcd"
    rgb888p_size=[320,320]
    confidence_threshold = 0.5
    nms_threshold=0.45
    mask_threshold=0.5
    # åˆå§‹åŒ–PipeLine
    pl=PipeLine(rgb888p_size=rgb888p_size,display_mode=display_mode)
    pl.create()
    display_size=pl.get_display_size()
    # åˆå§‹åŒ–YOLO11å®ä¾‹
    yolo=YOLO11(task_type="segment",mode="video",kmodel_path=kmodel_path,labels=labels,rgb888p_size=rgb888p_size,model_input_size=model_input_size,display_size=display_size,conf_thresh=confidence_threshold,nms_thresh=nms_threshold,mask_thresh=mask_threshold,max_boxes_num=50,debug_mode=0)
    yolo.config_preprocess()
    while True:
        with ScopedTiming("total",1):
            # é€å¸§æ¨ç†
            img=pl.get_frame()
            res=yolo.run(img)
            yolo.draw_result(res,pl.osd_img)
            pl.show_image()
            gc.collect()
    yolo.deinit()
    pl.destroy()
```

##### éƒ¨ç½²æ•ˆæœ

é€‰æ‹©ä¸€å¼ æ°´æœå›¾ç‰‡ä½¿ç”¨kmodelè¿›è¡Œæ°´æœåˆ†å‰²ã€‚åŸå›¾å’Œæ¨ç†ç»“æœçš„å¯¹æ¯”å¦‚ä¸‹å›¾ï¼š

![fruit_seg_res](https://www.kendryte.com/api/post/attachment?id=626)

### YOLO11æ—‹è½¬ç›®æ ‡æ£€æµ‹

#### YOLO11æºç åŠè®­ç»ƒç¯å¢ƒæ­å»º

`YOLO11` è®­ç»ƒç¯å¢ƒæ­å»ºè¯·å‚è€ƒ[ultralytics/ultralytics: Ultralytics YOLO ğŸš€ (github.com)](https://github.com/ultralytics/ultralytics)

```shell
# Pip install the ultralytics package including all requirements in a Python>=3.8 environment with PyTorch>=1.8.
pip install ultralytics
```

å¦‚æœæ‚¨å·²æ­å»ºå¥½ç¯å¢ƒï¼Œè¯·å¿½ç•¥æ­¤æ­¥éª¤ã€‚

#### è®­ç»ƒæ•°æ®å‡†å¤‡

ä¸‹è½½æ¡Œé¢ç­¾å­—ç¬”æ—‹è½¬ç›®æ ‡æ£€æµ‹æ•°æ®é›†ï¼Œå¹¶è§£å‹ã€‚

```shell
cd yolo11
wget https://kendryte-download.canaan-creative.com/developer/k230/yolo_dataset/pen_obb.zip
unzip pen_obb.zip
```

âš ï¸ **windowsç³»ç»Ÿè¯·ç›´æ¥å¤åˆ¶é“¾æ¥åˆ°æµè§ˆå™¨ä¸‹è½½ï¼Œå¹¶è§£å‹åˆ°å¯¹åº”ç›®å½•**ã€‚

å¦‚æœæ‚¨å·²ä¸‹è½½å¥½æ•°æ®ï¼Œè¯·å¿½ç•¥æ­¤æ­¥éª¤ã€‚

#### ä½¿ç”¨YOLO11æ—‹è½¬ç›®æ ‡æ£€æµ‹æ¨¡å‹

åœ¨ `yolo11` ç›®å½•ä¸‹æ‰§è¡Œå‘½ä»¤ï¼Œä½¿ç”¨ `yolo11` è®­ç»ƒå•ç±»æ—‹è½¬ç›®æ ‡æ£€æµ‹æ¨¡å‹ï¼š

```shell
yolo obb train data=pen_obb.yaml model=yolo11n-obb.pt epochs=100 imgsz=320
```

#### è½¬æ¢æ—‹è½¬ç›®æ ‡æ£€æµ‹kmodel

æ¨¡å‹è½¬æ¢éœ€è¦åœ¨è®­ç»ƒç¯å¢ƒå®‰è£…å¦‚ä¸‹åº“ï¼š

```Shell
# linuxå¹³å°ï¼šnncaseå’Œnncase-kpuå¯ä»¥åœ¨çº¿å®‰è£…ï¼Œnncase-2.x éœ€è¦å®‰è£… dotnet-7
sudo apt-get install -y dotnet-sdk-7.0
pip install --upgrade pip
pip install nncase==2.9.0
pip install nncase-kpu==2.9.0

# windowså¹³å°ï¼šè¯·è‡ªè¡Œå®‰è£…dotnet-7å¹¶æ·»åŠ ç¯å¢ƒå˜é‡,æ”¯æŒä½¿ç”¨pipåœ¨çº¿å®‰è£…nncaseï¼Œä½†æ˜¯nncase-kpuåº“éœ€è¦ç¦»çº¿å®‰è£…ï¼Œåœ¨https://github.com/kendryte/nncase/releasesä¸‹è½½nncase_kpu-2.*-py2.py3-none-win_amd64.whl
# è¿›å…¥å¯¹åº”çš„pythonç¯å¢ƒï¼Œåœ¨nncase_kpu-2.*-py2.py3-none-win_amd64.whlä¸‹è½½ç›®å½•ä¸‹ä½¿ç”¨pipå®‰è£…
pip install nncase_kpu-2.*-py2.py3-none-win_amd64.whl

# é™¤nncaseå’Œnncase-kpuå¤–ï¼Œè„šæœ¬è¿˜ç”¨åˆ°çš„å…¶ä»–åº“åŒ…æ‹¬ï¼š
pip install onnx
pip install onnxruntime
pip install onnxsim
```

ä¸‹è½½è„šæœ¬å·¥å…·ï¼Œå°†æ¨¡å‹è½¬æ¢è„šæœ¬å·¥å…· `test_yolo11.zip` è§£å‹åˆ° `yolo11` ç›®å½•ä¸‹ï¼›

```shell
wget https://kendryte-download.canaan-creative.com/developer/k230/yolo_files/test_yolo11.zip
unzip test_yolo11.zip
```

æŒ‰ç…§å¦‚ä¸‹å‘½ä»¤ï¼Œå¯¹ `runs/obb/train/weights` ä¸‹çš„ `pt` æ¨¡å‹å…ˆå¯¼å‡ºä¸º `onnx` æ¨¡å‹ï¼Œå†è½¬æ¢æˆ `kmodel` æ¨¡å‹ï¼š

```shell
# å¯¼å‡ºonnxï¼Œptæ¨¡å‹è·¯å¾„è¯·è‡ªè¡Œé€‰æ‹©
yolo export model=runs/obb/train/weights/best.pt format=onnx imgsz=320
cd test_yolo11/obb
# testä¸‹å›¾ç‰‡å¯ä»¥ä»è®­ç»ƒé›†ä¸­é€‰æ‹©ä¸€éƒ¨åˆ†æ›¿æ¢ï¼Œè½¬æ¢kmodel,onnxæ¨¡å‹è·¯å¾„è¯·è‡ªè¡Œé€‰æ‹©ï¼Œç”Ÿæˆçš„kmodelåœ¨onnxæ¨¡å‹åŒçº§ç›®å½•ä¸‹
python to_kmodel.py --target k230 --model ../../runs/obb/train/weights/best.onnx --dataset ../test_obb --input_width 320 --input_height 320 --ptq_option 0
cd ../../
```

ğŸ’¡ **æ¨¡å‹è½¬æ¢è„šæœ¬(to_kmodel.py)å‚æ•°è¯´æ˜**ï¼š

| å‚æ•°åç§°     | æè¿°     | è¯´æ˜                                                         | ç±»å‹  |
| ------------ | -------- | ------------------------------------------------------------| ----- |
| target       | ç›®æ ‡å¹³å° | å¯é€‰é¡¹ä¸ºk230/cpuï¼Œå¯¹åº”k230 kpuå’Œcpuï¼›                              | str   |
| model        | æ¨¡å‹è·¯å¾„ | å¾…è½¬æ¢çš„ONNXæ¨¡å‹è·¯å¾„ï¼›                                        | str   |
| dataset      | æ ¡å‡†å›¾ç‰‡é›†  | æ¨¡å‹è½¬æ¢æ—¶ä½¿ç”¨çš„å›¾ç‰‡æ•°æ®ï¼Œåœ¨é‡åŒ–é˜¶æ®µä½¿ç”¨ï¼Œå¯ä»¥ä»è®­ç»ƒé›†ä¸­å–ä¸€éƒ¨åˆ†æ›¿æ¢                    | str   |
| input_width  | è¾“å…¥å®½åº¦ | æ¨¡å‹è¾“å…¥çš„å®½åº¦                                             | int   |
| input_height | è¾“å…¥é«˜åº¦ | æ¨¡å‹è¾“å…¥çš„é«˜åº¦                                             | int   |
| ptq_option   | é‡åŒ–æ–¹å¼ | dataå’Œweightsçš„é‡åŒ–æ–¹å¼ï¼Œ0ä¸º[uint8,uint8], 1ä¸º[uint8,int16], 2ä¸º[int16,uint8] | 0/1/2 |

#### åœ¨k230ä¸Šä½¿ç”¨MicroPythonéƒ¨ç½²æ¨¡å‹

##### çƒ§å½•é•œåƒå¹¶å®‰è£…CanMV IDE

ğŸ’¡ **å›ºä»¶ä»‹ç»**ï¼šè¯·åœ¨ `github` æŒ‰ç…§æ‚¨çš„å¼€å‘æ¿ç±»å‹ä¸‹è½½æœ€æ–°çš„ [PreReleaseå›ºä»¶](https://github.com/kendryte/canmv_k230/releases/tag/PreRelease) ä»¥ä¿è¯**æœ€æ–°çš„ç‰¹æ€§**è¢«æ”¯æŒï¼æˆ–è€…ä½¿ç”¨æœ€æ–°çš„ä»£ç è‡ªè¡Œç¼–è¯‘å›ºä»¶ï¼Œæ•™ç¨‹è§ï¼š[å›ºä»¶ç¼–è¯‘](https://www.kendryte.com/k230_canmv/zh/main/zh/userguide/how_to_build.html)ã€‚

ä¸‹è½½å¹¶å®‰è£… CanMV IDE (ä¸‹è½½é“¾æ¥ï¼š[CanMV IDE download](https://www.kendryte.com/resource?selected=0-2-1))ï¼Œåœ¨ IDE ä¸­ç¼–å†™ä»£ç å¹¶è¿è¡Œã€‚

##### æ¨¡å‹æ–‡ä»¶æ‹·è´

è¿æ¥IDEï¼Œå°†è½¬æ¢å¥½çš„æ¨¡å‹å’Œæµ‹è¯•å›¾ç‰‡æ‹·è´åˆ°è·¯å¾„ `CanMV/data` ç›®å½•ä¸‹ã€‚è¯¥è·¯å¾„å¯ä»¥è‡ªå®šä¹‰ï¼Œåªéœ€è¦åœ¨ç¼–å†™ä»£ç æ—¶ä¿®æ”¹å¯¹åº”è·¯å¾„å³å¯ã€‚

##### YOLO11 æ¨¡å—

`YOLO11` ç±»é›†æˆäº† `YOLO11` çš„å››ç§ä»»åŠ¡ï¼ŒåŒ…æ‹¬åˆ†ç±»(classify)ã€æ£€æµ‹(detect)ã€åˆ†å‰²(segment)ã€æ—‹è½¬ç›®æ ‡æ£€æµ‹(obb)ï¼›æ”¯æŒä¸¤ç§æ¨ç†æ¨¡å¼ï¼ŒåŒ…æ‹¬å›¾ç‰‡(image)å’Œè§†é¢‘æµ(video)ï¼›è¯¥ç±»å°è£…äº† `YOLO11` çš„ kmodel æ¨ç†æµç¨‹ã€‚

- **å¯¼å…¥æ–¹æ³•**

```python
from libs.YOLO import YOLO11
```

- **å‚æ•°è¯´æ˜**

| å‚æ•°åç§°         | æè¿°           | è¯´æ˜                                                         | ç±»å‹         |
| ---------------- | -------------- | ------------------------------------------------------------ | ------------ |
| task_type        | ä»»åŠ¡ç±»å‹       | æ”¯æŒå››ç±»ä»»åŠ¡ï¼Œå¯é€‰é¡¹ä¸º'classify'/'detect'/'segment'/'obb'ï¼›        | str          |
| mode             | æ¨ç†æ¨¡å¼       | æ”¯æŒä¸¤ç§æ¨ç†æ¨¡å¼ï¼Œå¯é€‰é¡¹ä¸º'image'/'video'ï¼Œ'image'è¡¨ç¤ºæ¨ç†å›¾ç‰‡ï¼Œ'video'è¡¨ç¤ºæ¨ç†æ‘„åƒå¤´é‡‡é›†çš„å®æ—¶è§†é¢‘æµï¼› | str          |
| kmodel_path      | kmodelè·¯å¾„     | æ‹·è´åˆ°å¼€å‘æ¿ä¸Škmodelè·¯å¾„ï¼›                                   | str          |
| labels           | ç±»åˆ«æ ‡ç­¾åˆ—è¡¨   | ä¸åŒç±»åˆ«çš„æ ‡ç­¾åç§°ï¼›                                         | list[str]    |
| rgb888p_size     | æ¨ç†å¸§åˆ†è¾¨ç‡   | æ¨ç†å½“å‰å¸§åˆ†è¾¨ç‡ï¼Œå¦‚[1920,1080]ã€[1280,720]ã€[640,640];      | list[int]    |
| model_input_size | æ¨¡å‹è¾“å…¥åˆ†è¾¨ç‡ | YOLO11æ¨¡å‹è®­ç»ƒæ—¶çš„è¾“å…¥åˆ†è¾¨ç‡ï¼Œå¦‚[224,224]ã€[320,320]ã€[640,640]ï¼› | list[int]    |
| display_size     | æ˜¾ç¤ºåˆ†è¾¨ç‡     | æ¨ç†æ¨¡å¼ä¸º'video'æ—¶è®¾ç½®ï¼Œæ”¯æŒhdmi([1920,1080])å’Œlcd([800,480]); | list[int]    |
| conf_thresh      | ç½®ä¿¡åº¦é˜ˆå€¼     | åˆ†ç±»ä»»åŠ¡ç±»åˆ«ç½®ä¿¡åº¦é˜ˆå€¼ï¼Œæ£€æµ‹åˆ†å‰²ä»»åŠ¡çš„ç›®æ ‡ç½®ä¿¡åº¦é˜ˆå€¼ï¼Œå¦‚0.5ï¼› | floatã€0~1ã€‘ |
| nms_thresh       | nmsé˜ˆå€¼        | éæå¤§å€¼æŠ‘åˆ¶é˜ˆå€¼ï¼Œæ£€æµ‹å’Œåˆ†å‰²ä»»åŠ¡å¿…å¡«ï¼›                       | floatã€0~1ã€‘ |
| mask_thresh      | maské˜ˆå€¼       | åˆ†å‰²ä»»åŠ¡ä¸­çš„å¯¹æ£€æµ‹æ¡†ä¸­å¯¹è±¡åšåˆ†å‰²æ—¶çš„äºŒå€¼åŒ–é˜ˆå€¼ï¼›             | floatã€0~1ã€‘ |
| max_boxes_num    | æœ€å¤§æ£€æµ‹æ¡†æ•°   | ä¸€å¸§å›¾åƒä¸­å…è®¸è¿”å›çš„æœ€å¤šæ£€æµ‹æ¡†æ•°ç›®ï¼›                         | int          |
| debug_mode       | è°ƒè¯•æ¨¡å¼       | è®¡æ—¶å‡½æ•°æ˜¯å¦ç”Ÿæ•ˆï¼Œå¯é€‰é¡¹0/1ï¼Œ0ä¸ºä¸è®¡æ—¶ï¼Œ1ä¸ºè®¡æ—¶ï¼›            | intã€0/1ã€‘   |

##### éƒ¨ç½²æ¨¡å‹å®ç°å›¾ç‰‡æ¨ç†

å›¾ç‰‡æ¨ç†ï¼Œè¯·å‚è€ƒä¸‹è¿°ä»£ç ï¼Œ**æ ¹æ®å®é™…æƒ…å†µä¿®æ”¹ `__main__` ä¸­çš„å®šä¹‰å‚æ•°å˜é‡**ï¼›

```python
from libs.YOLO import YOLO11
from libs.Utils import *
import os,sys,gc
import ulab.numpy as np
import image

if __name__=="__main__":
    # è¿™é‡Œä»…ä¸ºç¤ºä¾‹ï¼Œè‡ªå®šä¹‰åœºæ™¯è¯·ä¿®æ”¹ä¸ºæ‚¨è‡ªå·±çš„æµ‹è¯•å›¾ç‰‡ã€æ¨¡å‹è·¯å¾„ã€æ ‡ç­¾åç§°ã€æ¨¡å‹è¾“å…¥å¤§å°
    img_path="/data/test_obb.jpg"
    kmodel_path="/data/best.kmodel"
    labels = ['pen']
    model_input_size=[320,320]

    confidence_threshold = 0.1
    nms_threshold=0.6
    img,img_ori=read_image(img_path)
    rgb888p_size=[img.shape[2],img.shape[1]]
    # åˆå§‹åŒ–YOLO11å®ä¾‹
    yolo=YOLO11(task_type="obb",mode="image",kmodel_path=kmodel_path,labels=labels,rgb888p_size=rgb888p_size,model_input_size=model_input_size,conf_thresh=confidence_threshold,nms_thresh=nms_threshold,max_boxes_num=100,debug_mode=0)
    yolo.config_preprocess()
    res=yolo.run(img)
    yolo.draw_result(res,img_ori)
    yolo.deinit()
    gc.collect()
```

##### éƒ¨ç½²æ¨¡å‹å®ç°è§†é¢‘æ¨ç†

è§†é¢‘æ¨ç†ï¼Œè¯·å‚è€ƒä¸‹è¿°ä»£ç ï¼Œ**æ ¹æ®å®é™…æƒ…å†µä¿®æ”¹ `__main__` ä¸­çš„å®šä¹‰å˜é‡**ï¼›

```python
from libs.PipeLine import PipeLine
from libs.Utils import *
from libs.YOLO import YOLO11
import os,sys,gc
import ulab.numpy as np
import image

if __name__=="__main__":
    # è¿™é‡Œä»…ä¸ºç¤ºä¾‹ï¼Œè‡ªå®šä¹‰åœºæ™¯è¯·ä¿®æ”¹ä¸ºæ‚¨è‡ªå·±çš„æ¨¡å‹è·¯å¾„ã€æ ‡ç­¾åç§°ã€æ¨¡å‹è¾“å…¥å¤§å°
    kmodel_path="/data/best.kmodel"
    labels = ['pen']
    model_input_size=[320,320]

    # æ·»åŠ æ˜¾ç¤ºæ¨¡å¼ï¼Œé»˜è®¤hdmiï¼Œå¯é€‰hdmi/lcd/lt9611/st7701/hx8399,å…¶ä¸­hdmié»˜è®¤ç½®ä¸ºlt9611ï¼Œåˆ†è¾¨ç‡1920*1080ï¼›lcdé»˜è®¤ç½®ä¸ºst7701ï¼Œåˆ†è¾¨ç‡800*480
    display_mode="lcd"
    rgb888p_size=[640,360]
    confidence_threshold = 0.1
    nms_threshold=0.6
    # åˆå§‹åŒ–PipeLine
    pl=PipeLine(rgb888p_size=rgb888p_size,display_mode=display_mode)
    pl.create()
    display_size=pl.get_display_size()
    # åˆå§‹åŒ–YOLO11å®ä¾‹
    yolo=YOLO11(task_type="obb",mode="video",kmodel_path=kmodel_path,labels=labels,rgb888p_size=rgb888p_size,model_input_size=model_input_size,display_size=display_size,conf_thresh=confidence_threshold,nms_thresh=nms_threshold,max_boxes_num=50,debug_mode=0)
    yolo.config_preprocess()
    while True:
        with ScopedTiming("total",1):
            # é€å¸§æ¨ç†
            img=pl.get_frame()
            res=yolo.run(img)
            yolo.draw_result(res,pl.osd_img)
            pl.show_image()
            gc.collect()
    yolo.deinit()
    pl.destroy()
```

##### éƒ¨ç½²æ•ˆæœ

é€‰æ‹©ä¸€å¼ æ¡Œé¢ç­¾å­—ç¬”å›¾ç‰‡ä½¿ç”¨kmodelè¿›è¡Œæ—‹è½¬ç›®æ ‡æ£€æµ‹ã€‚åŸå›¾å’Œæ¨ç†ç»“æœçš„å¯¹æ¯”å¦‚ä¸‹å›¾ï¼š

![pen_obb_res](https://www.kendryte.com/api/post/attachment?id=627)

## è¾…åŠ©å·¥å…·

### åœ¨çº¿è®­ç»ƒå¹³å°

#### äº‘è®­ç»ƒå¹³å°ç®€ä»‹

Canaanå¼€å‘è€…ç¤¾åŒºæ¨¡å‹è®­ç»ƒåŠŸèƒ½æ˜¯ä¸ºç®€åŒ–å¼€å‘æµç¨‹ï¼Œæé«˜å¼€å‘æ•ˆç‡å¼€æ”¾çš„è®­ç»ƒå¹³å°ã€‚è¯¥å¹³å°ä½¿ç”¨æˆ·å…³æ³¨è§†è§‰åœºæ™¯çš„è½åœ°å®ç°ï¼Œæ›´åŠ å¿«æ·çš„å®Œæˆä»æ•°æ®æ ‡æ³¨åˆ°è·å¾—éƒ¨ç½²åŒ…ä¸­çš„KModelæ¨¡å‹çš„è¿‡ç¨‹ï¼Œå¹¶åœ¨æ­è½½å˜‰æ¥ ç§‘æŠ€KendryteÂ®ç³»åˆ—AIoTèŠ¯ç‰‡ä¸­K230ã€K230DèŠ¯ç‰‡å¼€å‘æ¿ä¸Šè¿›è¡Œéƒ¨ç½²ã€‚ç”¨æˆ·ä»…éœ€ä¸Šä¼ æ•°æ®é›†ï¼Œç®€å•çš„é…ç½®å‚æ•°å°±å¯ä»¥å¼€å§‹è®­ç»ƒäº†ã€‚

![plat](https://www.kendryte.com/api/post/attachment?id=600)

ğŸ“Œå¹³å°åœ°å€ï¼š**[å˜‰æ¥ äº‘è®­ç»ƒå¹³å°](https://www.kendryte.com/zh/training/start)**

ğŸ“Œå¹³å°ä½¿ç”¨æ–‡æ¡£å‚è€ƒï¼š**[å˜‰æ¥ äº‘è®­ç»ƒå¹³å°æ–‡æ¡£æ•™ç¨‹](https://www.kendryte.com/web/CloudPlatDoc.html)**ï¼Œè¯·æ³¨æ„æ•°æ®é›†çš„æ ¼å¼ï¼

#### æ”¯æŒä»»åŠ¡ä»‹ç»

äº‘è®­ç»ƒå¹³å°ä¸­å¯¹äºK230ç³»åˆ—èŠ¯ç‰‡æ”¯æŒçš„è§†è§‰ä»»åŠ¡æœ‰7ç§ï¼Œä»»åŠ¡ä»‹ç»å¦‚ä¸‹è¡¨ï¼š

ğŸ’¡ **ä»»åŠ¡ä»‹ç»**ï¼š

| ä»»åŠ¡åç§°  | ä»»åŠ¡è¯´æ˜                                                                                                           |
| ----- | --------------------------------------------------------------------------------------------------------------------- |
| å›¾åƒåˆ†ç±»  | å¯¹å›¾ç‰‡è¿›è¡Œåˆ†ç±»ï¼Œå¾—åˆ°å›¾ç‰‡çš„ç±»åˆ«ç»“æœå’Œåˆ†æ•°ã€‚                                                                            |
| å›¾åƒæ£€æµ‹  | åœ¨å›¾ç‰‡ä¸­æ£€æµ‹å‡ºç›®æ ‡ç‰©ä½“ï¼Œå¹¶ç»™å‡ºç‰©ä½“çš„ä½ç½®ä¿¡æ¯ã€ç±»åˆ«ä¿¡æ¯å’Œåˆ†æ•°ã€‚                                                          |
| è¯­ä¹‰åˆ†å‰²  | å¯¹å›¾ç‰‡ä¸­çš„ç›®æ ‡åŒºåŸŸè¿›è¡Œåˆ†å‰²ï¼Œå°†å›¾ç‰‡ä¸­çš„ä¸åŒæ ‡ç­¾åŒºåŸŸåˆ‡å‰²å‡ºæ¥ï¼Œå±äºåƒç´ çº§ä»»åŠ¡ã€‚                                              |
| OCRæ£€æµ‹ | åœ¨å›¾ç‰‡ä¸­æ£€æµ‹å‡ºæ–‡æœ¬åŒºåŸŸï¼Œå¹¶ç»™å‡ºæ–‡æœ¬åŒºåŸŸçš„ä½ç½®ä¿¡æ¯ã€‚                                                                        |
| OCRè¯†åˆ« | åœ¨å›¾ç‰‡ä¸­è¯†åˆ«å‡ºæ–‡æœ¬å†…å®¹ã€‚                                                                                                |
| åº¦é‡å­¦ä¹   | è®­ç»ƒå¯ä»¥å°†å›¾ç‰‡ç‰¹å¾åŒ–çš„æ¨¡å‹ï¼Œä½¿ç”¨è¯¥æ¨¡å‹åˆ›å»ºç‰¹å¾åº“ï¼Œé€šè¿‡ç‰¹å¾å¯¹æ¯”ï¼Œåœ¨ä¸é‡æ–°è®­ç»ƒæ¨¡å‹çš„å‰æä¸‹å¯¹æ–°çš„ç±»åˆ«è¿›è¡Œåˆ†ç±»ï¼Œä¹Ÿå¯ç§°ä¸ºè‡ªå­¦ä¹ ã€‚   |
| å¤šæ ‡ç­¾åˆ†ç±» | å¯¹å›¾ç‰‡è¿›è¡Œå¤šç±»åˆ«åˆ†ç±»ï¼Œä¸€äº›å›¾ç‰‡å¯èƒ½ä¸åªæ˜¯å±äºæŸä¸ªå•ä¸€çš„ç±»åˆ«ï¼Œå¤©ç©ºå’Œå¤§æµ·å¯ä»¥åŒæ—¶å­˜åœ¨ï¼Œå¾—åˆ°å›¾ç‰‡çš„å¤šæ ‡ç­¾åˆ†ç±»ç»“æœã€‚               |

#### éƒ¨ç½²æ­¥éª¤

##### éƒ¨ç½²åŒ…è¯´æ˜

è®­ç»ƒç»“æŸåå¯ä»¥ä¸‹è½½å¯¹åº”è®­ç»ƒä»»åŠ¡çš„éƒ¨ç½²åŒ…ï¼Œä¸‹è½½çš„éƒ¨ç½²zipåŒ…è§£å‹åï¼Œç›®å½•å¦‚ä¸‹ï¼š

```shell
ğŸ“¦ task_name
â”œâ”€â”€ ğŸ“ **_result
â”‚   â”œâ”€â”€ test_0.jpg
â”‚   â”œâ”€â”€ test_1.jpg
â”‚   â””â”€â”€...
â”œâ”€â”€ mp_deployment_source
â”œâ”€â”€ **_image_1_2_2.py
â”œâ”€â”€ **_image_1_3.py
â”œâ”€â”€ **_video_1_2_2.py
â”œâ”€â”€ **_video_1_3.py
â””â”€â”€ README.pdf
```

å†…å®¹å¦‚å›¾æ‰€ç¤ºï¼š

![éƒ¨ç½²åŒ…](https://www.kendryte.com/api/post/attachment?id=657)

å…¶ä¸­`mp_deployment_source`å³æ˜¯åœ¨K230 MicroPython é•œåƒä¸Šéƒ¨ç½²çš„ä»£ç åŒ…ï¼Œå†…éƒ¨åŒ…å«éƒ¨ç½²çš„é…ç½®æ–‡ä»¶å’Œéƒ¨ç½²çš„KModelæ¨¡å‹ã€‚

##### æ–‡ä»¶æ‹·è´

âœ… **å›ºä»¶é€‰æ‹©**ï¼šè¯·åœ¨ `github` æŒ‰ç…§æ‚¨çš„å¼€å‘æ¿ç±»å‹ä¸‹è½½æœ€æ–°çš„ [PreReleaseå›ºä»¶](https://github.com/kendryte/canmv_k230/releases/tag/PreRelease) ä»¥ä¿è¯**æœ€æ–°çš„ç‰¹æ€§**è¢«æ”¯æŒï¼æˆ–è€…ä½¿ç”¨æœ€æ–°çš„ä»£ç è‡ªè¡Œç¼–è¯‘å›ºä»¶ï¼Œæ•™ç¨‹è§ï¼š[å›ºä»¶ç¼–è¯‘](https://www.kendryte.com/k230_canmv/zh/main/zh/userguide/how_to_build.html)ã€‚

âœ… **å›ºä»¶çƒ§å½•**ï¼š æŒ‰ç…§å¼€å‘æ¿ç±»å‹çƒ§å½•å›ºä»¶ï¼Œå›ºä»¶çƒ§å½•å‚è€ƒï¼š[å›ºä»¶çƒ§å½•](https://www.kendryte.com/k230_canmv/zh/main/zh/userguide/how_to_burn_firmware.html)ã€‚

âœ… **éƒ¨ç½²è„šæœ¬**ï¼šå›ºä»¶çƒ§å½•æˆåŠŸåï¼Œä¸Šç”µå¼€æœºï¼Œæ‚¨å¯ä»¥åœ¨æ–‡ä»¶ç³»ç»Ÿæ ¹ç›®å½•ä¸‹å‘ç°`CanMV/sdcard`ç›®å½•ï¼Œå°†`mp_deployment_source`æ‹·è´åˆ°`CanMV/sdcard`ç›®å½•ä¸‹ã€‚

##### è„šæœ¬è¿è¡Œ

æ‰“å¼€CanMV IDE K230ï¼Œé€‰æ‹©å·¦ä¸Šè§’`æ–‡ä»¶(F)`->`æ‰“å¼€æ–‡ä»¶`->`é€‰æ‹©CanMV/sdcard/examples/19-CloudPlatScripts`ä¸­çš„ä¸åŒä»»åŠ¡çš„è„šæœ¬è¿è¡Œã€‚

ğŸ’¡ **è„šæœ¬ä»‹ç»**ï¼š

|è„šæœ¬åç§°|è„šæœ¬è¯´æ˜|
|--|--|
|deploy_cls_image.py|å›¾åƒåˆ†ç±»å•å›¾æ¨ç†è„šæœ¬ï¼Œæ‚¨éœ€è¦åœ¨è‡ªè¡Œå¢åŠ æµ‹è¯•å›¾ç‰‡ï¼Œå¹¶ä¿®æ”¹è„šæœ¬å†…è¯»å…¥å›¾ç‰‡çš„è·¯å¾„ã€‚|
|deploy_cls_video.py|å›¾åƒåˆ†ç±»è§†é¢‘æµæ¨ç†è„šæœ¬ï¼Œè„šæœ¬è¯¦æƒ…è§è„šæœ¬å†…æ³¨é‡Šã€‚|
|deploy_det_image.py|ç›®æ ‡æ£€æµ‹å•å›¾æ¨ç†è„šæœ¬ï¼Œæ‚¨éœ€è¦åœ¨è‡ªè¡Œå¢åŠ æµ‹è¯•å›¾ç‰‡ï¼Œå¹¶ä¿®æ”¹è„šæœ¬å†…è¯»å…¥å›¾ç‰‡çš„è·¯å¾„ã€‚|
|deploy_det_video.py|ç›®æ ‡æ£€æµ‹è§†é¢‘æµæ¨ç†è„šæœ¬ï¼Œè„šæœ¬è¯¦æƒ…è§è„šæœ¬å†…æ³¨é‡Šã€‚|
|deploy_seg_image.py|è¯­ä¹‰åˆ†å‰²å•å›¾æ¨ç†è„šæœ¬ï¼Œæ‚¨éœ€è¦åœ¨è‡ªè¡Œå¢åŠ æµ‹è¯•å›¾ç‰‡ï¼Œå¹¶ä¿®æ”¹è„šæœ¬å†…è¯»å…¥å›¾ç‰‡çš„è·¯å¾„ã€‚|
|deploy_seg_video.py|è¯­ä¹‰åˆ†å‰²è§†é¢‘æµæ¨ç†è„šæœ¬ï¼Œè„šæœ¬è¯¦æƒ…è§è„šæœ¬å†…æ³¨é‡Šã€‚|
|deploy_ocrdet_image.py|OCRæ£€æµ‹å•å›¾æ¨ç†è„šæœ¬ï¼Œæ‚¨éœ€è¦åœ¨è‡ªè¡Œå¢åŠ æµ‹è¯•å›¾ç‰‡ï¼Œå¹¶è„šæœ¬ä¿®æ”¹è¯»å…¥å›¾ç‰‡çš„è·¯å¾„ã€‚|
|deploy_ocrdet_video.py|OCRæ£€æµ‹è§†é¢‘æµæ¨ç†è„šæœ¬ï¼Œè„šæœ¬è¯¦æƒ…è§è„šæœ¬å†…æ³¨é‡Šã€‚|
|deploy_ocrrec_image.py|OCRè¯†åˆ«å•å›¾æ¨ç†è„šæœ¬ï¼Œæ‚¨éœ€è¦åœ¨è‡ªè¡Œå¢åŠ æµ‹è¯•å›¾ç‰‡ï¼Œå¹¶è„šæœ¬ä¿®æ”¹è¯»å…¥å›¾ç‰‡çš„è·¯å¾„ã€‚è€ƒè™‘åˆ°å¹³å°OCRè¯†åˆ«æ¨¡å‹å•æ¬¡æ¨ç†è¯»å…¥çš„æ•°æ®ä¸ºé•¿æ¡çŠ¶æ–‡æœ¬ï¼Œå› æ­¤**ä¸æ”¯æŒ**è§†é¢‘æµæ¨ç†ã€‚|
|deploy_ocr_image.py|OCRå•å›¾æ¨ç†è„šæœ¬ï¼Œæ‚¨éœ€è¦åœ¨è‡ªè¡Œå¢åŠ æµ‹è¯•å›¾ç‰‡ï¼Œå¹¶è„šæœ¬ä¿®æ”¹è¯»å…¥å›¾ç‰‡çš„è·¯å¾„ã€‚åŒæ¨¡å‹ä»»åŠ¡ï¼Œéœ€è¦åŒæ—¶æ·»åŠ OCRæ£€æµ‹å’ŒOCRè¯†åˆ«çš„éƒ¨ç½²åŒ…ï¼Œæ³¨æ„ä¿®æ”¹è„šæœ¬å†…ç›®å½•è·¯å¾„ã€‚|
|deploy_ocr_video.py|OCRè§†é¢‘æµæ¨ç†è„šæœ¬ï¼Œè„šæœ¬è¯¦æƒ…è§è„šæœ¬å†…æ³¨é‡Šã€‚åŒæ¨¡å‹ä»»åŠ¡ï¼Œéœ€è¦åŒæ—¶æ·»åŠ OCRæ£€æµ‹å’ŒOCRè¯†åˆ«çš„éƒ¨ç½²åŒ…ï¼Œæ³¨æ„ä¿®æ”¹è„šæœ¬å†…ç›®å½•è·¯å¾„ã€‚|
|deploy_ml_image.py|åº¦é‡å­¦ä¹ å•å›¾æ¨ç†è„šæœ¬ï¼Œæ‚¨éœ€è¦åœ¨è‡ªè¡Œå¢åŠ æµ‹è¯•å›¾ç‰‡ï¼Œå¹¶è„šæœ¬ä¿®æ”¹è¯»å…¥å›¾ç‰‡çš„è·¯å¾„ã€‚è¾“å‡ºä¸ºå¯¹åº”ç»´åº¦çš„ç‰¹å¾ï¼Œåç»­æ“ä½œè§†åº”ç”¨åœºæ™¯ä¿®æ”¹ã€‚|
|deploy_ml_video.py|åº¦é‡å­¦ä¹ è§†é¢‘æµæ¨ç†è„šæœ¬ï¼Œè„šæœ¬è¯¦æƒ…è§è„šæœ¬å†…æ³¨é‡Šã€‚è¾“å‡ºä¸ºå¯¹åº”ç»´åº¦çš„ç‰¹å¾ï¼Œåç»­æ“ä½œè§†åº”ç”¨åœºæ™¯ä¿®æ”¹ã€‚|
|deploy_multl_image.py|å¤šæ ‡ç­¾åˆ†ç±»å•å›¾æ¨ç†è„šæœ¬ï¼Œæ‚¨éœ€è¦åœ¨è‡ªè¡Œå¢åŠ æµ‹è¯•å›¾ç‰‡ï¼Œå¹¶è„šæœ¬ä¿®æ”¹è¯»å…¥å›¾ç‰‡çš„è·¯å¾„ã€‚|
|deploy_multl_video.py|å¤šæ ‡ç­¾åˆ†ç±»è§†é¢‘æµæ¨ç†è„šæœ¬ï¼Œè„šæœ¬è¯¦æƒ…è§è„šæœ¬å†…æ³¨é‡Šã€‚|

##### éƒ¨ç½²è¯´æ˜

- ğŸ“¢ åœ¨éƒ¨ç½²æ¨¡å‹æ—¶å¦‚æœæ•ˆæœä¸ç†æƒ³ï¼Œé¦–å…ˆè°ƒæ•´å¯¹åº”ä»»åŠ¡çš„é˜ˆå€¼å’Œæ¨ç†å›¾åƒçš„åˆ†è¾¨ç‡ï¼Œæµ‹è¯•ç»“æœæ˜¯å¦å¯ä»¥æœ‰å¥½è½¬ï¼

- ğŸ“¢ å­¦ä¼šå®šä½é—®é¢˜ï¼Œæ¯”å¦‚æŸ¥çœ‹éƒ¨ç½²åŒ…ä¸­çš„`**_results`ç›®å½•ä¸‹çš„æµ‹è¯•å›¾ç‰‡ï¼Œå¦‚æœè¯¥å›¾ç‰‡æ­£å¸¸ï¼Œåˆ™å¯èƒ½æ˜¯éƒ¨ç½²ä»£ç ã€æ¨¡å‹è½¬æ¢æˆ–è€…é˜ˆå€¼çš„é—®é¢˜ï¼

- ğŸ“¢ è°ƒæ•´æ¨¡å‹è®­ç»ƒçš„å‚æ•°ï¼Œæ¯”å¦‚`epoch`ã€`learning_rate`ç­‰ï¼Œé˜²æ­¢å‡ºç°è®­ç»ƒä¸å……åˆ†çš„æƒ…å†µï¼

### AICube

#### AICubeç®€ä»‹

AICubeæ˜¯å˜‰æ¥ ä¸ºå¼€å‘è€…æä¾›çš„ç¦»çº¿è®­ç»ƒå·¥å…·ï¼Œè¯¥å¹³å°ä¿è¯äº†æ•°æ®å®‰å…¨æ€§ï¼Œå®ç°å¯è§†åŒ–çš„æœ¬åœ°è®­ç»ƒã€‚è¯¥å¹³å°æ”¯æŒå›¾åƒåˆ†ç±»ã€ç›®æ ‡æ£€æµ‹ã€è¯­ä¹‰åˆ†å‰²ã€OCRæ£€æµ‹ã€OCRè¯†åˆ«ã€åº¦é‡å­¦ä¹ ã€å¤šæ ‡ç­¾åˆ†ç±»ã€å¼‚å¸¸æ£€æµ‹å…±8ä¸ªä»»åŠ¡ã€‚å…¶ç›¸å¯¹äºåœ¨çº¿è®­ç»ƒå¹³å°ï¼Œå¯ä»¥ä¿è¯ç”¨æˆ·ä½¿ç”¨æœ¬åœ°çš„GPUå®ç°æ¨¡å‹è®­ç»ƒï¼Œå¹¶å°†æ¨¡å‹è½¬æ¢æˆkmodeléƒ¨ç½²åœ¨K230ä¸Šã€‚

#### ç¯å¢ƒå‡†å¤‡å’Œè½¯ä»¶å®‰è£…

åœ¨å®‰è£…AICubeå‰ï¼Œè¯·å…³æ³¨ä¸€ä¸‹å‰ææ¡ä»¶æ˜¯å¦å…·å¤‡ï¼š

- å¸¦æœ‰NVIDIA GPUçš„è®¾å¤‡ï¼Œæ¨èæ˜¾å­˜8Gä»¥ä¸Šï¼›

- è®¡ç®—æœºå·²å®‰è£…CUDA 11.7ä»¥åŠä»¥ä¸Šç‰ˆæœ¬ï¼Œå·²å®‰è£…CUDNNï¼›

- è®¡ç®—æœºå·²å®‰è£…dotnet 7.0ï¼Œå¹¶å°†å®‰è£…è·¯å¾„æ·»åŠ åˆ°ç¯å¢ƒå˜é‡ï¼›

- æ¨èè®¡ç®—æœºå†…å­˜åœ¨8GBä»¥ä¸Šï¼Œç¡¬ç›˜å‰©ä½™ç©ºé—´è‡³å°‘20GBä»¥ä¸Šï¼›

å¦‚æœæ‚¨çš„è®¡ç®—æœºæ»¡è¶³ä¸Šè¿°æ¡ä»¶ï¼Œå¯ä»¥ä¸‹è½½AICubeå¹¶è§£å‹ä½¿ç”¨ã€‚AICubeæä¾›äº†ubuntuç‰ˆæœ¬å’Œwindowsç‰ˆæœ¬çš„å®‰è£…åŒ…ï¼Œå› ä¸ºå®‰è£…åŒ…å†…åŒ…å«äº†é…å¥—çš„**torchè®­ç»ƒç¯å¢ƒã€å¤šä¸ªé¢„è®­ç»ƒæ¨¡å‹å’Œç¤ºä¾‹æ•°æ®é›†**ï¼Œå› æ­¤å®‰è£…åŒ…è¾ƒå¤§ï¼Œ**è¯·åœ¨åˆé€‚çš„ç½‘ç»œç¯å¢ƒä¸‹è½½**ï¼Œä¸‹è½½åœ°å€è§: [AICubeä¸‹è½½](https://www.kendryte.com/zh/resource?selected=4-2)ã€‚ä½¿ç”¨æ­¥éª¤è¯·å‚è€ƒå¯¹åº”ç‰ˆæœ¬çš„ç”¨æˆ·æŒ‡å—ã€‚

ğŸ“¢ **ä¸‹è½½æ—¶è¯·é€‰æ‹©æœ€æ–°ç‰ˆæœ¬ä¸‹è½½**ã€‚

#### æ”¯æŒä»»åŠ¡ä»‹ç»

AICubeä¸­å¯¹äºK230ç³»åˆ—èŠ¯ç‰‡æ”¯æŒçš„è§†è§‰ä»»åŠ¡æœ‰8ç§ï¼Œä»»åŠ¡ä»‹ç»å¦‚ä¸‹è¡¨ï¼š

ğŸ’¡ **ä»»åŠ¡ä»‹ç»**ï¼š

| ä»»åŠ¡åç§°  | ä»»åŠ¡è¯´æ˜                                                                                                           |
| ----- | --------------------------------------------------------------------------------------------------------------------- |
| å›¾åƒåˆ†ç±»  | å¯¹å›¾ç‰‡è¿›è¡Œåˆ†ç±»ï¼Œå¾—åˆ°å›¾ç‰‡çš„ç±»åˆ«ç»“æœå’Œåˆ†æ•°ã€‚                                                                            |
| å›¾åƒæ£€æµ‹  | åœ¨å›¾ç‰‡ä¸­æ£€æµ‹å‡ºç›®æ ‡ç‰©ä½“ï¼Œå¹¶ç»™å‡ºç‰©ä½“çš„ä½ç½®ä¿¡æ¯ã€ç±»åˆ«ä¿¡æ¯å’Œåˆ†æ•°ã€‚                                                          |
| è¯­ä¹‰åˆ†å‰²  | å¯¹å›¾ç‰‡ä¸­çš„ç›®æ ‡åŒºåŸŸè¿›è¡Œåˆ†å‰²ï¼Œå°†å›¾ç‰‡ä¸­çš„ä¸åŒæ ‡ç­¾åŒºåŸŸåˆ‡å‰²å‡ºæ¥ï¼Œå±äºåƒç´ çº§ä»»åŠ¡ã€‚                                              |
| OCRæ£€æµ‹ | åœ¨å›¾ç‰‡ä¸­æ£€æµ‹å‡ºæ–‡æœ¬åŒºåŸŸï¼Œå¹¶ç»™å‡ºæ–‡æœ¬åŒºåŸŸçš„ä½ç½®ä¿¡æ¯ã€‚                                                                        |
| OCRè¯†åˆ« | åœ¨å›¾ç‰‡ä¸­è¯†åˆ«å‡ºæ–‡æœ¬å†…å®¹ã€‚                                                                                                |
| åº¦é‡å­¦ä¹   | è®­ç»ƒå¯ä»¥å°†å›¾ç‰‡ç‰¹å¾åŒ–çš„æ¨¡å‹ï¼Œä½¿ç”¨è¯¥æ¨¡å‹åˆ›å»ºç‰¹å¾åº“ï¼Œé€šè¿‡ç‰¹å¾å¯¹æ¯”ï¼Œåœ¨ä¸é‡æ–°è®­ç»ƒæ¨¡å‹çš„å‰æä¸‹å¯¹æ–°çš„ç±»åˆ«è¿›è¡Œåˆ†ç±»ï¼Œä¹Ÿå¯ç§°ä¸ºè‡ªå­¦ä¹ ã€‚   |
| å¤šæ ‡ç­¾åˆ†ç±» | å¯¹å›¾ç‰‡è¿›è¡Œå¤šç±»åˆ«åˆ†ç±»ï¼Œä¸€äº›å›¾ç‰‡å¯èƒ½ä¸åªæ˜¯å±äºæŸä¸ªå•ä¸€çš„ç±»åˆ«ï¼Œå¤©ç©ºå’Œå¤§æµ·å¯ä»¥åŒæ—¶å­˜åœ¨ï¼Œå¾—åˆ°å›¾ç‰‡çš„å¤šæ ‡ç­¾åˆ†ç±»ç»“æœã€‚               |
|å¼‚å¸¸æ£€æµ‹| ç”¨äºæ£€æµ‹æŸç±»äº§å“ä¸­çš„å¼‚å¸¸ç±»åˆ«ï¼Œå¸¸ç”¨äºå·¥ä¸šè´¨æ£€ç­‰é¢†åŸŸã€‚|

#### ä½¿ç”¨è¯´æ˜

##### åŠŸèƒ½é¡µä»‹ç»

AI CubeåŒ…å«5ä¸ªåŠŸèƒ½é¡µï¼Œâ€œé¡¹ç›®â€é¡µé¢ä¸»è¦å®ç°é¡¹ç›®ç®¡ç†åŠŸèƒ½ï¼Œå±•ç¤ºå½“å‰é¡¹ç›®å’Œæœ€è¿‘é¡¹ç›®ï¼›â€œå›¾åƒâ€é¡µé¢å±•ç¤ºå½“å‰é¡¹ç›®çš„æ•°æ®é›†ä¿¡æ¯ï¼Œä¾¿äºç”¨æˆ·æŸ¥çœ‹æ•°æ®é›†çš„å›¾ç‰‡ï¼›â€œæ‹†åˆ†â€é¡µé¢å±•ç¤ºæ‹†åˆ†ä¿¡æ¯ï¼Œç»Ÿè®¡æ‹†åˆ†ç±»åˆ«å’Œä¸åŒæ‹†åˆ†é›†çš„å›¾ç‰‡ï¼›â€œè®­ç»ƒâ€é¡µé¢å®ç°è®­ç»ƒå‚æ•°é…ç½®ï¼Œè®­ç»ƒä¿¡æ¯å’Œè®­ç»ƒæ›²çº¿çš„æ˜¾ç¤ºï¼›â€œè¯„ä¼°â€é¡µé¢å®ç°æ¨¡å‹è¯„ä¼°å’Œè¯„ä¼°ä¿¡æ¯çš„å±•ç¤ºï¼Œå¹¶ä¸”å¯ä»¥é…ç½®éƒ¨ç½²å¿…è¦å‚æ•°ç”Ÿæˆéƒ¨ç½²åŒ…ã€‚

ğŸ—‚ï¸ **é¡¹ç›®é¡µé¢**å›¾ç¤ºï¼š

![é¡¹ç›®é¡µé¢](https://www.kendryte.com/api/post/attachment?id=616)

ğŸ—‚ï¸ **å›¾åƒé¡µé¢**å›¾ç¤ºï¼š

![å›¾åƒé¡µé¢](https://www.kendryte.com/api/post/attachment?id=617)

ğŸ—‚ï¸ **æ‹†åˆ†é¡µé¢**å›¾ç¤ºï¼š

![æ‹†åˆ†é¡µé¢](https://www.kendryte.com/api/post/attachment?id=618)

ğŸ—‚ï¸ **è®­ç»ƒé¡µé¢**å›¾ç¤ºï¼š

![è®­ç»ƒé¡µé¢](https://www.kendryte.com/api/post/attachment?id=619)

ğŸ—‚ï¸ **è¯„ä¼°é¡µé¢**å›¾ç¤ºï¼š

![è¯„ä¼°é¡µé¢](https://www.kendryte.com/api/post/attachment?id=620)

##### åˆ›å»ºæ•°æ®é›†

æŒ‰ç…§ä¸åŒä»»åŠ¡çš„æ•°æ®é›†æ ¼å¼ç»„ç»‡æ•°æ®é›†ã€‚å¯¹åº”æ•°æ®é›†æ ¼å¼åœ¨`é¡¹ç›®é¡µé¢`ç‚¹å‡»æ–°å»ºé¡¹ç›®æŸ¥çœ‹ï¼ŒåŒæ—¶æˆ‘ä»¬æä¾›äº†ä¸åŒä»»åŠ¡çš„ç¤ºä¾‹æ•°æ®é›†ï¼Œåœ¨`example_dataset`ç›®å½•ä¸‹ï¼›å¹¶ä½¿ç”¨è¿™äº›ç¤ºä¾‹æ•°æ®é›†åˆ›å»ºäº†ç¤ºä¾‹é¡¹ç›®ï¼Œä½äº`example_projects`ç›®å½•ä¸‹ã€‚

å…³äºä¸åŒä»»åŠ¡çš„ç¤ºä¾‹æ•°æ®é›†å’Œç¤ºä¾‹ä»»åŠ¡ï¼Œå¯¹åº”å…³ç³»å¦‚ä¸‹ï¼š

| æ•°æ®é›†åç§°     | ç¤ºä¾‹ä»»åŠ¡   | è¯´æ˜                   |
| -------------- | ---------- | ---------------------- |
| vegetable_cls  | å›¾åƒåˆ†ç±»   | è”¬èœåˆ†ç±»åœºæ™¯           |
| insect         | ç›®æ ‡æ£€æµ‹   | æ˜†è™«æ£€æµ‹åœºæ™¯           |
| Ocular_lesions | è¯­ä¹‰åˆ†å‰²   | çœ¼çƒç—…å˜åŒºåŸŸåˆ†å‰²åœºæ™¯   |
| dataset_td100  | OCRæ£€æµ‹    | OCRæ–‡å­—æ£€æµ‹åœºæ™¯        |
| ProductionDate | OCRè¯†åˆ«    | ç”Ÿäº§æ—¥æœŸè¯†åˆ«åœºæ™¯       |
| drink          | åº¦é‡å­¦ä¹    | é¥®æ–™ç“¶åˆ†ç±»åœºæ™¯         |
| multilabel2000 | å¤šæ ‡ç­¾åˆ†ç±» | è‡ªç„¶é£å…‰å¤šæ ‡ç­¾åˆ†ç±»åœºæ™¯ |
| bottle         | å¼‚å¸¸æ£€æµ‹   | ç“¶å£å¼‚å¸¸æ£€æµ‹åœºæ™¯       |

æ‚¨å¯ä»¥ä½¿ç”¨æˆ‘ä»¬æä¾›çš„ç¤ºä¾‹æ•°æ®é›†ï¼Œä¹Ÿå¯ä»¥è‡ªå·±æŒ‰ç…§`æ–°å»ºé¡¹ç›®ç•Œé¢`å¯¹åº”ä»»åŠ¡æ ¼å¼ç»„ç»‡æ‚¨çš„æ•°æ®é›†ã€‚AICubeé‡åˆ°çš„å¤§å¤šæ•°é—®é¢˜éƒ½æ˜¯æ•°æ®çš„é—®é¢˜ï¼Œæˆ‘ä»¬åªå¯¹æ•°æ®é›†çš„ç›®å½•ç»“æ„å®ç°äº†æ£€æŸ¥ï¼Œå¹¶æ²¡æœ‰å¯¹æ•°æ®å†…éƒ¨çš„æ ‡æ³¨ä¿¡æ¯åšæ£€æŸ¥ï¼Œè¯·è°¨æ…çš„å¤„ç†æ•°æ®ã€‚

##### åˆ›å»ºé¡¹ç›®

è¿›å…¥`é¡¹ç›®é¡µé¢`--->ç‚¹å‡»`æ–°å»ºé¡¹ç›®`æŒ‰é’®--->é€‰æ‹©ä»»åŠ¡ç±»å‹--->å¯¼å…¥æ•°æ®é›†--->é€‰æ‹©é¡¹ç›®çš„å­˜å‚¨è·¯å¾„--->æ·»åŠ é¡¹ç›®çš„åç§°--->åˆ›å»ºé¡¹ç›®ã€‚

æ–°å»ºé¡¹ç›®ç•Œé¢å¦‚ä¸‹å›¾æ‰€ç¤ºï¼š

![æ–°å»ºé¡¹ç›®](https://www.kendryte.com/api/post/attachment?id=621)

é¡¹ç›®æ–°å»ºå®Œæˆåï¼Œä¼šè‡ªåŠ¨è·³è½¬åˆ°`å›¾åƒé¡µé¢`ï¼Œæ‚¨å¯ä»¥æŸ¥çœ‹æ‚¨çš„æ•°æ®é›†è¯¦æƒ…ã€‚è¿›å…¥`æ‹†åˆ†é¡µé¢`ï¼Œæ‚¨å¯ä»¥æŒ‰ç…§è‡ªå®šä¹‰æ¯”ä¾‹å¯¹æ•°æ®é›†è¿›è¡Œæ‹†åˆ†ï¼Œå¹¶æŸ¥çœ‹æ‹†åˆ†é›†çš„ç»Ÿè®¡ä¿¡æ¯ã€‚

##### å¯åŠ¨è®­ç»ƒ

è¿›å…¥`è®­ç»ƒé¡µé¢`ï¼Œåœ¨å·¦ä¾§é…ç½®**æ¨¡å‹ã€æ•°æ®å¢å¼ºå’Œè®­ç»ƒå‚æ•°**ã€‚

å¸¸è§å‚æ•°è§£æï¼š

| å¹³å°å‚æ•°åç§°     | å¸¸ç”¨å‚æ•°å®šä¹‰            | å‚æ•°å«ä¹‰è§£æ                                                 |
| ---------------- | ----------------------- | ------------------------------------------------------------ |
| æ¨¡å‹             | model                   | ä¸åŒç»“æ„çš„ç½‘ç»œæ¨¡å‹ï¼Œç”¨äºå®ç°ä¸åŒçš„ä»»åŠ¡ï¼›                     |
| Backbone         | model backbone          | æ¨¡å‹ä¸­çš„ç‰¹å¾æå–éƒ¨åˆ†ç½‘ç»œç»“æ„ï¼Œæ¯”å¦‚æ£€æµ‹å’Œåˆ†å‰²ä»»åŠ¡çš„æ¨¡å‹ï¼›     |
| æ˜¯å¦é¢„è®­ç»ƒ       | pretrain                | æ˜¯å¦åŠ è½½AICubeæä¾›çš„é¢„è®­ç»ƒæ¨¡å‹;                             |
| é¢„è®­ç»ƒæ¨¡å‹è¯­è¨€   | pretrain language       | **OCRè¯†åˆ«**çš„ç‰¹å®šä»»åŠ¡å‚æ•°ï¼Œé€‰æ‹©è®­ç»ƒé¢„è®­ç»ƒæ¨¡å‹çš„æ ·æœ¬è¯­è¨€ï¼›å…¶ä»–ä»»åŠ¡å¿½ç•¥ï¼›        |
| æ¨¡å‹å¤§å°         | model size              | nã€sã€mã€lã€xï¼ŒåŒä¸€æ¨¡å‹çš„å˜ä½“ï¼ŒåŒºåˆ«æ˜¯æ¨¡å‹å°ºå¯¸ï¼Œç”¨äºå¹³è¡¡å‡†ç¡®ç‡å’Œé€Ÿç‡ï¼› |
| æ¨¡å‹å®½åº¦         | model width             | å®½åº¦è¶Šå¤§ï¼Œå‚æ•°é‡è¶Šå¤§;                                        |
| å›¾åƒå°ºå¯¸         | model input size        | æ¨¡å‹è¾“å…¥åˆ†è¾¨ç‡ï¼Œå•å€¼è¡¨ç¤ºè¾“å…¥ä¸º[x,x]ï¼ŒåŒå€¼è¡¨ç¤ºè¾“å…¥ä¸º[x,y];    |
| ASPPç©ºæ´ç‡       | ASPP dilation rate      | **è¯­ä¹‰åˆ†å‰²**çš„ç‰¹å®šä»»åŠ¡å‚æ•°ï¼Œä¸åŒç©ºæ´å·ç§¯å’Œæ± åŒ–æ“ä½œçš„å°ºåº¦ï¼Œä¸åŒçš„ç©ºæ´ç‡è¿›è¡Œç©ºæ´å·ç§¯å¯ä»¥æ‰©å¤§æ„Ÿå—é‡ï¼Œè·å¾—æ›´å¹¿é˜”çš„çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼› |
| ç¼–ç é•¿åº¦         | embedding length        | **åº¦é‡å­¦ä¹ **çš„ç‰¹å®šä»»åŠ¡å‚æ•°ï¼Œæ ·æœ¬è¢«å‘é‡åŒ–çš„å‘é‡é•¿åº¦ï¼›             |
| è‡ªåŠ¨æ•°æ®å¢å¼º     | TrivialAugment          | æ— å‚æ•°å•å›¾éšæœºè‡ªåŠ¨æ•°æ®å¢å¼º;                                  |
| å…¶ä»–æ•°æ®å¢å¼ºæ–¹æ³• | â€”                       | äº®åº¦ã€å¯¹æ¯”åº¦ã€é¥±å’Œåº¦ã€è‰²åº¦ã€é”åº¦å¢å¼ºï¼Œç¿»è½¬ï¼Œæ—‹è½¬ï¼Œéšæœºç¼©æ”¾ï¼Œéšæœºè£å‰ªï¼Œé€è§†å˜æ¢ï¼Œé«˜æ–¯æ¨¡ç³Šï¼Œç›´æ–¹å›¾å‡è¡¡åŒ–ï¼Œç°åº¦ä¸–ç•Œç®—æ³•ï¼ŒCutOutï¼ŒRandom Erasingï¼ŒMask; |
| å­¦ä¹ ç‡           | learning rate           | ä¼˜åŒ–ç®—æ³•çš„å‚æ•°ï¼Œæ¯æ¬¡è¿­ä»£çš„è°ƒæ•´æ­¥é•¿ï¼›                         |
| è¿­ä»£è½®æ•°         | epoch                   | ä¸€ä¸ªepochæ˜¯ç¥ç»ç½‘ç»œä½¿ç”¨å…¨éƒ¨è®­ç»ƒæ ·æœ¬è®­ç»ƒä¸€æ¬¡çš„è¿‡ç¨‹ï¼›          |
| è®­ç»ƒæ‰¹å¤§å°       | batchsize               | æ¯æ¬¡å‰å‘å’Œåå‘ä¼ æ’­ä½¿ç”¨çš„æ ·æœ¬æ•°é‡ï¼›                           |
| ä¼˜åŒ–å™¨           | optimizer               | ä¼˜åŒ–ç½‘ç»œçš„æ—¶å€™ä½¿ç”¨çš„ä¼˜åŒ–å‡½æ•°ï¼Œæ¯”å¦‚SGDã€Adamç­‰ï¼›              |
| AutoAnchor       | autoanchor              | ç›®æ ‡æ£€æµ‹ä»»åŠ¡ä¸­çš„é”šæ¡†è‡ªé€‚åº”ï¼›                                 |
| NMSé€‰é¡¹          | nms option              | ç›®æ ‡æ£€æµ‹ä»»åŠ¡ä¸­åŒºåˆ«ç±»å†…å’Œç±»é—´çš„éæå¤§å€¼æŠ‘åˆ¶é€‰é¡¹ï¼›             |
| ç½®ä¿¡åº¦é˜ˆå€¼       | confidience threshold   | ç”¨äºé¢„æµ‹æ¡†ç±»åˆ«çš„è¿‡æ»¤ï¼Œä½äºæ­¤é˜ˆå€¼çš„é¢„æµ‹æ¡†éƒ½å°†è¢«åˆ é™¤ï¼›         |
| äº¤å¹¶æ¯”é˜ˆå€¼       | IOU threshold           | å¯¹å¤šä¸ªé‡å æ¡†è¿›è¡Œæå¤§å€¼ç­›é€‰ï¼Œè®¡ç®—æ‰€æœ‰æ£€æµ‹æ¡†çš„å¾—åˆ†ï¼Œä¾æ¬¡ä¸å¾—åˆ†æœ€é«˜çš„æ£€æµ‹æ¡†å¯¹æ¯”ï¼Œå¤§äºæ­¤é˜ˆå€¼çš„æ£€æµ‹æ¡†è¢«åˆ é™¤ï¼›OCRæ£€æµ‹ä¸­çš„Boxé˜ˆå€¼ç±»ä¼¼ï¼› |
| è‡ªåŠ¨æ··åˆç²¾åº¦     | AMP                     | é’ˆå¯¹ä¸åŒå±‚é‡‡ç”¨ä¸åŒçš„æ•°æ®ç²¾åº¦ï¼Œä»¥èŠ‚çœæ˜¾å­˜å¹¶æé«˜è®¡ç®—é€Ÿåº¦ï¼›     |
| æŒ‡æ•°ç§»åŠ¨å¹³å‡     | EMA                     | å¹³æ»‘æ–¹æ³•ï¼Œé˜²æ­¢å¼‚å¸¸å€¼çš„å½±å“ï¼Œæƒé‡éšæ—¶é—´æŒ‡æ•°é€’å‡ï¼›             |
| æ—©åœ             | Early Stopping          | å¢åŠ æ¨¡å‹æ³›åŒ–æ€§å’Œé˜²æ­¢è¿‡æ‹Ÿåˆçš„æ–¹æ³•ï¼›                           |
| é¢„çƒ­ç­–ç•¥         | WarmUp                  | æ“ä½œè®­ç»ƒåˆå§‹é˜¶æ®µçš„learning rateï¼Œä½¿æ¨¡å‹æ›´å¿«çš„æ”¶æ•›ï¼›          |
| å¤šå°ºåº¦è®­ç»ƒ       | MST                     | å®ç°å¯¹ä¸åŒå°ºåº¦çš„è¾“å…¥å›¾åƒè¿›è¡Œè®­ç»ƒï¼Œæé«˜æ£€æµ‹æ¨¡å‹å¯¹ä¸åŒå¤§å°ç‰©ä½“çš„æ£€æµ‹æ³›åŒ–æ€§ï¼› |
| æŸå¤±å‡½æ•°         | loss function           | ç”¨äºè¯„ä¼°æ¨¡å‹é¢„æµ‹å€¼å’ŒçœŸå®å€¼çš„å·®è·ç¨‹åº¦ï¼ŒæŸå¤±è¶Šå°ï¼Œæ¨¡å‹æ€§èƒ½è¶Šå¥½ï¼› |
| å­¦ä¹ ç‡è°ƒåº¦       | learning rate scheduler | å­¦ä¹ ç‡è°ƒæ•´ç­–ç•¥ï¼Œè®­ç»ƒè¿‡ç¨‹ä¸­åŠ¨æ€çš„è°ƒæ•´å­¦ä¹ ç‡ä»¥é€‚åº”æ¢¯åº¦ä¸‹é™è¿‡ç¨‹ï¼ŒåŒ…æ‹¬StepLRã€CosineAnnealingLRã€LinearLRã€MultiStepLRç­‰ï¼› |
| æŸå¤±åˆ·æ–°æ­¥é•¿     | loss refresh step       | ç•Œé¢Lossæ›²çº¿ç»˜åˆ¶é¢‘ç‡ï¼Œä»¥batchä¸ºå•ä½ï¼›                        |
| GPUç´¢å¼•          | gpu index               | æ˜¾å¡ç´¢å¼•ï¼›                                                 |

æŒ‰ç…§ä¸åŒçš„ä»»åŠ¡é…ç½®å¥½å¯¹åº”å‚æ•°åï¼Œå¯ä»¥ç‚¹å‡»`å¢å¼ºæ ·æœ¬æŒ‰é’®`æŸ¥çœ‹ç»è¿‡æ•°æ®å¢å¼ºçš„éƒ¨åˆ†ç¤ºä¾‹æ ·æœ¬ï¼›ç‚¹å‡»`å­¦ä¹ ç‡æ›²çº¿`å¯ä»¥æŸ¥çœ‹ä¸åŒçš„å­¦ä¹ ç‡ç­–ç•¥å¯¼è‡´çš„å­¦ä¹ ç‡å˜åŒ–ï¼›ç‚¹å‡»`å¼€å§‹è®­ç»ƒæŒ‰é’®`ï¼Œè®­ç»ƒçš„ä¿¡æ¯ä¼šåœ¨å³ä¸Šæ–¹é¢æ¿æ˜¾ç¤ºï¼ŒæŸå¤±æ›²çº¿å’ŒæŒ‡æ ‡æ›²çº¿ä¼šåœ¨ä¸­é—´ä½ç½®ç»˜åˆ¶ï¼›ç¤ºä¾‹æ ·æœ¬çš„é¢„æµ‹ç»“æœä¼šåœ¨å³ä¸‹é¢æ¿è¿­ä»£æ˜¾ç¤ºæ¯ä¸ªepochçš„å˜åŒ–ã€‚è®­ç»ƒæ—¶ç•Œé¢å¦‚ä¸‹å›¾ï¼š

![è®­ç»ƒè¿‡ç¨‹](https://www.kendryte.com/api/post/attachment?id=619)

##### æ¨¡å‹æµ‹è¯•

è¿›å…¥`è¯„ä¼°é¡µé¢`ï¼Œé€‰æ‹©è®­ç»ƒå¥½çš„æ¨¡å‹ï¼Œç„¶åé€‰æ‹©æµ‹è¯•æ–¹å¼ã€‚æµ‹è¯•æ–¹å¼å¦‚ä¸‹ï¼š

| æµ‹è¯•æ–¹å¼     | è¯´æ˜                                                         |
| ------------ | ------------------------------------------------------------ |
| æµ‹è¯•é›†æµ‹è¯•   | å¯¹æ‹†åˆ†å¾—åˆ°çš„æµ‹è¯•é›†è¿›è¡Œæµ‹è¯•è¯„ä¼°ï¼Œè¾“å‡ºæµ‹è¯•æŒ‡æ ‡æ•°æ®ï¼›           |
| é¢å¤–æ•°æ®æµ‹è¯• | ä½¿ç”¨å’Œè®­ç»ƒæ•°æ®é›†ç›¸åŒæ ¼å¼çš„å¸¦æ ‡æ³¨æ•°æ®è¿›è¡Œæµ‹è¯•ï¼Œè¾“å‡ºæµ‹è¯•æŒ‡æ ‡æ•°æ®ï¼› |
| å›¾åƒç›®å½•æµ‹è¯• | åªé€‰æ‹©ä½¿ç”¨è®­ç»ƒçš„æ¨¡å‹å’Œå‚æ•°å¯¹å›¾ç‰‡ç›®å½•ä¸‹çš„æ‰€æœ‰æ— æ ‡æ³¨æ ·æœ¬è¿›è¡Œæ¨ç†ï¼Œæ— æµ‹è¯•æŒ‡æ ‡ï¼› |

ç‚¹å‡»â€œå¼€å§‹æµ‹è¯•â€æŒ‰é’®ï¼Œè¿›è¡Œæµ‹è¯•ï¼Œæµ‹è¯•ç»“æŸåï¼Œæ ¹æ®è¯„ä¼°æŒ‡æ ‡æŸ¥çœ‹æ‚¨çš„æ¨¡å‹æ€§èƒ½ï¼›åŒå‡»æµ‹è¯•æ•°æ®åˆ—è¡¨çš„æ¡ç›®å¯ä»¥æŸ¥çœ‹æ¨ç†ç»“æœå¤§å›¾ã€‚

##### æ¨¡å‹éƒ¨ç½²

å¦‚æœæ¨¡å‹çš„æ€§èƒ½ç¬¦åˆæ‚¨çš„éœ€æ±‚ï¼Œæ‚¨å¯ä»¥åœ¨èŠ¯ç‰‡é€‚é…é¢æ¿é…ç½®éƒ¨ç½²å‚æ•°ï¼Œä¸»è¦æ˜¯æ¨¡å‹çš„è¾“å…¥åˆ†è¾¨ç‡å’Œä¸€äº›åŸºç¡€å‚æ•°ï¼Œç‚¹å‡»`éƒ¨ç½²æŒ‰é’®`ç”Ÿæˆéƒ¨ç½²åŒ…ã€‚

![éƒ¨ç½²åŒ…ç”Ÿæˆ](https://www.kendryte.com/api/post/attachment?id=622)

éƒ¨ç½²äº§ç‰©ç”Ÿæˆåæ‚¨å¯ä»¥åœ¨å½“å‰é¡¹ç›®çš„æ ¹ç›®å½•ä¸‹æ‰¾åˆ°å¦‚ä¸‹æ–‡ä»¶ï¼Œæˆ‘ä»¬ä¸»è¦ä½¿ç”¨`kmodel`å’Œé…ç½®æ–‡ä»¶`deploy_config.json`ï¼š

```shell
ğŸ“¦ task_name
â”œâ”€â”€ ğŸ“ cpp_deployment_source
â”œâ”€â”€ ğŸ“ mp_deployment_source
â””â”€â”€ README.md
```

![é¡¹ç›®æ–‡ä»¶](https://www.kendryte.com/api/post/attachment?id=623)

å…¶ä¸­`mp_deployment_source`ç›®å½•æ˜¯åœ¨K230 MicroPythonæ–¹æ¡ˆä¸Šéƒ¨ç½²çš„èµ„æºï¼ŒåŒ…å«Kmodelæ–‡ä»¶å’Œéƒ¨ç½²é…ç½®æ–‡ä»¶ï¼

#### éƒ¨ç½²æ­¥éª¤

##### éƒ¨ç½²åŒ…è¯´æ˜

è®­ç»ƒç»“æŸåå¯ä»¥å¾—åˆ°å¯¹åº”è®­ç»ƒä»»åŠ¡çš„éƒ¨ç½²äº§ç‰©ã€‚

##### æ–‡ä»¶æ‹·è´

âœ… **å›ºä»¶é€‰æ‹©**ï¼šè¯·åœ¨ `github` æŒ‰ç…§æ‚¨çš„å¼€å‘æ¿ç±»å‹ä¸‹è½½æœ€æ–°çš„ [PreReleaseå›ºä»¶](https://github.com/kendryte/canmv_k230/releases/tag/PreRelease) ä»¥ä¿è¯**æœ€æ–°çš„ç‰¹æ€§**è¢«æ”¯æŒï¼æˆ–è€…ä½¿ç”¨æœ€æ–°çš„ä»£ç è‡ªè¡Œç¼–è¯‘å›ºä»¶ï¼Œæ•™ç¨‹è§ï¼š[å›ºä»¶ç¼–è¯‘](https://www.kendryte.com/k230_canmv/zh/main/zh/userguide/how_to_build.html)ã€‚

âœ… **å›ºä»¶çƒ§å½•**ï¼š æŒ‰ç…§å¼€å‘æ¿ç±»å‹çƒ§å½•å›ºä»¶ï¼Œå›ºä»¶çƒ§å½•å‚è€ƒï¼š[å›ºä»¶çƒ§å½•](https://www.kendryte.com/k230_canmv/zh/main/zh/userguide/how_to_burn_firmware.html)ã€‚

âœ… **éƒ¨ç½²è„šæœ¬**ï¼šå›ºä»¶çƒ§å½•æˆåŠŸåï¼Œä¸Šç”µå¼€æœºï¼Œæ‚¨å¯ä»¥åœ¨æ–‡ä»¶ç³»ç»Ÿæ ¹ç›®å½•ä¸‹å‘ç°`CanMV/sdcard`ç›®å½•ï¼Œå°†`mp_deployment_source`æ‹·è´åˆ°`CanMV/sdcard`ç›®å½•ä¸‹ã€‚

##### è„šæœ¬è¿è¡Œ

æ‰“å¼€CanMV IDE K230ï¼Œé€‰æ‹©å·¦ä¸Šè§’`æ–‡ä»¶(F)`->`æ‰“å¼€æ–‡ä»¶`->`é€‰æ‹©CanMV/sdcard/examples/19-CloudPlatScripts`ä¸­çš„ä¸åŒä»»åŠ¡çš„è„šæœ¬è¿è¡Œã€‚æˆ–è€…é€‰æ‹©éƒ¨ç½²èµ„æºç›®å½•ä¸­çš„éƒ¨ç½²è„šæœ¬è¿è¡Œã€‚

ğŸ’¡ **è„šæœ¬ä»‹ç»**ï¼š

|è„šæœ¬åç§°|è„šæœ¬è¯´æ˜|
|--|--|
|deploy_cls_image.py|å›¾åƒåˆ†ç±»å•å›¾æ¨ç†è„šæœ¬ï¼Œæ‚¨éœ€è¦åœ¨è‡ªè¡Œå¢åŠ æµ‹è¯•å›¾ç‰‡ï¼Œå¹¶ä¿®æ”¹è„šæœ¬å†…è¯»å…¥å›¾ç‰‡çš„è·¯å¾„ã€‚|
|deploy_cls_video.py|å›¾åƒåˆ†ç±»è§†é¢‘æµæ¨ç†è„šæœ¬ï¼Œè„šæœ¬è¯¦æƒ…è§è„šæœ¬å†…æ³¨é‡Šã€‚|
|deploy_det_image.py|ç›®æ ‡æ£€æµ‹å•å›¾æ¨ç†è„šæœ¬ï¼Œæ‚¨éœ€è¦åœ¨è‡ªè¡Œå¢åŠ æµ‹è¯•å›¾ç‰‡ï¼Œå¹¶ä¿®æ”¹è„šæœ¬å†…è¯»å…¥å›¾ç‰‡çš„è·¯å¾„ã€‚|
|deploy_det_video.py|ç›®æ ‡æ£€æµ‹è§†é¢‘æµæ¨ç†è„šæœ¬ï¼Œè„šæœ¬è¯¦æƒ…è§è„šæœ¬å†…æ³¨é‡Šã€‚|
|deploy_seg_image.py|è¯­ä¹‰åˆ†å‰²å•å›¾æ¨ç†è„šæœ¬ï¼Œæ‚¨éœ€è¦åœ¨è‡ªè¡Œå¢åŠ æµ‹è¯•å›¾ç‰‡ï¼Œå¹¶ä¿®æ”¹è„šæœ¬å†…è¯»å…¥å›¾ç‰‡çš„è·¯å¾„ã€‚|
|deploy_seg_video.py|è¯­ä¹‰åˆ†å‰²è§†é¢‘æµæ¨ç†è„šæœ¬ï¼Œè„šæœ¬è¯¦æƒ…è§è„šæœ¬å†…æ³¨é‡Šã€‚|
|deploy_ocrdet_image.py|OCRæ£€æµ‹å•å›¾æ¨ç†è„šæœ¬ï¼Œæ‚¨éœ€è¦åœ¨è‡ªè¡Œå¢åŠ æµ‹è¯•å›¾ç‰‡ï¼Œå¹¶è„šæœ¬ä¿®æ”¹è¯»å…¥å›¾ç‰‡çš„è·¯å¾„ã€‚|
|deploy_ocrdet_video.py|OCRæ£€æµ‹è§†é¢‘æµæ¨ç†è„šæœ¬ï¼Œè„šæœ¬è¯¦æƒ…è§è„šæœ¬å†…æ³¨é‡Šã€‚|
|deploy_ocrrec_image.py|OCRè¯†åˆ«å•å›¾æ¨ç†è„šæœ¬ï¼Œæ‚¨éœ€è¦åœ¨è‡ªè¡Œå¢åŠ æµ‹è¯•å›¾ç‰‡ï¼Œå¹¶è„šæœ¬ä¿®æ”¹è¯»å…¥å›¾ç‰‡çš„è·¯å¾„ã€‚è€ƒè™‘åˆ°å¹³å°OCRè¯†åˆ«æ¨¡å‹å•æ¬¡æ¨ç†è¯»å…¥çš„æ•°æ®ä¸ºé•¿æ¡çŠ¶æ–‡æœ¬ï¼Œå› æ­¤**ä¸æ”¯æŒ**è§†é¢‘æµæ¨ç†ã€‚|
|deploy_ocr_image.py|OCRå•å›¾æ¨ç†è„šæœ¬ï¼Œæ‚¨éœ€è¦åœ¨è‡ªè¡Œå¢åŠ æµ‹è¯•å›¾ç‰‡ï¼Œå¹¶è„šæœ¬ä¿®æ”¹è¯»å…¥å›¾ç‰‡çš„è·¯å¾„ã€‚åŒæ¨¡å‹ä»»åŠ¡ï¼Œéœ€è¦åŒæ—¶æ·»åŠ OCRæ£€æµ‹å’ŒOCRè¯†åˆ«çš„éƒ¨ç½²åŒ…ï¼Œæ³¨æ„ä¿®æ”¹è„šæœ¬å†…ç›®å½•è·¯å¾„ã€‚|
|deploy_ocr_video.py|OCRè§†é¢‘æµæ¨ç†è„šæœ¬ï¼Œè„šæœ¬è¯¦æƒ…è§è„šæœ¬å†…æ³¨é‡Šã€‚åŒæ¨¡å‹ä»»åŠ¡ï¼Œéœ€è¦åŒæ—¶æ·»åŠ OCRæ£€æµ‹å’ŒOCRè¯†åˆ«çš„éƒ¨ç½²åŒ…ï¼Œæ³¨æ„ä¿®æ”¹è„šæœ¬å†…ç›®å½•è·¯å¾„ã€‚|
|deploy_ml_image.py|åº¦é‡å­¦ä¹ å•å›¾æ¨ç†è„šæœ¬ï¼Œæ‚¨éœ€è¦åœ¨è‡ªè¡Œå¢åŠ æµ‹è¯•å›¾ç‰‡ï¼Œå¹¶è„šæœ¬ä¿®æ”¹è¯»å…¥å›¾ç‰‡çš„è·¯å¾„ã€‚è¾“å‡ºä¸ºå¯¹åº”ç»´åº¦çš„ç‰¹å¾ï¼Œåç»­æ“ä½œè§†åº”ç”¨åœºæ™¯ä¿®æ”¹ã€‚|
|deploy_ml_video.py|åº¦é‡å­¦ä¹ è§†é¢‘æµæ¨ç†è„šæœ¬ï¼Œè„šæœ¬è¯¦æƒ…è§è„šæœ¬å†…æ³¨é‡Šã€‚è¾“å‡ºä¸ºå¯¹åº”ç»´åº¦çš„ç‰¹å¾ï¼Œåç»­æ“ä½œè§†åº”ç”¨åœºæ™¯ä¿®æ”¹ã€‚|
|deploy_multl_image.py|å¤šæ ‡ç­¾åˆ†ç±»å•å›¾æ¨ç†è„šæœ¬ï¼Œæ‚¨éœ€è¦åœ¨è‡ªè¡Œå¢åŠ æµ‹è¯•å›¾ç‰‡ï¼Œå¹¶è„šæœ¬ä¿®æ”¹è¯»å…¥å›¾ç‰‡çš„è·¯å¾„ã€‚|
|deploy_multl_video.py|å¤šæ ‡ç­¾åˆ†ç±»è§†é¢‘æµæ¨ç†è„šæœ¬ï¼Œè„šæœ¬è¯¦æƒ…è§è„šæœ¬å†…æ³¨é‡Šã€‚|

##### éƒ¨ç½²è¯´æ˜

- ğŸ“¢ åœ¨éƒ¨ç½²æ¨¡å‹æ—¶å¦‚æœæ•ˆæœä¸ç†æƒ³ï¼Œé¦–å…ˆè°ƒæ•´å¯¹åº”ä»»åŠ¡çš„é˜ˆå€¼å’Œæ¨ç†å›¾åƒçš„åˆ†è¾¨ç‡ï¼Œæµ‹è¯•ç»“æœæ˜¯å¦å¯ä»¥æœ‰å¥½è½¬ï¼

- ğŸ“¢ å­¦ä¼šå®šä½é—®é¢˜ï¼Œæ¯”å¦‚æŸ¥çœ‹AICubeæ¨¡å‹è¯„ä¼°çš„ç»“æœï¼Œå¦‚æœè¯¥å›¾ç‰‡æ­£å¸¸ï¼Œåˆ™å¯èƒ½æ˜¯éƒ¨ç½²ä»£ç ã€æ¨¡å‹è½¬æ¢æˆ–è€…é˜ˆå€¼çš„é—®é¢˜ï¼Œæ‚¨å¯ä»¥é€‰æ‹©è°ƒæ•´é‡åŒ–æ–¹å¼æˆ–è€…è°ƒæ•´éƒ¨ç½²å‚æ•°è¿›è¡Œä¼˜åŒ–ï¼

- ğŸ“¢ AICubeå­˜åœ¨å¤§é‡çš„è®­ç»ƒå‚æ•°ï¼Œå¯¹æ·±åº¦å­¦ä¹ äº†è§£çš„ç”¨æˆ·å¯ä»¥æ ¹æ®å¯èƒ½çš„ä¼˜åŒ–æ–¹å‘è°ƒæ•´è®­ç»ƒå‚æ•°ï¼Œè°ƒæ•´æ¨¡å‹è®­ç»ƒçš„å‚æ•°å®ç°é‡æ–°è®­ç»ƒè½¬æ¢ï¼

## è¿›é˜¶å¼€å‘

è¿™é‡Œé’ˆå¯¹ä¸åŒçš„åœºæ™¯ç»™å‡ºä¸€äº›å¤æ‚ç¤ºä¾‹ï¼Œä»¥AI+å…¶ä»–æ¨¡å—ä¸ºåŸºç¡€ï¼Œå®ç°è¿›é˜¶å¼€å‘ã€‚

### AIå¤šçº¿ç¨‹æ¨ç†

ä½¿ç”¨å¤šçº¿ç¨‹å®ç°å¤šä¸ªAIæ¨¡å‹åŒæ—¶æ¨ç†ï¼Œæ³¨æ„KPUäº’æ–¥å ç”¨ã€‚è¿™é‡Œä»¥YOLOv8æ£€æµ‹å’Œäººè„¸æ£€æµ‹ä¸ºä¾‹ï¼Œç»™å‡ºå¦‚ä½•ä½¿ç”¨å¤šçº¿ç¨‹å®ç°åŒæ—¶æ¨ç†ã€‚ç¤ºä¾‹ä»£ç å¦‚ä¸‹ï¼š

```python
from libs.PipeLine import PipeLine
from libs.AIBase import AIBase
from libs.AI2D import Ai2d
from libs.Utils import *
import nncase_runtime as nn
import ulab.numpy as np
import aidemo
from media.display import *
from media.media import *
from media.sensor import *
import time, os, sys, gc
import lvgl as lv
from machine import TOUCH
from machine import RTC
import _thread

DISPLAY_WIDTH = ALIGN_UP(800, 16)
DISPLAY_HEIGHT = 480

sensor = None
rgb888p_size=[1280,720]
display_size = [800, 480]
face_det_stop=False
yolo_det_stop=False
face_osd_img=None
yolo_osd_img=None
lock = _thread.allocate_lock()

# è‡ªå®šä¹‰YOLOv8æ£€æµ‹ç±»
class ObjectDetectionApp(AIBase):
    def __init__(self,kmodel_path,labels,model_input_size,max_boxes_num,confidence_threshold=0.5,nms_threshold=0.2,rgb888p_size=[224,224],display_size=[1920,1080],debug_mode=0):
        super().__init__(kmodel_path,model_input_size,rgb888p_size,debug_mode)
        self.kmodel_path=kmodel_path
        self.labels=labels
        self.model_input_size=model_input_size
        self.confidence_threshold=confidence_threshold
        self.nms_threshold=nms_threshold
        self.max_boxes_num=max_boxes_num
        self.rgb888p_size=[ALIGN_UP(rgb888p_size[0],16),rgb888p_size[1]]
        self.display_size=[ALIGN_UP(display_size[0],16),display_size[1]]
        self.debug_mode=debug_mode
        self.color_four=get_colors(len(self.labels))
        self.x_factor = float(self.rgb888p_size[0])/self.model_input_size[0]
        self.y_factor = float(self.rgb888p_size[1])/self.model_input_size[1]
        self.ai2d=Ai2d(debug_mode)
        self.ai2d.set_ai2d_dtype(nn.ai2d_format.NCHW_FMT,nn.ai2d_format.NCHW_FMT,np.uint8, np.uint8)

    # é…ç½®é¢„å¤„ç†æ“ä½œï¼Œè¿™é‡Œä½¿ç”¨äº†resizeï¼ŒAi2dæ”¯æŒcrop/shift/pad/resize/affineï¼Œå…·ä½“ä»£ç è¯·æ‰“å¼€/sdcard/app/libs/AI2D.pyæŸ¥çœ‹
    def config_preprocess(self,input_image_size=None):
        with ScopedTiming("set preprocess config",self.debug_mode > 0):
            ai2d_input_size=input_image_size if input_image_size else self.rgb888p_size
            top,bottom,left,right,self.scale=letterbox_pad_param(self.rgb888p_size,self.model_input_size)
            self.ai2d.pad([0,0,0,0,top,bottom,left,right], 0, [128,128,128])
            self.ai2d.resize(nn.interp_method.tf_bilinear, nn.interp_mode.half_pixel)
            self.ai2d.build([1,3,ai2d_input_size[1],ai2d_input_size[0]],[1,3,self.model_input_size[1],self.model_input_size[0]])

    def postprocess(self,results):
        with ScopedTiming("postprocess",self.debug_mode > 0):
            new_result=results[0][0].transpose()
            det_res = aidemo.yolov8_det_postprocess(new_result.copy(),[self.rgb888p_size[1],self.rgb888p_size[0]],[self.model_input_size[1],self.model_input_size[0]],[self.display_size[1],self.display_size[0]],len(self.labels),self.confidence_threshold,self.nms_threshold,self.max_boxes_num)
            return det_res

    def draw_result(self,osd_img,dets):
        with ScopedTiming("display_draw",self.debug_mode >0):
            osd_img.clear()
            if dets:
                for i in range(len(dets[0])):
                    x, y, w, h = map(lambda x: int(round(x, 0)), dets[0][i])
                    osd_img.draw_rectangle(x,y, w, h, color=self.color_four[dets[1][i]],thickness=4)
                    osd_img.draw_string_advanced(x, y-50,32," " + self.labels[dets[1][i]] + " " + str(round(dets[2][i],2)) , color=self.color_four[dets[1][i]])


# è‡ªå®šä¹‰äººè„¸æ£€æµ‹ç±»ï¼Œç»§æ‰¿è‡ªAIBaseåŸºç±»
class FaceDetectionApp(AIBase):
    def __init__(self, kmodel_path, model_input_size, anchors, confidence_threshold=0.5, nms_threshold=0.2, rgb888p_size=[224,224], display_size=[1920,1080], debug_mode=0):
        super().__init__(kmodel_path, model_input_size, rgb888p_size, debug_mode)  # è°ƒç”¨åŸºç±»çš„æ„é€ å‡½æ•°
        self.kmodel_path = kmodel_path  # æ¨¡å‹æ–‡ä»¶è·¯å¾„
        self.model_input_size = model_input_size  # æ¨¡å‹è¾“å…¥åˆ†è¾¨ç‡
        self.confidence_threshold = confidence_threshold  # ç½®ä¿¡åº¦é˜ˆå€¼
        self.nms_threshold = nms_threshold  # NMSï¼ˆéæå¤§å€¼æŠ‘åˆ¶ï¼‰é˜ˆå€¼
        self.anchors = anchors  # é”šç‚¹æ•°æ®ï¼Œç”¨äºç›®æ ‡æ£€æµ‹
        self.rgb888p_size = [ALIGN_UP(rgb888p_size[0], 16), rgb888p_size[1]]  # sensorç»™åˆ°AIçš„å›¾åƒåˆ†è¾¨ç‡ï¼Œå¹¶å¯¹å®½åº¦è¿›è¡Œ16çš„å¯¹é½
        self.display_size = [ALIGN_UP(display_size[0], 16), display_size[1]]  # æ˜¾ç¤ºåˆ†è¾¨ç‡ï¼Œå¹¶å¯¹å®½åº¦è¿›è¡Œ16çš„å¯¹é½
        self.debug_mode = debug_mode  # æ˜¯å¦å¼€å¯è°ƒè¯•æ¨¡å¼
        self.ai2d = Ai2d(debug_mode)  # å®ä¾‹åŒ–Ai2dï¼Œç”¨äºå®ç°æ¨¡å‹é¢„å¤„ç†
        self.ai2d.set_ai2d_dtype(nn.ai2d_format.NCHW_FMT, nn.ai2d_format.NCHW_FMT, np.uint8, np.uint8)  # è®¾ç½®Ai2dçš„è¾“å…¥è¾“å‡ºæ ¼å¼å’Œç±»å‹

    # é…ç½®é¢„å¤„ç†æ“ä½œï¼Œè¿™é‡Œä½¿ç”¨äº†padå’Œresizeï¼ŒAi2dæ”¯æŒcrop/shift/pad/resize/affineï¼Œå…·ä½“ä»£ç è¯·æ‰“å¼€/sdcard/app/libs/AI2D.pyæŸ¥çœ‹
    def config_preprocess(self, input_image_size=None):
        with ScopedTiming("set preprocess config", self.debug_mode > 0):  # è®¡æ—¶å™¨ï¼Œå¦‚æœdebug_modeå¤§äº0åˆ™å¼€å¯
            ai2d_input_size = input_image_size if input_image_size else self.rgb888p_size  # åˆå§‹åŒ–ai2dé¢„å¤„ç†é…ç½®ï¼Œé»˜è®¤ä¸ºsensorç»™åˆ°AIçš„å°ºå¯¸ï¼Œå¯ä»¥é€šè¿‡è®¾ç½®input_image_sizeè‡ªè¡Œä¿®æ”¹è¾“å…¥å°ºå¯¸
            top, bottom, left, right,_ = letterbox_pad_param(self.rgb888p_size,self.model_input_size)
            self.ai2d.pad([0, 0, 0, 0, top, bottom, left, right], 0, [104, 117, 123])  # å¡«å……è¾¹ç¼˜
            self.ai2d.resize(nn.interp_method.tf_bilinear, nn.interp_mode.half_pixel)  # ç¼©æ”¾å›¾åƒ
            self.ai2d.build([1,3,ai2d_input_size[1],ai2d_input_size[0]],[1,3,self.model_input_size[1],self.model_input_size[0]])  # æ„å»ºé¢„å¤„ç†æµç¨‹

    # è‡ªå®šä¹‰å½“å‰ä»»åŠ¡çš„åå¤„ç†ï¼Œresultsæ˜¯æ¨¡å‹è¾“å‡ºarrayåˆ—è¡¨ï¼Œè¿™é‡Œä½¿ç”¨äº†aidemoåº“çš„face_det_post_processæ¥å£
    def postprocess(self, results):
        with ScopedTiming("postprocess", self.debug_mode > 0):
            post_ret = aidemo.face_det_post_process(self.confidence_threshold, self.nms_threshold, self.model_input_size[1], self.anchors, self.rgb888p_size, results)
            if len(post_ret) == 0:
                return post_ret
            else:
                return post_ret[0]

    # ç»˜åˆ¶æ£€æµ‹ç»“æœåˆ°ç”»é¢ä¸Š
    def draw_result(self, osd_img, dets):
        with ScopedTiming("display_draw", self.debug_mode > 0):
            osd_img.clear()
            if dets:
                for det in dets:
                    # å°†æ£€æµ‹æ¡†çš„åæ ‡è½¬æ¢ä¸ºæ˜¾ç¤ºåˆ†è¾¨ç‡ä¸‹çš„åæ ‡
                    x, y, w, h = map(lambda x: int(round(x, 0)), det[:4])
                    x = x * self.display_size[0] // self.rgb888p_size[0]
                    y = y * self.display_size[1] // self.rgb888p_size[1]
                    w = w * self.display_size[0] // self.rgb888p_size[0]
                    h = h * self.display_size[1] // self.rgb888p_size[1]
                    osd_img.draw_rectangle(x, y, w, h, color=(255, 255, 0, 255), thickness=2)


def face_det_thread():
    global sensor,osd_img,rgb888p_size,display_size,face_osd_img
    # è®¾ç½®æ¨¡å‹è·¯å¾„å’Œå…¶ä»–å‚æ•°
    kmodel_path = "/sdcard/examples/kmodel/face_detection_320.kmodel"
    # å…¶å®ƒå‚æ•°
    confidence_threshold = 0.5
    nms_threshold = 0.2
    anchor_len = 4200
    det_dim = 4
    anchors_path = "/sdcard/examples/utils/prior_data_320.bin"
    anchors = np.fromfile(anchors_path, dtype=np.float)
    anchors = anchors.reshape((anchor_len, det_dim))
    face_det = FaceDetectionApp(kmodel_path, model_input_size=[320, 320], anchors=anchors, confidence_threshold=confidence_threshold, nms_threshold=nms_threshold, rgb888p_size=rgb888p_size, display_size=display_size, debug_mode=0)
    face_det.config_preprocess()  # é…ç½®é¢„å¤„ç†
    while True:
        if face_det_stop:
            break
        img_2 = sensor.snapshot(chn = CAM_CHN_ID_2)
        img_np =img_2.to_numpy_ref()
        with lock:
            res = face_det.run(img_np)         # æ¨ç†å½“å‰å¸§
        face_det.draw_result(face_osd_img, res)   # ç»˜åˆ¶ç»“æœ
        Display.show_image(face_osd_img, 0, 0, Display.LAYER_OSD2)
        gc.collect()
    face_det.deinit()


def yolov8_det_thread():
    global sensor,osd_img,rgb888p_size,display_size,yolo_osd_img
    kmodel_path="/sdcard/examples/kmodel/yolov8n_224.kmodel"
    labels = ["person", "bicycle", "car", "motorcycle", "airplane", "bus", "train", "truck", "boat", "traffic light", "fire hydrant", "stop sign", "parking meter", "bench", "bird", "cat", "dog", "horse", "sheep", "cow", "elephant", "bear", "zebra", "giraffe", "backpack", "umbrella", "handbag", "tie", "suitcase", "frisbee", "skis", "snowboard", "sports ball", "kite", "baseball bat", "baseball glove", "skateboard", "surfboard", "tennis racket", "bottle", "wine glass", "cup", "fork", "knife", "spoon", "bowl", "banana", "apple", "sandwich", "orange", "broccoli", "carrot", "hot dog", "pizza", "donut", "cake", "chair", "couch", "potted plant", "bed", "dining table", "toilet", "tv", "laptop", "mouse", "remote", "keyboard", "cell phone", "microwave", "oven", "toaster", "sink", "refrigerator", "book", "clock", "vase", "scissors", "teddy bear", "hair drier", "toothbrush"]
    confidence_threshold = 0.3
    nms_threshold = 0.4
    ob_det=ObjectDetectionApp(kmodel_path,labels=labels,model_input_size=[224,224],max_boxes_num=50,confidence_threshold=confidence_threshold,nms_threshold=nms_threshold,rgb888p_size=rgb888p_size,display_size=display_size,debug_mode=0)
    ob_det.config_preprocess()
    while True:
        if yolo_det_stop:
            break
        img_2 = sensor.snapshot(chn = CAM_CHN_ID_2)
        img_np =img_2.to_numpy_ref()
        with lock:
            det_res = ob_det.run(img_np)
        ob_det.draw_result(yolo_osd_img, det_res)
        Display.show_image(yolo_osd_img, 0, 0, Display.LAYER_OSD1)
        gc.collect()
    ob_det.deinit()


def media_init():
    global sensor,osd_img,rgb888p_size,display_size,face_osd_img,yolo_osd_img
    Display.init(Display.ST7701, width = DISPLAY_WIDTH, height = DISPLAY_HEIGHT, to_ide = True, osd_num=3)
    sensor = Sensor(fps=30)
    sensor.reset()
    sensor.set_framesize(w = 800, h = 480,chn=CAM_CHN_ID_0)
    sensor.set_pixformat(Sensor.YUV420SP)
    sensor.set_framesize(w = rgb888p_size[0], h = rgb888p_size[1], chn=CAM_CHN_ID_2)
    sensor.set_pixformat(Sensor.RGBP888, chn=CAM_CHN_ID_2)

    sensor_bind_info = sensor.bind_info(x = 0, y = 0, chn = CAM_CHN_ID_0)
    Display.bind_layer(**sensor_bind_info, layer = Display.LAYER_VIDEO1)
    face_osd_img = image.Image(display_size[0], display_size[1], image.ARGB8888)
    yolo_osd_img = image.Image(display_size[0], display_size[1], image.ARGB8888)
    MediaManager.init()
    sensor.run()

def media_deinit():
    global sensor
    os.exitpoint(os.EXITPOINT_ENABLE_SLEEP)
    sensor.stop()
    Display.deinit()
    time.sleep_ms(50)
    MediaManager.deinit()

if __name__ == "__main__":
    media_init()
    _thread.start_new_thread(yolov8_det_thread,())
    _thread.start_new_thread(face_det_thread,())
    try:
        while True:
            time.sleep_ms(50)
    except BaseException as e:
        import sys
        sys.print_exception(e)
        yolo_det_stop=True
        face_det_stop=True
    media_deinit()
    gc.collect()
```

### AI+UARTé€šä¿¡

AIæ¨ç†ç»“æŸåï¼Œå¦‚ä½•å°†è¯†åˆ«åˆ°çš„å†…å®¹é€šè¿‡ä¸²å£å‘é€åˆ°ä¸Šä½æœºï¼Œè¿™é‡Œä»¥YOLOv8æ£€æµ‹ä½œä¸ºAIéƒ¨åˆ†ä¸ºä¾‹ï¼Œç»™å‡ºå¦‚ä½•ä½¿ç”¨UARTé€šä¿¡å®ç°AI+UARTé€šä¿¡ã€‚ç¤ºä¾‹ä»£ç å¦‚ä¸‹ï¼š

```python
from libs.PipeLine import PipeLine
from libs.AIBase import AIBase
from libs.AI2D import Ai2d
from libs.Utils import *
import os, sys, ujson, gc, math
from media.media import *
import nncase_runtime as nn
import ulab.numpy as np
import image
import aidemo
from machine import UART
from machine import FPIOA
import time

# Custom YOLOv8 object detection class
class ObjectDetectionApp(AIBase):
    def __init__(self, kmodel_path, labels, model_input_size, max_boxes_num, confidence_threshold=0.5, nms_threshold=0.2, rgb888p_size=[224,224], display_size=[1920,1080], debug_mode=0):
        """
        Initialize object detection system.

        Parameters:
        - kmodel_path: Path to YOLOv8 KModel.
        - labels: List of class labels.
        - model_input_size: Model input resolution.
        - max_boxes_num: Max detection results to keep.
        - confidence_threshold: Detection score threshold.
        - nms_threshold: Non-max suppression threshold.
        - rgb888p_size: Camera input size (aligned to 16-width).
        - display_size: Output display size.
        - debug_mode: Enable debug timing logs.
        """
        super().__init__(kmodel_path, model_input_size, rgb888p_size, debug_mode)
        self.kmodel_path = kmodel_path
        self.labels = labels
        self.model_input_size = model_input_size
        self.confidence_threshold = confidence_threshold
        self.nms_threshold = nms_threshold
        self.max_boxes_num = max_boxes_num

        # Align width to multiple of 16 for hardware compatibility
        self.rgb888p_size = [ALIGN_UP(rgb888p_size[0], 16), rgb888p_size[1]]
        self.display_size = [ALIGN_UP(display_size[0], 16), display_size[1]]
        self.debug_mode = debug_mode

        # Predefined colors for each class
        self.color_four = get_colors(len(self.labels))

        # Input scaling factors
        self.x_factor = float(self.rgb888p_size[0]) / self.model_input_size[0]
        self.y_factor = float(self.rgb888p_size[1]) / self.model_input_size[1]

        # Ai2d instance for preprocessing
        self.ai2d = Ai2d(debug_mode)
        self.ai2d.set_ai2d_dtype(nn.ai2d_format.NCHW_FMT, nn.ai2d_format.NCHW_FMT, np.uint8, np.uint8)

        # Configure UART pins using FPIOA
        self.fpioa = FPIOA()
        self.fpioa.set_function(3, self.fpioa.UART1_TXD, ie=1, oe=1)
        self.fpioa.set_function(4, self.fpioa.UART1_RXD, ie=1, oe=1)

        # Initialize UART1
        self.uart = UART(UART.UART1, baudrate=115200, bits=UART.EIGHTBITS, parity=UART.PARITY_NONE, stop=UART.STOPBITS_ONE)

    def config_preprocess(self, input_image_size=None):
        """
        Configure pre-processing: padding and resizing using Ai2d.
        """
        with ScopedTiming("set preprocess config", self.debug_mode > 0):
            ai2d_input_size = input_image_size if input_image_size else self.rgb888p_size
            top, bottom, left, right, self.scale = letterbox_pad_param(self.rgb888p_size, self.model_input_size)
            self.ai2d.pad([0,0,0,0,top,bottom,left,right], 0, [128,128,128])
            self.ai2d.resize(nn.interp_method.tf_bilinear, nn.interp_mode.half_pixel)
            self.ai2d.build(
                [1, 3, ai2d_input_size[1], ai2d_input_size[0]],
                [1, 3, self.model_input_size[1], self.model_input_size[0]]
            )

    def preprocess(self, input_np):
        """
        Prepare numpy image for inference.
        """
        with ScopedTiming("preprocess", self.debug_mode > 0):
            return [nn.from_numpy(input_np)]

    def postprocess(self, results):
        """
        Apply YOLOv8 post-processing including NMS and thresholding.
        """
        with ScopedTiming("postprocess", self.debug_mode > 0):
            new_result = results[0][0].transpose()
            det_res = aidemo.yolov8_det_postprocess(
                new_result.copy(),
                [self.rgb888p_size[1], self.rgb888p_size[0]],
                [self.model_input_size[1], self.model_input_size[0]],
                [self.display_size[1], self.display_size[0]],
                len(self.labels),
                self.confidence_threshold,
                self.nms_threshold,
                self.max_boxes_num
            )
            return det_res

    def draw_result(self, pl, dets):
        """
        Draw detection results and send label info via UART.
        """
        with ScopedTiming("display_draw", self.debug_mode > 0):
            if dets:
                pl.osd_img.clear()
                for i in range(len(dets[0])):
                    x, y, w, h = map(lambda x: int(round(x, 0)), dets[0][i])
                    pl.osd_img.draw_rectangle(x, y, w, h, color=self.color_four[dets[1][i]], thickness=4)
                    pl.osd_img.draw_string_advanced(
                        x, y - 50, 32,
                        " " + self.labels[dets[1][i]] + " " + str(round(dets[2][i], 2)),
                        color=self.color_four[dets[1][i]]
                    )
                    # Send detected label over UART
                    uart_write_res = self.labels[dets[1][i]] + " "
                    self.uart.write(uart_write_res.encode("utf-8"))
            else:
                pl.osd_img.clear()

if __name__ == "__main__":
    # Choose display mode: lcd / hdmi / lt9611 / st7701 / hx8399
    display_mode = "lcd"
    rgb888p_size = [224, 224]
    kmodel_path = "/sdcard/examples/kmodel/yolov8n_224.kmodel"

    # Class labels for COCO dataset
    labels = ["person", "bicycle", "car", "motorcycle", "airplane", "bus", "train", "truck", "boat",
              "traffic light", "fire hydrant", "stop sign", "parking meter", "bench", "bird", "cat",
              "dog", "horse", "sheep", "cow", "elephant", "bear", "zebra", "giraffe", "backpack",
              "umbrella", "handbag", "tie", "suitcase", "frisbee", "skis", "snowboard", "sports ball",
              "kite", "baseball bat", "baseball glove", "skateboard", "surfboard", "tennis racket",
              "bottle", "wine glass", "cup", "fork", "knife", "spoon", "bowl", "banana", "apple",
              "sandwich", "orange", "broccoli", "carrot", "hot dog", "pizza", "donut", "cake", "chair",
              "couch", "potted plant", "bed", "dining table", "toilet", "tv", "laptop", "mouse", "remote",
              "keyboard", "cell phone", "microwave", "oven", "toaster", "sink", "refrigerator", "book",
              "clock", "vase", "scissors", "teddy bear", "hair drier", "toothbrush"]

    confidence_threshold = 0.3
    nms_threshold = 0.4
    max_boxes_num = 30

    # Initialize video pipeline
    pl = PipeLine(rgb888p_size=rgb888p_size, display_mode=display_mode)
    pl.create()
    display_size = pl.get_display_size()

    # Initialize detection app
    ob_det = ObjectDetectionApp(
        kmodel_path,
        labels=labels,
        model_input_size=[224, 224],
        max_boxes_num=max_boxes_num,
        confidence_threshold=confidence_threshold,
        nms_threshold=nms_threshold,
        rgb888p_size=rgb888p_size,
        display_size=display_size,
        debug_mode=0
    )
    ob_det.config_preprocess()

    # Real-time processing loop
    while True:
        with ScopedTiming("total", 1):
            img = pl.get_frame()                         # Capture frame
            res = ob_det.run(img)                        # Run inference
            ob_det.draw_result(pl, res)                  # Draw results
            pl.show_image()                              # Display results
            gc.collect()                                 # Free memory

    ob_det.deinit()
    pl.destroy()
```

### AIå¤šæ‘„æ¨ç†

å¤šæ‘„åƒå¤´AIæ¨ç†æ˜¯æŒ‡åŒæ—¶ä½¿ç”¨å¤šä¸ªæ‘„åƒå¤´è¿›è¡ŒAIæ¨ç†ï¼Œè¿™é‡Œä»¥ä½¿ç”¨ä¸¤ä¸ªæ‘„åƒå¤´è¿›è¡ŒYOLOv8æ£€æµ‹å’Œäººè„¸æ£€æµ‹ä¸ºä¾‹ï¼Œç»™å‡ºå¦‚ä½•ä½¿ç”¨åŒæ‘„å¤šçº¿ç¨‹å®ç°AIæ¨ç†ã€‚ç¤ºä¾‹ä»£ç å¦‚ä¸‹ï¼š

```python
import os,sys
from media.sensor import *
from media.display import *
from media.media import *
import nncase_runtime as nn
import ulab.numpy as np
import time,image,random,gc
from libs.AIBase import AIBase
from libs.AI2D import Ai2d
from libs.Utils import *
import aidemo
import _thread

# ä¸€äº›åˆå§‹åŒ–è®¾ç½®
DISPLAY_WIDTH=ALIGN_UP(1920, 16)
DISPLAY_HEIGHT=1080
display_size=[DISPLAY_WIDTH//2,DISPLAY_HEIGHT//2]
sensor1 = None
sensor2 = None
yolo_rgb888p_size=[224,224]
face_rgb888p_size=[640,360]
face_det_run=True
yolo_det_run=True
face_osd_img=None
yolo_osd_img=None
lock = _thread.allocate_lock()

# è‡ªå®šä¹‰YOLOv8æ£€æµ‹ç±»
class ObjectDetectionApp(AIBase):
    def __init__(self,kmodel_path,labels,model_input_size,max_boxes_num,confidence_threshold=0.5,nms_threshold=0.2,rgb888p_size=[224,224],display_size=[1920,1080],debug_mode=0):
        super().__init__(kmodel_path,model_input_size,rgb888p_size,debug_mode)
        self.kmodel_path=kmodel_path
        self.labels=labels
        # æ¨¡å‹è¾“å…¥åˆ†è¾¨ç‡
        self.model_input_size=model_input_size
        # é˜ˆå€¼è®¾ç½®
        self.confidence_threshold=confidence_threshold
        self.nms_threshold=nms_threshold
        self.max_boxes_num=max_boxes_num
        # sensorç»™åˆ°AIçš„å›¾åƒåˆ†è¾¨ç‡
        self.rgb888p_size=[ALIGN_UP(rgb888p_size[0],16),rgb888p_size[1]]
        # æ˜¾ç¤ºåˆ†è¾¨ç‡
        self.display_size=[ALIGN_UP(display_size[0],16),display_size[1]]
        self.debug_mode=debug_mode
        # æ£€æµ‹æ¡†é¢„ç½®é¢œè‰²å€¼
        self.color_four=get_colors(len(self.labels))
        # å®½é«˜ç¼©æ”¾æ¯”ä¾‹
        self.x_factor = float(self.rgb888p_size[0])/self.model_input_size[0]
        self.y_factor = float(self.rgb888p_size[1])/self.model_input_size[1]
        # Ai2då®ä¾‹ï¼Œç”¨äºå®ç°æ¨¡å‹é¢„å¤„ç†
        self.ai2d=Ai2d(debug_mode)
        # è®¾ç½®Ai2dçš„è¾“å…¥è¾“å‡ºæ ¼å¼å’Œç±»å‹
        self.ai2d.set_ai2d_dtype(nn.ai2d_format.NCHW_FMT,nn.ai2d_format.NCHW_FMT,np.uint8, np.uint8)

    # é…ç½®é¢„å¤„ç†æ“ä½œï¼Œè¿™é‡Œä½¿ç”¨äº†resizeï¼ŒAi2dæ”¯æŒcrop/shift/pad/resize/affineï¼Œå…·ä½“ä»£ç è¯·æ‰“å¼€/sdcard/app/libs/AI2D.pyæŸ¥çœ‹
    def config_preprocess(self,input_image_size=None):
        with ScopedTiming("set preprocess config",self.debug_mode > 0):
            # åˆå§‹åŒ–ai2dé¢„å¤„ç†é…ç½®ï¼Œé»˜è®¤ä¸ºsensorç»™åˆ°AIçš„å°ºå¯¸ï¼Œæ‚¨å¯ä»¥é€šè¿‡è®¾ç½®input_image_sizeè‡ªè¡Œä¿®æ”¹è¾“å…¥å°ºå¯¸
            ai2d_input_size=input_image_size if input_image_size else self.rgb888p_size
            top,bottom,left,right,self.scale=letterbox_pad_param(self.rgb888p_size,self.model_input_size)
            # é…ç½®paddingé¢„å¤„ç†
            self.ai2d.pad([0,0,0,0,top,bottom,left,right], 0, [128,128,128])
            self.ai2d.resize(nn.interp_method.tf_bilinear, nn.interp_mode.half_pixel)
            self.ai2d.build([1,3,ai2d_input_size[1],ai2d_input_size[0]],[1,3,self.model_input_size[1],self.model_input_size[0]])

    def preprocess(self,input_np):
        with ScopedTiming("preprocess",self.debug_mode > 0):
            return [nn.from_numpy(input_np)]

    # è‡ªå®šä¹‰å½“å‰ä»»åŠ¡çš„åå¤„ç†
    def postprocess(self,results):
        with ScopedTiming("postprocess",self.debug_mode > 0):
            new_result=results[0][0].transpose()
            det_res = aidemo.yolov8_det_postprocess(new_result.copy(),[self.rgb888p_size[1],self.rgb888p_size[0]],[self.model_input_size[1],self.model_input_size[0]],[self.display_size[1],self.display_size[0]],len(self.labels),self.confidence_threshold,self.nms_threshold,self.max_boxes_num)
            return det_res
    # èµ„æºé‡Šæ”¾
    def deinit(self):
         del self.kpu
         del self.ai2d
         self.tensors.clear()
         del self.tensors
         gc.collect()
         time.sleep_ms(50)


 # è‡ªå®šä¹‰äººè„¸æ£€æµ‹ç±»ï¼Œç»§æ‰¿è‡ªAIBaseåŸºç±»
class FaceDetectionApp(AIBase):
    def __init__(self, kmodel_path, model_input_size, anchors, confidence_threshold=0.5, nms_threshold=0.2, rgb888p_size=[224,224], display_size=[1920,1080], debug_mode=0):
         super().__init__(kmodel_path, model_input_size, rgb888p_size, debug_mode)  # è°ƒç”¨åŸºç±»çš„æ„é€ å‡½æ•°
         self.kmodel_path = kmodel_path  # æ¨¡å‹æ–‡ä»¶è·¯å¾„
         self.model_input_size = model_input_size  # æ¨¡å‹è¾“å…¥åˆ†è¾¨ç‡
         self.confidence_threshold = confidence_threshold  # ç½®ä¿¡åº¦é˜ˆå€¼
         self.nms_threshold = nms_threshold  # NMSï¼ˆéæå¤§å€¼æŠ‘åˆ¶ï¼‰é˜ˆå€¼
         self.anchors = anchors  # é”šç‚¹æ•°æ®ï¼Œç”¨äºç›®æ ‡æ£€æµ‹
         self.rgb888p_size = [ALIGN_UP(rgb888p_size[0], 16), rgb888p_size[1]]  # sensorç»™åˆ°AIçš„å›¾åƒåˆ†è¾¨ç‡ï¼Œå¹¶å¯¹å®½åº¦è¿›è¡Œ16çš„å¯¹é½
         self.display_size = [ALIGN_UP(display_size[0], 16), display_size[1]]  # æ˜¾ç¤ºåˆ†è¾¨ç‡ï¼Œå¹¶å¯¹å®½åº¦è¿›è¡Œ16çš„å¯¹é½
         self.debug_mode = debug_mode  # æ˜¯å¦å¼€å¯è°ƒè¯•æ¨¡å¼
         self.ai2d = Ai2d(debug_mode)  # å®ä¾‹åŒ–Ai2dï¼Œç”¨äºå®ç°æ¨¡å‹é¢„å¤„ç†
         self.ai2d.set_ai2d_dtype(nn.ai2d_format.NCHW_FMT, nn.ai2d_format.NCHW_FMT, np.uint8, np.uint8)  # è®¾ç½®Ai2dçš„è¾“å…¥è¾“å‡ºæ ¼å¼å’Œç±»å‹

    # é…ç½®é¢„å¤„ç†æ“ä½œï¼Œè¿™é‡Œä½¿ç”¨äº†padå’Œresizeï¼ŒAi2dæ”¯æŒcrop/shift/pad/resize/affineï¼Œå…·ä½“ä»£ç è¯·æ‰“å¼€/sdcard/app/libs/AI2D.pyæŸ¥çœ‹
    def config_preprocess(self, input_image_size=None):
         with ScopedTiming("set preprocess config", self.debug_mode > 0):  # è®¡æ—¶å™¨ï¼Œå¦‚æœdebug_modeå¤§äº0åˆ™å¼€å¯
             ai2d_input_size = input_image_size if input_image_size else self.rgb888p_size  # åˆå§‹åŒ–ai2dé¢„å¤„ç†é…ç½®ï¼Œé»˜è®¤ä¸ºsensorç»™åˆ°AIçš„å°ºå¯¸ï¼Œå¯ä»¥é€šè¿‡è®¾ç½®input_image_sizeè‡ªè¡Œä¿®æ”¹è¾“å…¥å°ºå¯¸
             top, bottom, left, right,_ = letterbox_pad_param(self.rgb888p_size,self.model_input_size)
             self.ai2d.pad([0, 0, 0, 0, top, bottom, left, right], 0, [104, 117, 123])  # å¡«å……è¾¹ç¼˜
             self.ai2d.resize(nn.interp_method.tf_bilinear, nn.interp_mode.half_pixel)  # ç¼©æ”¾å›¾åƒ
             self.ai2d.build([1,3,ai2d_input_size[1],ai2d_input_size[0]],[1,3,self.model_input_size[1],self.model_input_size[0]])  # æ„å»ºé¢„å¤„ç†æµç¨‹

    # è‡ªå®šä¹‰å½“å‰ä»»åŠ¡çš„åå¤„ç†ï¼Œresultsæ˜¯æ¨¡å‹è¾“å‡ºarrayåˆ—è¡¨ï¼Œè¿™é‡Œä½¿ç”¨äº†aidemoåº“çš„face_det_post_processæ¥å£
    def postprocess(self, results):
         with ScopedTiming("postprocess", self.debug_mode > 0):
             post_ret = aidemo.face_det_post_process(self.confidence_threshold, self.nms_threshold, self.model_input_size[1], self.anchors, self.rgb888p_size, results)
             if len(post_ret) == 0:
                 return post_ret
             else:
                 return post_ret[0]

    # èµ„æºé‡Šæ”¾
    def deinit(self):
         del self.kpu
         del self.ai2d
         self.tensors.clear()
         del self.tensors
         gc.collect()
         time.sleep_ms(50)

#äººè„¸æ£€æµ‹çº¿ç¨‹
def face_det_thread():
     global display_size,sensor1,osd_img,face_rgb888p_size,face_osd_img
     # è®¾ç½®æ¨¡å‹è·¯å¾„å’Œå…¶ä»–å‚æ•°
     kmodel_path = "/sdcard/examples/kmodel/face_detection_320.kmodel"
     # å…¶å®ƒå‚æ•°
     confidence_threshold = 0.5
     nms_threshold = 0.2
     anchor_len = 4200
     det_dim = 4
     anchors_path = "/sdcard/examples/utils/prior_data_320.bin"
     anchors = np.fromfile(anchors_path, dtype=np.float)
     anchors = anchors.reshape((anchor_len, det_dim))
     face_det = FaceDetectionApp(kmodel_path, model_input_size=[320, 320], anchors=anchors, confidence_threshold=confidence_threshold, nms_threshold=nms_threshold, rgb888p_size=face_rgb888p_size, display_size=display_size, debug_mode=0)
     face_det.config_preprocess()  # é…ç½®é¢„å¤„ç†
     while face_det_run:
         img = sensor1.snapshot(chn = CAM_CHN_ID_1)
         img_np =img.to_numpy_ref()
         with lock:
             res = face_det.run(img_np)         # æ¨ç†å½“å‰å¸§
         face_osd_img.clear()
         if res:
             for det in res:
                 # å°†æ£€æµ‹æ¡†çš„åæ ‡è½¬æ¢ä¸ºæ˜¾ç¤ºåˆ†è¾¨ç‡ä¸‹çš„åæ ‡
                 x, y, w, h = map(lambda x: int(round(x, 0)), det[:4])
                 x = x * display_size[0] // face_rgb888p_size[0]
                 y = y * display_size[1] // face_rgb888p_size[1]
                 w = w * display_size[0] // face_rgb888p_size[0]
                 h = h * display_size[1] // face_rgb888p_size[1]
                 face_osd_img.draw_rectangle(x, y, w, h, color=(255, 255, 0, 255), thickness=2)
         Display.show_image(face_osd_img, 0, 0, Display.LAYER_OSD1)
         del img
         del img_np
         gc.collect()
     del face_osd_img
     face_det.deinit()

# YOLOv8æ£€æµ‹çº¿ç¨‹
def yolov8_det_thread():
     global display_size,sensor2,osd_img,yolo_rgb888p_size,yolo_osd_img
     kmodel_path="/sdcard/examples/kmodel/yolov8n_224.kmodel"
     labels = ["person", "bicycle", "car", "motorcycle", "airplane", "bus", "train", "truck", "boat", "traffic light", "fire hydrant", "stop sign", "parking meter", "bench", "bird", "cat", "dog", "horse", "sheep", "cow", "elephant", "bear", "zebra", "giraffe", "backpack", "umbrella", "handbag", "tie", "suitcase", "frisbee", "skis", "snowboard", "sports ball", "kite", "baseball bat", "baseball glove", "skateboard", "surfboard", "tennis racket", "bottle", "wine glass", "cup", "fork", "knife", "spoon", "bowl", "banana", "apple", "sandwich", "orange", "broccoli", "carrot", "hot dog", "pizza", "donut", "cake", "chair", "couch", "potted plant", "bed", "dining table", "toilet", "tv", "laptop", "mouse", "remote", "keyboard", "cell phone", "microwave", "oven", "toaster", "sink", "refrigerator", "book", "clock", "vase", "scissors", "teddy bear", "hair drier", "toothbrush"]
     confidence_threshold = 0.3
     nms_threshold = 0.4
     color_four=get_colors(len(labels))
     ob_det=ObjectDetectionApp(kmodel_path,labels=labels,model_input_size=[224,224],max_boxes_num=50,confidence_threshold=confidence_threshold,nms_threshold=nms_threshold,rgb888p_size=yolo_rgb888p_size,display_size=display_size,debug_mode=0)
     ob_det.config_preprocess()
     while yolo_det_run:
         img = sensor2.snapshot(chn = CAM_CHN_ID_1)
         img_np =img.to_numpy_ref()
         with lock:
             res = ob_det.run(img_np)

         yolo_osd_img.clear()
         for i in range(len(res[0])):
             x, y, w, h = map(lambda x: int(round(x, 0)), res[0][i])
             x=x+display_size[0]
             y=y+display_size[1]
             yolo_osd_img.draw_rectangle(x,y, w, h, color=color_four[res[1][i]],thickness=4)
             yolo_osd_img.draw_string_advanced( x , y-50,32," " + labels[res[1][i]] + " " + str(round(res[2][i],2)) , color=color_four[res[1][i]])

         Display.show_image(yolo_osd_img, 0, 0, Display.LAYER_OSD2)
         del img
         del img_np
         gc.collect()
     del yolo_osd_img
     ob_det.deinit()

def media_init():
    global display_size,sensor1,sensor2,yolo_rgb888p_size,face_rgb888p_size,face_osd_img,yolo_osd_img
    #-----------------------------Sensor1åˆå§‹åŒ–éƒ¨åˆ†-------------------------------
    sensor1 = Sensor(id=1)
    sensor1.reset()
    # è®¾ç½®æ°´å¹³é•œåƒå’Œå‚ç›´ç¿»è½¬ï¼Œä¸åŒæ¿å­çš„æ–¹å‘ä¸åŒï¼Œé€šè¿‡é…ç½®è¿™ä¸¤ä¸ªå‚æ•°ä½¿ç”»é¢è½¬æ­£
    #sensor1.set_hmirror(False)
    #sensor1.set_vflip(False)
    # é…ç½®sensor1çš„å¤šé€šé“å‡ºå›¾ï¼Œæ¯ä¸ªé€šé“çš„å‡ºå›¾æ ¼å¼å’Œåˆ†è¾¨ç‡å¯ä»¥ä¸åŒï¼Œæœ€å¤šå¯ä»¥å‡ºä¸‰è·¯å›¾ï¼Œå‚è€ƒsensor APIæ–‡æ¡£
    # é€šé“0ç›´æ¥ç»™åˆ°æ˜¾ç¤ºVOï¼Œæ ¼å¼ä¸ºYUV420
    sensor1.set_framesize(width = display_size[0], height = display_size[1],chn=CAM_CHN_ID_0)
    sensor1.set_pixformat(Sensor.YUV420SP,chn=CAM_CHN_ID_0)
    # é€šé“1ç»™åˆ°AIåšç®—æ³•å¤„ç†ï¼Œæ ¼å¼ä¸ºRGB888P
    sensor1.set_framesize(width = face_rgb888p_size[0] , height = face_rgb888p_size[1], chn=CAM_CHN_ID_1)
    # set chn1 output format
    sensor1.set_pixformat(Sensor.RGBP888, chn=CAM_CHN_ID_1)

    # ç»‘å®šé€šé“0çš„æ‘„åƒå¤´å›¾åƒåˆ°å±å¹•ï¼Œé˜²æ­¢å¦ä¸€ä¸ªé€šé“çš„AIæ¨ç†è¿‡ç¨‹å¤ªæ…¢å½±å“æ˜¾ç¤ºè¿‡ç¨‹ï¼Œå¯¼è‡´å‡ºç°å¡é¡¿æ•ˆæœ
    sensor_bind_info1 = sensor1.bind_info(x = 0, y = 0, chn = CAM_CHN_ID_0)
    Display.bind_layer(**sensor_bind_info1, layer = Display.LAYER_VIDEO1)

    #-----------------------------Sensor2åˆå§‹åŒ–éƒ¨åˆ†-------------------------------
    sensor2 = Sensor(id=2)
    sensor2.reset()
    # è®¾ç½®æ°´å¹³é•œåƒå’Œå‚ç›´ç¿»è½¬ï¼Œä¸åŒæ¿å­çš„æ–¹å‘ä¸åŒï¼Œé€šè¿‡é…ç½®è¿™ä¸¤ä¸ªå‚æ•°ä½¿ç”»é¢è½¬æ­£
    #sensor2.set_hmirror(False)
    #sensor2.set_vflip(False)

    # é…ç½®sensor2çš„å¤šé€šé“å‡ºå›¾ï¼Œæ¯ä¸ªé€šé“çš„å‡ºå›¾æ ¼å¼å’Œåˆ†è¾¨ç‡å¯ä»¥ä¸åŒï¼Œæœ€å¤šå¯ä»¥å‡ºä¸‰è·¯å›¾ï¼Œå‚è€ƒsensor APIæ–‡æ¡£
    # é€šé“0ç›´æ¥ç»™åˆ°æ˜¾ç¤ºVOï¼Œæ ¼å¼ä¸ºYUV420
    sensor2.set_framesize(width = display_size[0], height = display_size[1],chn=CAM_CHN_ID_0)
    sensor2.set_pixformat(Sensor.YUV420SP,chn=CAM_CHN_ID_0)
    # é€šé“1ç»™åˆ°AIåšç®—æ³•å¤„ç†ï¼Œæ ¼å¼ä¸ºRGB888P
    sensor2.set_framesize(width = yolo_rgb888p_size[0] , height = yolo_rgb888p_size[1], chn=CAM_CHN_ID_1)
    # set chn1 output format
    sensor2.set_pixformat(Sensor.RGBP888, chn=CAM_CHN_ID_1)

    # ç»‘å®šé€šé“0çš„æ‘„åƒå¤´å›¾åƒåˆ°å±å¹•ï¼Œé˜²æ­¢å¦ä¸€ä¸ªé€šé“çš„AIæ¨ç†è¿‡ç¨‹å¤ªæ…¢å½±å“æ˜¾ç¤ºè¿‡ç¨‹ï¼Œå¯¼è‡´å‡ºç°å¡é¡¿æ•ˆæœ
    sensor_bind_info2 = sensor2.bind_info(x = display_size[0], y = display_size[1], chn = CAM_CHN_ID_0)
    Display.bind_layer(**sensor_bind_info2, layer = Display.LAYER_VIDEO2)


    # OSDå›¾åƒåˆå§‹åŒ–,åˆ›å»ºä¸€å¸§å’Œå±å¹•åˆ†è¾¨ç‡åŒæ ·å¤§çš„é€æ˜å›¾åƒï¼Œç”¨äºç»˜åˆ¶AIæ¨ç†ç»“æœ
    face_osd_img = image.Image(DISPLAY_WIDTH, DISPLAY_HEIGHT, image.ARGB8888)
    yolo_osd_img = image.Image(DISPLAY_WIDTH, DISPLAY_HEIGHT, image.ARGB8888)

    # è®¾ç½®ä¸ºLT9611æ˜¾ç¤º
    Display.init(Display.LT9611,osd_num=2, to_ide=True)

    # mediaåˆå§‹åŒ–
    MediaManager.init()
    sensor1.run()

def media_deinit():
    global sensor1,sensor2,face_osd_img,yolo_osd_img
    sensor1.stop()
    sensor2.stop()
    Display.deinit()
    time.sleep_ms(50)
    MediaManager.deinit()
    nn.shrink_memory_pool()


if __name__=="__main__":
    media_init()
    _thread.start_new_thread(yolov8_det_thread,())
    _thread.start_new_thread(face_det_thread,())

    try:
        while True:
            time.sleep_ms(50)
    except BaseException as e:
        import sys
        sys.print_exception(e)
        yolo_det_run=False
        face_det_run=False
    time.sleep_ms(500)
    media_deinit()
    gc.collect()

```

### AI+UVCç¡¬è§£ç æ¨ç†

ä½¿ç”¨UVCæ‘„åƒå¤´è·å–å›¾åƒï¼Œå¹¶ä½¿ç”¨ç¡¬ä»¶CSCå°†å›¾åƒè½¬æ¢æˆRGB888æ ¼å¼ï¼Œåˆ›å»ºtensorï¼Œå°†tensorè¾“å…¥åˆ°AIæ¨¡å‹ä¸­ï¼Œè·å–AIæ¨¡å‹çš„è¾“å‡ºç»“æœï¼Œæœ€åå°†è¾“å‡ºç»“æœç»˜åˆ¶åˆ°å±å¹•ä¸Šã€‚è¿™é‡ŒAIæ¨ç†åœºæ™¯ä¸ºYOLOv8æ£€æµ‹ã€‚ç¤ºä¾‹ä»£ç å¦‚ä¸‹ï¼š

```python
from libs.PipeLine import PipeLine
from libs.AIBase import AIBase
from libs.AI2D import Ai2d
from libs.Utils import *
import os,sys,ujson,gc,math, urandom
from media.display import *
from media.media import *
from media.uvc import *
import nncase_runtime as nn
import ulab.numpy as np
import image
import aidemo
from nonai2d import CSC

# Custom YOLOv8 object detection class
class ObjectDetectionApp(AIBase):
    def __init__(self, kmodel_path, labels, model_input_size, max_boxes_num, confidence_threshold=0.5, nms_threshold=0.2, rgb888p_size=[224,224], display_size=[1920,1080], debug_mode=0):
        """
        Initialize object detection system.

        Parameters:
        - kmodel_path: Path to YOLOv8 KModel.
        - labels: List of class labels.
        - model_input_size: Model input size.
        - max_boxes_num: Max detection results to keep.
        - confidence_threshold: Detection score threshold.
        - nms_threshold: Non-max suppression threshold.
        - rgb888p_size: Camera input size (aligned to 16-width).
        - display_size: Output display size.
        - debug_mode: Enable debug timing logs.
        """
        super().__init__(kmodel_path, model_input_size, rgb888p_size, debug_mode)
        self.kmodel_path = kmodel_path
        self.labels = labels
        self.model_input_size = model_input_size
        self.confidence_threshold = confidence_threshold
        self.nms_threshold = nms_threshold
        self.max_boxes_num = max_boxes_num

        # Align width to multiple of 16 for hardware compatibility
        self.rgb888p_size = [ALIGN_UP(rgb888p_size[0], 16), rgb888p_size[1]]
        self.display_size = [ALIGN_UP(display_size[0], 16), display_size[1]]
        self.debug_mode = debug_mode

        # Predefined colors for each class
        self.color_four = get_colors(len(self.labels))

        # Input scaling factors
        self.x_factor = float(self.rgb888p_size[0]) / self.model_input_size[0]
        self.y_factor = float(self.rgb888p_size[1]) / self.model_input_size[1]

        # Ai2d instance for preprocessing
        self.ai2d = Ai2d(debug_mode)
        self.ai2d.set_ai2d_dtype(nn.ai2d_format.NCHW_FMT, nn.ai2d_format.NCHW_FMT, np.uint8, np.uint8)

    def config_preprocess(self, input_image_size=None):
        """
        Configure pre-processing: padding and resizing using Ai2d.
        """
        with ScopedTiming("set preprocess config", self.debug_mode > 0):
            ai2d_input_size = input_image_size if input_image_size else self.rgb888p_size
            top, bottom, left, right, self.scale = letterbox_pad_param(self.rgb888p_size, self.model_input_size)
            self.ai2d.pad([0,0,0,0,top,bottom,left,right], 0, [128,128,128])
            self.ai2d.resize(nn.interp_method.tf_bilinear, nn.interp_mode.half_pixel)
            self.ai2d.build(
                [1, 3, ai2d_input_size[1], ai2d_input_size[0]],
                [1, 3, self.model_input_size[1], self.model_input_size[0]]
            )

    def postprocess(self, results):
        """
        Apply YOLOv8 post-processing including NMS and thresholding.
        """
        with ScopedTiming("postprocess", self.debug_mode > 0):
            new_result = results[0][0].transpose()
            det_res = aidemo.yolov8_det_postprocess(
                new_result.copy(),
                [self.rgb888p_size[1], self.rgb888p_size[0]],
                [self.model_input_size[1], self.model_input_size[0]],
                [self.display_size[1], self.display_size[0]],
                len(self.labels),
                self.confidence_threshold,
                self.nms_threshold,
                self.max_boxes_num
            )
            return det_res

    def draw_result(self, img, dets):
        """
        Draw detection results and send label info via UART.
        """
        with ScopedTiming("display_draw",self.debug_mode >0):
            if dets:
                for i in range(len(dets[0])):
                    x, y, w, h = map(lambda x: int(round(x, 0)), dets[0][i])
                    img.draw_rectangle(x,y, w, h, color=self.color_four[dets[1][i]],thickness=4)
                    img.draw_string_advanced( x , y-50,32," " + self.labels[dets[1][i]] + " " + str(round(dets[2][i],2)) , color=self.color_four[dets[1][i]])


if __name__ == "__main__":

    # Align display width to 16 bytes for hardware requirement
    DISPLAY_WIDTH = ALIGN_UP(800, 16)
    DISPLAY_HEIGHT = 480

    # Create CSC instance for pixel format conversion (e.g., to RGB888)
    csc = CSC(0, CSC.PIXEL_FORMAT_RGB_888)

    # Initialize LCD display (ST7701) and enable IDE display
    Display.init(Display.ST7701, width=DISPLAY_WIDTH, height=DISPLAY_HEIGHT, to_ide=True)

    # Initialize media manager to manage frame buffers and UVC stream
    MediaManager.init()

    # Wait for USB camera to be detected
    while True:
        plugin, dev = UVC.probe()
        if plugin:
            print(f"detect USB Camera {dev}")
            break
        time.sleep_ms(100)

    # Select and configure UVC video mode: 640x480 @ 30 FPS, MJPEG format
    mode = UVC.video_mode(640, 480, UVC.FORMAT_MJPEG, 30)
    succ, mode = UVC.select_video_mode(mode)
    print(f"select mode success: {succ}, mode: {mode}")

    # Define input image from USB camera (sensor side)
    rgb888p_size = [640, 480]

    # Path to the YOLOv8n kmodel
    kmodel_path = "/sdcard/examples/kmodel/yolov8n_224.kmodel"

    # COCO class labels used for detection
    labels = ["person", "bicycle", "car", "motorcycle", "airplane", "bus", "train", "truck", "boat",
              "traffic light", "fire hydrant", "stop sign", "parking meter", "bench", "bird", "cat",
              "dog", "horse", "sheep", "cow", "elephant", "bear", "zebra", "giraffe", "backpack",
              "umbrella", "handbag", "tie", "suitcase", "frisbee", "skis", "snowboard", "sports ball",
              "kite", "baseball bat", "baseball glove", "skateboard", "surfboard", "tennis racket",
              "bottle", "wine glass", "cup", "fork", "knife", "spoon", "bowl", "banana", "apple",
              "sandwich", "orange", "broccoli", "carrot", "hot dog", "pizza", "donut", "cake", "chair",
              "couch", "potted plant", "bed", "dining table", "toilet", "tv", "laptop", "mouse", "remote",
              "keyboard", "cell phone", "microwave", "oven", "toaster", "sink", "refrigerator", "book",
              "clock", "vase", "scissors", "teddy bear", "hair drier", "toothbrush"]

    # Detection parameters
    confidence_threshold = 0.3  # Minimum confidence to accept a detection
    nms_threshold = 0.4         # Non-Maximum Suppression threshold
    max_boxes_num = 30          # Max boxes per frame after filtering

    # Initialize object detection application with YOLOv8 model
    ob_det = ObjectDetectionApp(
        kmodel_path,
        labels=labels,
        model_input_size=[224, 224],
        max_boxes_num=max_boxes_num,
        confidence_threshold=confidence_threshold,
        nms_threshold=nms_threshold,
        rgb888p_size=rgb888p_size,
        display_size=rgb888p_size,
        debug_mode=0
    )

    # Configure Ai2d preprocessing (resize + letterbox pad)
    ob_det.config_preprocess()
    # Start UVC video stream with pixel format conversion enabled
    UVC.start(cvt=True)
    clock = time.clock()
    # Main loop: acquire frame, run inference, draw and display
    while True:
        clock.tick()
        img = UVC.snapshot()
        if img is not None:
            # Convert format (e.g., to RGB888)
            img = csc.convert(img)
            # Convert to Ulab.Numpy.ndarray
            img_np_hwc = img.to_numpy_ref()
            # HWC->CHW
            img_np_chw = hwc2chw(img_np_hwc)
            # Run YOLOv8 inference on the current frame
            res = ob_det.run(img_np_chw)
            # Draw detection results on the frame
            ob_det.draw_result(img, res)
            # Show result on display
            Display.show_image(img)
            # Explicitly release image buffer
            img.__del__()
            gc.collect()
        # Print current frame rate
        print(f"fps: {clock.fps()}")
    # Clean up: stop display and media system
    ob_det.deinit()
    Display.deinit()
    csc.destroy()
    UVC.stop()
    time.sleep_ms(100)
    MediaManager.deinit()
```

### AI+UVCè½¯è§£ç æ¨ç†

ä½¿ç”¨UVCæ‘„åƒå¤´è·å–å›¾åƒï¼Œå¹¶ä½¿ç”¨è½¯ä»¶è§£ç å°†å›¾åƒè½¬æ¢æˆRGB888æ ¼å¼ï¼Œåˆ›å»ºtensorï¼Œå°†tensorè¾“å…¥åˆ°AIæ¨¡å‹ä¸­ï¼Œè·å–AIæ¨¡å‹çš„è¾“å‡ºç»“æœï¼Œæœ€åå°†è¾“å‡ºç»“æœç»˜åˆ¶åˆ°å±å¹•ä¸Šã€‚è¿™é‡ŒAIæ¨ç†åœºæ™¯ä¸ºYOLOv8æ£€æµ‹ã€‚ç¤ºä¾‹ä»£ç å¦‚ä¸‹ï¼š

```python
from libs.PipeLine import PipeLine
from libs.AIBase import AIBase
from libs.AI2D import Ai2d
from libs.Utils import *
import os,sys,ujson,gc,math, urandom
from media.display import *
from media.media import *
from media.uvc import *
import nncase_runtime as nn
import ulab.numpy as np
import image
import aidemo

# Custom YOLOv8 object detection class
class ObjectDetectionApp(AIBase):
    def __init__(self, kmodel_path, labels, model_input_size, max_boxes_num, confidence_threshold=0.5, nms_threshold=0.2, rgb888p_size=[224,224], display_size=[1920,1080], debug_mode=0):
        """
        Initialize object detection system.

        Parameters:
        - kmodel_path: Path to YOLOv8 KModel.
        - labels: List of class labels.
        - model_input_size: Model input size.
        - max_boxes_num: Max detection results to keep.
        - confidence_threshold: Detection score threshold.
        - nms_threshold: Non-max suppression threshold.
        - rgb888p_size: Camera input size (aligned to 16-width).
        - display_size: Output display size.
        - debug_mode: Enable debug timing logs.
        """
        super().__init__(kmodel_path, model_input_size, rgb888p_size, debug_mode)
        self.kmodel_path = kmodel_path
        self.labels = labels
        self.model_input_size = model_input_size
        self.confidence_threshold = confidence_threshold
        self.nms_threshold = nms_threshold
        self.max_boxes_num = max_boxes_num

        # Align width to multiple of 16 for hardware compatibility
        self.rgb888p_size = [ALIGN_UP(rgb888p_size[0], 16), rgb888p_size[1]]
        self.display_size = [ALIGN_UP(display_size[0], 16), display_size[1]]
        self.debug_mode = debug_mode

        # Predefined colors for each class
        self.color_four = get_colors(len(self.labels))

        # Input scaling factors
        self.x_factor = float(self.rgb888p_size[0]) / self.model_input_size[0]
        self.y_factor = float(self.rgb888p_size[1]) / self.model_input_size[1]

        # Ai2d instance for preprocessing
        self.ai2d = Ai2d(debug_mode)
        self.ai2d.set_ai2d_dtype(nn.ai2d_format.NCHW_FMT, nn.ai2d_format.NCHW_FMT, np.uint8, np.uint8)

    def config_preprocess(self, input_image_size=None):
        """
        Configure pre-processing: padding and resizing using Ai2d.
        """
        with ScopedTiming("set preprocess config", self.debug_mode > 0):
            ai2d_input_size = input_image_size if input_image_size else self.rgb888p_size
            top, bottom, left, right, self.scale = letterbox_pad_param(self.rgb888p_size, self.model_input_size)
            self.ai2d.pad([0,0,0,0,top,bottom,left,right], 0, [128,128,128])
            self.ai2d.resize(nn.interp_method.tf_bilinear, nn.interp_mode.half_pixel)
            self.ai2d.build(
                [1, 3, ai2d_input_size[1], ai2d_input_size[0]],
                [1, 3, self.model_input_size[1], self.model_input_size[0]]
            )

    def postprocess(self, results):
        """
        Apply YOLOv8 post-processing including NMS and thresholding.
        """
        with ScopedTiming("postprocess", self.debug_mode > 0):
            new_result = results[0][0].transpose()
            det_res = aidemo.yolov8_det_postprocess(
                new_result.copy(),
                [self.rgb888p_size[1], self.rgb888p_size[0]],
                [self.model_input_size[1], self.model_input_size[0]],
                [self.display_size[1], self.display_size[0]],
                len(self.labels),
                self.confidence_threshold,
                self.nms_threshold,
                self.max_boxes_num
            )
            return det_res

    def draw_result(self, img, dets):
        """
        Draw detection results and send label info via UART.
        """
        with ScopedTiming("display_draw",self.debug_mode >0):
            if dets:
                for i in range(len(dets[0])):
                    x, y, w, h = map(lambda x: int(round(x, 0)), dets[0][i])
                    img.draw_rectangle(x,y, w, h, color=self.color_four[dets[1][i]],thickness=4)
                    img.draw_string_advanced( x , y-50,32," " + self.labels[dets[1][i]] + " " + str(round(dets[2][i],2)) , color=self.color_four[dets[1][i]])


if __name__ == "__main__":

    # Align display width to 16 bytes for hardware requirement
    DISPLAY_WIDTH = ALIGN_UP(800, 16)
    DISPLAY_HEIGHT = 480

    # Initialize LCD display (ST7701) and enable IDE display
    Display.init(Display.ST7701, width=DISPLAY_WIDTH, height=DISPLAY_HEIGHT, to_ide=True)

    # Initialize media manager to manage frame buffers and UVC stream
    MediaManager.init()

    # Wait for USB camera to be detected
    while True:
        plugin, dev = UVC.probe()
        if plugin:
            print(f"detect USB Camera {dev}")
            break
        time.sleep_ms(100)

    # Select and configure UVC video mode: 640x480 @ 30 FPS, MJPEG format
    mode = UVC.video_mode(640, 480, UVC.FORMAT_MJPEG, 30)
    succ, mode = UVC.select_video_mode(mode)
    print(f"select mode success: {succ}, mode: {mode}")

    # Define input image from USB camera (sensor side)
    rgb888p_size = [640, 480]

    # Path to the YOLOv8n kmodel
    kmodel_path = "/sdcard/examples/kmodel/yolov8n_224.kmodel"

    # COCO class labels used for detection
    labels = ["person", "bicycle", "car", "motorcycle", "airplane", "bus", "train", "truck", "boat",
              "traffic light", "fire hydrant", "stop sign", "parking meter", "bench", "bird", "cat",
              "dog", "horse", "sheep", "cow", "elephant", "bear", "zebra", "giraffe", "backpack",
              "umbrella", "handbag", "tie", "suitcase", "frisbee", "skis", "snowboard", "sports ball",
              "kite", "baseball bat", "baseball glove", "skateboard", "surfboard", "tennis racket",
              "bottle", "wine glass", "cup", "fork", "knife", "spoon", "bowl", "banana", "apple",
              "sandwich", "orange", "broccoli", "carrot", "hot dog", "pizza", "donut", "cake", "chair",
              "couch", "potted plant", "bed", "dining table", "toilet", "tv", "laptop", "mouse", "remote",
              "keyboard", "cell phone", "microwave", "oven", "toaster", "sink", "refrigerator", "book",
              "clock", "vase", "scissors", "teddy bear", "hair drier", "toothbrush"]

    # Detection parameters
    confidence_threshold = 0.3  # Minimum confidence to accept a detection
    nms_threshold = 0.4         # Non-Maximum Suppression threshold
    max_boxes_num = 30          # Max boxes per frame after filtering

    # Initialize object detection application with YOLOv8 model
    ob_det = ObjectDetectionApp(
        kmodel_path,
        labels=labels,
        model_input_size=[224, 224],
        max_boxes_num=max_boxes_num,
        confidence_threshold=confidence_threshold,
        nms_threshold=nms_threshold,
        rgb888p_size=rgb888p_size,
        display_size=rgb888p_size,
        debug_mode=0
    )

    # Configure Ai2d preprocessing (resize + letterbox pad)
    ob_det.config_preprocess()
    # Start UVC video stream with pixel format conversion enabled
    UVC.start(cvt=False)
    clock = time.clock()
    # Main loop: acquire frame, run inference, draw and display
    while True:
        clock.tick()
        img = UVC.snapshot()
        if img is not None:
            # Convert format (e.g., to RGB888)
            img = img.to_rgb888()
            # Convert to Ulab.Numpy.ndarray
            img_np_hwc = img.to_numpy_ref()
            # HWC->CHW
            img_np_chw = hwc2chw(img_np_hwc)
            # Run YOLOv8 inference on the current frame
            res = ob_det.run(img_np_chw)
            # Draw detection results on the frame
            ob_det.draw_result(img, res)
            # Show result on display
            Display.show_image(img)
            # Explicitly release image buffer
            img.__del__()
            gc.collect()
        # Print current frame rate
        print(f"fps: {clock.fps()}")
    # Clean up: stop display and media system
    ob_det.deinit()
    Display.deinit()
    UVC.stop()
    time.sleep_ms(100)
    MediaManager.deinit()

```

## FAQ
  
### å¼€å‘è¿‡ç¨‹ä¸­å¦‚ä½•æŸ¥æ‰¾é—®é¢˜æ‰€åœ¨ï¼Ÿ

ğŸ“ é¦–å…ˆæ ¹æ®ä¸åŒçš„é˜¶æ®µå’Œé”™è¯¯é‡‡å–ä¸åŒçš„æ–¹æ³•ï¼š

- å¦‚æœæ¨¡å‹è½¬æ¢é˜¶æ®µå‡ºç°é”™è¯¯ï¼Œå¯èƒ½æ˜¯è½¬æ¢ä»£ç å­˜åœ¨é—®é¢˜ï¼Œéœ€è¦é˜…è¯»nncaseçš„ä½¿ç”¨æ–¹æ³•ï¼Œè°ƒæ•´è½¬æ¢ä»£ç ï¼›
- å¦‚æœæ¨¡å‹è½¬æ¢æˆåŠŸï¼Œä½†æ˜¯æ•ˆæœä¸åŠé¢„æœŸï¼Œå¯ä»¥è€ƒè™‘è°ƒæ•´é˜ˆå€¼ã€æ›´æ”¹æ¨¡å‹è½¬æ¢çš„é‡åŒ–æ–¹å¼ã€è®­ç»ƒæ—¶è°ƒæ•´è®­ç»ƒå‚æ•°ï¼›
- å¦‚æœæ¨¡å‹è½¬æ¢æˆåŠŸï¼Œä½†æ˜¯å¸§ç‡è¾ƒä½ï¼Œå¯ä»¥è€ƒè™‘æ›´æ¢æ›´è½»é‡çš„æ¨¡å‹æˆ–è€…é™ä½æ¨¡å‹è¾“å…¥åˆ†è¾¨ç‡ï¼›
- å¦‚æœéƒ¨ç½²æŠ¥é”™ï¼Œè¯·æŸ¥çœ‹éƒ¨ç½²ä»£ç æŠ¥é”™è¡Œæ•°ï¼Œæ ¹æ®APIæ–‡æ¡£æŸ¥æ‰¾æŠ¥é”™åŸå› ï¼Œè°ƒæ•´ä»£ç ï¼›

### nncaseæ”¯æŒå“ªäº›ç®—å­ï¼Ÿ

ğŸ“ nncaseæ”¯æŒçš„onnxç®—å­å’Œtfliteç®—å­è§é“¾æ¥ï¼š[onnxç®—å­æ”¯æŒ](https://github.com/kendryte/nncase/blob/master/docs/onnx_ops.md) å’Œ [tfliteç®—å­æ”¯æŒ](https://github.com/kendryte/nncase/blob/master/docs/tflite_ops.md)

### åœ¨è½¬æ¢æ¨¡å‹æ—¶æŠ¥é”™â€œImportError: DLL load failed while importing _nncaseâ€

ğŸ“ è¯·å‚è€ƒå¦‚ä¸‹é“¾æ¥çš„è§£å†³æ–¹æ³•ï¼š[ImportError: DLL load failed while importing _nncase](https://github.com/kendryte/nncase/issues/451)

### è½¬æ¢æ¨¡å‹æ—¶æŠ¥é”™â€œRuntimeError: Failed to initialize hostfxrâ€

ğŸ“ è¯·å®‰è£…dotnet-sdk-7.0ï¼Œ è¯·ä¸è¦å†Anacondaè™šæ‹Ÿç¯å¢ƒä¸­å®‰è£…dotnet-sdkã€‚

Linux:

```shell
sudo apt-get update
sudo apt-get install dotnet-sdk-7.0
If you still have problems after installation, maybe you install dotnet in a virtual enviroment, set the environment variables. dotnet error
export DOTNET_ROOT=/usr/share/dotnet
```

Windows: è¯·å‚è€ƒå¾®è½¯å®˜æ–¹ç½‘ç«™ã€‚

### åœ¨çº¿è®­ç»ƒå¹³å°å’ŒAICubeçš„åŒºåˆ«ï¼Ÿ

ğŸ“ åœ¨çº¿è®­ç»ƒå¹³å°çš„ä½¿ç”¨äº‘ç«¯ç®—åŠ›ï¼Œèµ„æºç´§å¼ æ—¶éœ€è¦æ’é˜Ÿï¼ŒåŒæ—¶å‚æ•°é…ç½®æ¯”è¾ƒç®€å•ï¼Œä¸€é”®è®­ç»ƒï¼Œçµæ´»æ€§è¾ƒä½ï¼›AICubeä½¿ç”¨æœ¬åœ°ç§äººç®—åŠ›ï¼Œç¯å¢ƒå’Œå‚æ•°é…ç½®æ¯”è¾ƒå¤æ‚ï¼Œçµæ´»æ€§é«˜ã€‚ä»–ä»¬çš„ç›®çš„éƒ½æ˜¯è·å¾—kmodelå’Œé…ç½®æ–‡ä»¶ï¼Œä½¿ç”¨å›ºä»¶ä¸­çš„`CanMV/sdcard/examples/19-CloudPlatScripts`çš„è„šæœ¬å³å¯å®ç°éƒ¨ç½²ã€‚

### å¦‚ä½•å°†è°ƒè¯•å¥½çš„è„šæœ¬è®¾ç½®ä¸ºè‡ªå¯åŠ¨ï¼Ÿ

ğŸ“ å°†è„šæœ¬ä¿å­˜åœ¨`/sdcard`ç›®å½•ä¸‹ä»¥`main.py`å‘½åã€‚æˆ–è€…ä½¿ç”¨CanMV IDEçš„`å·¥å…·(T)`->`Save open script to CanMV board (as main.py)`ä¿å­˜åï¼Œé‡æ–°ä¸Šç”µå¯åŠ¨ã€‚

### YOLOåº“ä¸­æ”¯æŒå“ªäº›ä»»åŠ¡ï¼Ÿ

ğŸ“ YOLOv5æ”¯æŒåˆ†ç±»ã€æ£€æµ‹ã€åˆ†å‰²ä¸‰ç±»ä»»åŠ¡ï¼ŒYOLOv8å’ŒYOLO11æ”¯æŒåˆ†ç±»ã€æ£€æµ‹ã€åˆ†å‰²å’Œæ—‹è½¬ç›®æ ‡æ£€æµ‹å››ç±»ä»»åŠ¡ã€‚

### UVCçš„è½¯ç¡¬ä»¶è§£ç æœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿ

ğŸ“ ç¡¬ä»¶è§£ç ä½¿ç”¨CSCå®ç°æ ¼å¼è½¬æ¢ï¼Œå°†UVCå›¾åƒæ•°æ®è½¬æ¢æˆRGB888çš„Imageå®ä¾‹ï¼›è½¯ä»¶è§£ç ä½¿ç”¨Imageå®ä¾‹çš„`to_rgb888`æ¥å£å°†å›¾åƒæ•°æ®è½¬æ¢æˆRGB888æ ¼å¼çš„Imageå®ä¾‹ã€‚ç¡¬ä»¶è§£ç æ¯”è½¯ä»¶è§£ç æ›´å¿«ï¼Œå¸§ç‡æ›´é«˜ã€‚

### å¦‚ä½•è·å–æ”¯æŒï¼Ÿ

ğŸ“ åœ¨å¼€å‘è¿‡ç¨‹ä¸­é‡åˆ°é—®é¢˜ï¼Œæ‚¨å¯ä»¥å‰å¾€å˜‰æ¥ å¼€å‘è€…ç¤¾åŒºé—®ç­”è®ºå›å‘å¸–æé—®ã€‚è®ºå›åœ°å€ï¼š[Canaané—®ç­”è®ºå›](https://www.kendryte.com/answer/)ã€‚

## é™„å½•

### API

K230 MicroPython APIæ–‡æ¡£è§é“¾æ¥ï¼š[APIæ–‡æ¡£](./api/index.md)

### KTS

`K230_training_scriptsï¼ˆKTSï¼‰`æ˜¯å®ç°çš„ç«¯åˆ°ç«¯çš„è®­ç»ƒå¤„ç†è¿‡ç¨‹ï¼Œä½†æ˜¯è¯¥é¡¹ç›®çš„ä»£ç æ˜¯åŸºäºåŒç³»ç»ŸC++å¼€å‘çš„ï¼Œæ‚¨å¯ä»¥ä½¿ç”¨è¯¥å·¥å…·è·å–kmodelï¼Œä½†è¯¥å·¥å…·ä¸­ä¸åŒ…å«MicroPythonéƒ¨ç½²ä»£ç ï¼Œæ‚¨éœ€è¦è‡ªè¡Œç¼–å†™ã€‚é¡¹ç›®åœ°å€ï¼š[K230_training_scripts](https://github.com/kendryte/K230_training_scripts)ã€‚
